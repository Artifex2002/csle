Search.setIndex({"docnames": ["csle_agents", "csle_agents.agents", "csle_agents.agents.base", "csle_agents.agents.bayes_opt", "csle_agents.agents.bayesian_optimization", "csle_agents.agents.cross_entropy", "csle_agents.agents.dfsp_local", "csle_agents.agents.differential_evolution", "csle_agents.agents.dqn", "csle_agents.agents.dynasec", "csle_agents.agents.fp", "csle_agents.agents.hsvi", "csle_agents.agents.hsvi_os_posg", "csle_agents.agents.kiefer_wolfowitz", "csle_agents.agents.lp_nf", "csle_agents.agents.pi", "csle_agents.agents.ppo", "csle_agents.agents.q_learning", "csle_agents.agents.random_search", "csle_agents.agents.reinforce", "csle_agents.agents.sarsa", "csle_agents.agents.shapley_iteration", "csle_agents.agents.sondik_vi", "csle_agents.agents.t_fp", "csle_agents.agents.t_spsa", "csle_agents.agents.vi", "csle_agents.common", "csle_agents.constants", "csle_agents.job_controllers", "index", "modules"], "filenames": ["csle_agents.rst", "csle_agents.agents.rst", "csle_agents.agents.base.rst", "csle_agents.agents.bayes_opt.rst", "csle_agents.agents.bayesian_optimization.rst", "csle_agents.agents.cross_entropy.rst", "csle_agents.agents.dfsp_local.rst", "csle_agents.agents.differential_evolution.rst", "csle_agents.agents.dqn.rst", "csle_agents.agents.dynasec.rst", "csle_agents.agents.fp.rst", "csle_agents.agents.hsvi.rst", "csle_agents.agents.hsvi_os_posg.rst", "csle_agents.agents.kiefer_wolfowitz.rst", "csle_agents.agents.lp_nf.rst", "csle_agents.agents.pi.rst", "csle_agents.agents.ppo.rst", "csle_agents.agents.q_learning.rst", "csle_agents.agents.random_search.rst", "csle_agents.agents.reinforce.rst", "csle_agents.agents.sarsa.rst", "csle_agents.agents.shapley_iteration.rst", "csle_agents.agents.sondik_vi.rst", "csle_agents.agents.t_fp.rst", "csle_agents.agents.t_spsa.rst", "csle_agents.agents.vi.rst", "csle_agents.common.rst", "csle_agents.constants.rst", "csle_agents.job_controllers.rst", "index.rst", "modules.rst"], "titles": ["csle_agents package", "csle_agents.agents package", "csle_agents.agents.base package", "csle_agents.agents.bayes_opt package", "csle_agents.agents.bayesian_optimization package", "csle_agents.agents.cross_entropy package", "csle_agents.agents.dfsp_local package", "csle_agents.agents.differential_evolution package", "csle_agents.agents.dqn package", "csle_agents.agents.dynasec package", "csle_agents.agents.fp package", "csle_agents.agents.hsvi package", "csle_agents.agents.hsvi_os_posg package", "csle_agents.agents.kiefer_wolfowitz package", "csle_agents.agents.lp_nf package", "csle_agents.agents.pi package", "csle_agents.agents.ppo package", "csle_agents.agents.q_learning package", "csle_agents.agents.random_search package", "csle_agents.agents.reinforce package", "csle_agents.agents.sarsa package", "csle_agents.agents.shapley_iteration package", "csle_agents.agents.sondik_vi package", "csle_agents.agents.t_fp package", "csle_agents.agents.t_spsa package", "csle_agents.agents.vi package", "csle_agents.common package", "csle_agents.constants package", "csle_agents.job_controllers package", "csle_agents package", "csle_agents"], "terms": {"agent": [0, 27, 29, 30], "base": [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], "submodul": [0, 1, 29, 30], "base_ag": [0, 1, 29], "bayesian_optim": [0, 1, 27, 29], "bayes_opt_ag": [0, 1, 29], "cross_entropi": [0, 1, 27, 29], "cross_entropy_ag": [0, 1, 29], "dfsp_local": [0, 1, 29], "dfsp_local_ag": [0, 1, 29], "dfsp_local_ppo_ag": [0, 1, 29], "differential_evolut": [0, 1, 27, 29], "differential_evolution_ag": [0, 1, 29], "dqn": [0, 1, 27, 29], "dqn_agent": [0, 1, 29], "dynasec": [0, 1, 27, 29], "dynasec_ag": [0, 1, 29], "fp": [0, 1, 23, 27, 29], "fictitious_play_ag": [0, 1, 29], "hsvi": [0, 1, 12, 27, 29], "hsvi_ag": [0, 1, 29], "hsvi_os_posg": [0, 1, 27, 29], "hsvi_os_posg_ag": [0, 1, 29], "kiefer_wolfowitz": [0, 1, 27, 29], "kiefer_wolfowitz_ag": [0, 1, 29], "lp_nf": [0, 1, 12, 29], "linear_programming_normal_form_game_ag": [0, 1, 29], "pi": [0, 1, 12, 27, 29], "pi_ag": [0, 1, 29], "ppo": [0, 1, 27, 29], "ppo_ag": [0, 1, 29], "q_learn": [0, 1, 20, 27, 29], "q_learning_ag": [0, 1, 29], "random_search": [0, 1, 27, 29], "random_search_ag": [0, 1, 29], "reinforc": [0, 1, 9, 27, 29], "reinforce_ag": [0, 1, 29], "sarsa": [0, 1, 27, 29], "sarsa_ag": [0, 1, 29], "shapley_iter": [0, 1, 27, 29], "shapley_iteration_ag": [0, 1, 29], "sondik_vi": [0, 1, 27, 29], "sondik_vi_ag": [0, 1, 29], "t_fp": [0, 1, 27, 29], "t_fp_agent": [0, 1, 29], "t_spsa": [0, 1, 29], "t_spsa_ag": [0, 1, 29], "vi": [0, 1, 11, 12, 27, 29], "vi_ag": [0, 1, 29], "common": [0, 27, 29, 30], "actor_critic_net": [0, 29, 30], "fnn_w_gaussian": [0, 29, 30], "fnnwithgaussian": [0, 26, 29], "forward": [0, 26, 29], "get_hidden_activ": [0, 26, 29], "test": [0, 26, 29], "fnn_w_linear": [0, 29, 30], "fnnwithlinear": [0, 26, 29], "prune": [0, 1, 11, 12, 22, 29, 30], "check_dominance_lp": [0, 26, 29], "check_dupl": [0, 1, 22, 26, 29], "prune_lower_bound": [0, 26, 29], "constant": [0, 29, 30], "l": [0, 4, 5, 7, 8, 12, 13, 16, 18, 21, 24, 27, 29], "n": [0, 6, 15, 17, 20, 23, 27, 29], "parameter_bound": [0, 27, 29], "param": [0, 11, 12, 15, 22, 25, 27, 29], "policy_typ": [0, 27, 29], "stop_distribution_attack": [0, 27, 29], "stop_distribution_defend": [0, 27, 29], "target": [0, 27, 29], "theta1": [0, 27, 29], "theta": [0, 4, 5, 7, 11, 12, 13, 18, 24, 25, 27, 29], "threshold": [0, 4, 5, 7, 11, 12, 13, 18, 21, 23, 24, 25, 27, 29], "ucb": [0, 27, 29], "ucb_kappa": [0, 27, 29], "ucb_xi": [0, 27, 29], "utility_funct": [0, 27, 29], "adam": [0, 27, 29], "average_attacker_return": [0, 27, 29], "average_defender_return": [0, 27, 29], "average_heuristic_return": [0, 27, 29], "average_random_return": [0, 27, 29], "average_return": [0, 25, 27, 29], "average_time_horizon": [0, 27, 29], "average_upper_bound_return": [0, 27, 29], "baseline_prefix": [0, 27, 29], "batch_siz": [0, 27, 29], "confidence_interv": [0, 27, 29], "eval_batch_s": [0, 8, 15, 16, 17, 20, 22, 25, 27, 29], "eval_everi": [0, 8, 16, 27, 29], "eval_prefix": [0, 27, 29], "exploit": [0, 1, 6, 23, 27, 29], "gamma": [0, 11, 12, 15, 17, 19, 20, 21, 22, 27, 29], "learning_r": [0, 27, 29], "learning_rate_decay_r": [0, 27, 29], "learning_rate_exp_decai": [0, 27, 29], "max_env_step": [0, 27, 29], "num_cached_simulation_trac": [0, 27, 29], "num_nod": [0, 27, 29], "num_parallel_env": [0, 27, 29], "num_training_timestep": [0, 27, 29], "optim": [0, 4, 9, 12, 15, 19, 23, 24, 27, 29], "policy_loss": [0, 27, 29], "running_averag": [0, 1, 6, 23, 27, 29], "running_average_attacker_return": [0, 27, 29], "running_average_defender_return": [0, 27, 29], "running_average_exploit": [0, 27, 29], "running_average_intrusion_length": [0, 27, 29], "running_average_intrusion_start": [0, 27, 29], "running_average_return": [0, 27, 29], "running_average_start_point_correct": [0, 27, 29], "running_average_time_horizon": [0, 27, 29], "running_average_weighted_intrusion_prediction_dist": [0, 27, 29], "runtim": [0, 27, 29], "save_everi": [0, 8, 16, 27, 29], "sgd": [0, 27, 29], "start_point_correct": [0, 27, 29], "stopping_env": [0, 27, 29], "weighted_intrusion_prediction_dist": [0, 27, 29], "k": [0, 13, 24, 27, 29], "lamb": [0, 24, 27, 29], "bound": [0, 7, 11, 12, 26, 27, 29], "mutat": [0, 27, 29], "population_s": [0, 27, 29], "recombin": [0, 27, 29], "buffer_s": [0, 27, 29], "dqn_batch_siz": [0, 27, 29], "exploration_final_ep": [0, 27, 29], "exploration_fract": [0, 27, 29], "exploration_initial_ep": [0, 27, 29], "gradient_step": [0, 27, 29], "learning_start": [0, 27, 29], "max_grad_norm": [0, 27, 29], "mlp_polici": [0, 27, 29], "n_episodes_rollout": [0, 27, 29], "target_update_interv": [0, 27, 29], "train_freq": [0, 27, 29], "clients_arrival_r": [0, 27, 29], "emulation_monitor_sleep_tim": [0, 27, 29], "emulation_traces_to_save_w_data_collection_job": [0, 27, 29], "intrusion_alerts_mean": [0, 27, 29], "intrusion_alerts_mean_baselin": [0, 27, 29], "intrusion_start_p": [0, 9, 27, 29], "no_intrusion_alerts_mean": [0, 27, 29], "no_intrusion_alerts_mean_baselin": [0, 27, 29], "num_client": [0, 27, 29], "replay_window_s": [0, 27, 29], "sleep_tim": [0, 9, 27, 29], "static_attacker_typ": [0, 27, 29], "training_epoch": [0, 27, 29], "warmup_episod": [0, 27, 29], "env_metr": [0, 27, 29], "attacker_act": [0, 27, 29], "defender_act": [0, 27, 29], "observ": [0, 9, 11, 12, 22, 27, 29], "return": [0, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], "state": [0, 8, 11, 12, 15, 16, 17, 20, 21, 22, 25, 26, 27, 29], "time_horizon": [0, 27, 29], "time_step": [0, 27, 29], "fictitious_plai": [0, 1, 10, 27, 29], "payoff_matrix": [0, 27, 29], "player_1_prior": [0, 27, 29], "player_2_prior": [0, 27, 29], "action_spac": [0, 27, 29], "epsilon": [0, 11, 12, 17, 20, 24, 27, 29], "initial_belief": [0, 27, 29], "initial_belief_valu": [0, 27, 29], "lb_size": [0, 27, 29], "number_of_simul": [0, 11, 27, 29], "observation_spac": [0, 27, 29], "observation_tensor": [0, 27, 29], "prune_frequ": [0, 11, 12, 27, 29], "reward_tensor": [0, 27, 29], "simulate_horizon": [0, 11, 27, 29], "simulation_frequ": [0, 11, 27, 29], "state_spac": [0, 27, 29], "transition_tensor": [0, 27, 29], "ub_siz": [0, 27, 29], "use_lp": [0, 27, 29], "width": [0, 1, 11, 12, 27, 29], "action_space_player_1": [0, 27, 29], "action_space_player_2": [0, 27, 29], "excess": [0, 1, 11, 12, 27, 29], "observation_funct": [0, 27, 29], "delta": [0, 12, 13, 18, 25, 27, 29], "gradient_batch_s": [0, 13, 24, 27, 29], "initial_alpha": [0, 27, 29], "local_dfsp": [0, 1, 6, 27, 29], "average_best_response_attacker_return": [0, 27, 29], "average_best_response_defender_return": [0, 27, 29], "best_response_evaluation_iter": [0, 27, 29], "equilibrium_strategies_evaluation_iter": [0, 27, 29], "n_2": [0, 27, 29], "running_average_best_response_attacker_return": [0, 27, 29], "running_average_best_response_defender_return": [0, 27, 29], "lp_for_nf_gam": [0, 27, 29], "initial_polici": [0, 27, 29], "num_act": [0, 11, 12, 15, 17, 20, 25, 27, 29], "num_stat": [0, 11, 12, 15, 17, 20, 25, 27, 29], "clip_rang": [0, 27, 29], "clip_range_vf": [0, 27, 29], "ent_coef": [0, 27, 29], "gae_lambda": [0, 27, 29], "steps_between_upd": [0, 27, 29], "target_kl": [0, 27, 29], "vf_coef": [0, 27, 29], "A": [0, 8, 10, 11, 12, 14, 16, 17, 20, 21, 24, 26, 27, 29], "initial_state_valu": [0, 27, 29], "": [0, 11, 12, 17, 19, 20, 21, 22, 26, 27, 29], "clip_gradi": [0, 27, 29], "num_alpha_vector": [0, 27, 29], "planning_horizon": [0, 27, 29], "use_prun": [0, 22, 27, 29], "attacker_threshold": [0, 23, 27, 29], "defender_threshold": [0, 6, 23, 27, 29], "theta1_attack": [0, 27, 29], "theta1_defend": [0, 27, 29], "job_control": [0, 29, 30], "training_job_manag": [0, 29, 30], "trainingjobmanag": [0, 28, 29], "run_training_job": [0, 28, 29], "start_training_job_in_background": [0, 28, 29], "baseag": [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 29], "hparam_nam": [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 29], "train": [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29], "bayesoptag": [1, 4, 29], "compute_avg_metr": [1, 4, 5, 6, 7, 10, 13, 14, 18, 19, 23, 24, 29], "eval_theta": [1, 4, 5, 7, 13, 18, 24, 29], "get_polici": [1, 4, 5, 7, 13, 18, 24, 29], "get_theta_vector_from_param_dict": [1, 4, 29], "initial_theta": [1, 4, 5, 7, 13, 18, 24, 29], "round_vec": [1, 4, 5, 6, 7, 10, 13, 14, 18, 19, 23, 24, 29], "update_metr": [1, 4, 5, 6, 7, 10, 13, 14, 18, 19, 23, 24, 29], "crossentropyag": [1, 5, 29], "dfsplocalag": [1, 6, 29], "attacker_best_respons": [1, 6, 23, 29], "defender_best_respons": [1, 6, 23, 29], "evaluate_attacker_polici": [1, 6, 23, 29], "evaluate_defender_polici": [1, 6, 23, 29], "evaluate_strategy_profil": [1, 6, 23, 29], "reduce_r": [1, 6, 29], "reduce_t": [1, 6, 29], "dfsplocalppoag": [1, 6, 29], "get_attacker_experiment_config": [1, 6, 23, 29], "get_defender_experiment_config": [1, 6, 23, 29], "differentialevolutionag": [1, 7, 29], "ensure_bound": [1, 7, 29], "dqnagent": [1, 8, 29], "dqntrainingcallback": [1, 8, 29], "datacollectorprocess": [1, 9, 29], "run": [1, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29], "dynasecag": [1, 9, 29], "get_z_from_system_model": [1, 9, 29], "get_spsa_experiment_config": [1, 9, 29], "mean": [1, 9, 22, 29], "record_metr": [1, 9, 29], "emulationmonitorthread": [1, 9, 29], "emulationstatisticsthread": [1, 9, 29], "policyevaluationthread": [1, 9, 29], "eval_trac": [1, 9, 29], "policyoptimizationprocess": [1, 9, 29], "systemidentificationprocess": [1, 9, 29], "fictitiousplayag": [1, 10, 29], "best_respons": [1, 10, 29], "compute_empirical_strategi": [1, 10, 29], "hsviagent": [1, 11, 29], "approximate_projection_sawtooth": [1, 11, 29], "bayes_filt": [1, 11, 12, 29], "explor": [1, 11, 12, 17, 20, 29], "generate_corner_belief": [1, 11, 12, 29], "hsvi_algorithm": [1, 11, 29], "initialize_lower_bound": [1, 11, 12, 29], "initialize_upper_bound": [1, 11, 12, 29], "interior_point_belief_v": [1, 11, 29], "local_lower_bound_upd": [1, 11, 12, 29], "local_upd": [1, 11, 12, 29], "local_upper_bound_upd": [1, 11, 12, 29], "lower_bound_backup": [1, 11, 12, 29], "lower_bound_valu": [1, 11, 12, 29], "lp_convex_hull_projection_lp": [1, 11, 29], "next_belief": [1, 11, 12, 29], "observation_poss": [1, 11, 29], "one_step_lookahead": [1, 11, 12, 25, 29], "p_o_given_b_a": [1, 11, 29], "prune_upper_bound": [1, 11, 12, 29], "q": [1, 11, 17, 20, 26, 27, 29], "q_hat_interv": [1, 11, 29], "simul": [1, 4, 5, 7, 11, 13, 18, 22, 24, 29], "update_corner_point": [1, 11, 29], "upper_bound_backup": [1, 11, 12, 29], "upper_bound_valu": [1, 11, 12, 29], "hsviosposgag": [1, 12, 29], "auxillary_gam": [1, 12, 21, 29], "choose_a_o_for_explor": [1, 12, 29], "combine_weights_and_pure_strategies_into_mixed_strategi": [1, 12, 29], "compute_delta": [1, 12, 29], "compute_equilibrium_strategies_in_matrix_gam": [1, 12, 14, 29], "compute_matrix_game_valu": [1, 12, 14, 21, 29], "delta_lipschitz_envelope_of_upper_bound_valu": [1, 12, 29], "maxcomp_shapley_bellman_oper": [1, 12, 29], "mdp_reward_matrix_p2": [1, 12, 29], "mdp_transition_tensor_p2": [1, 12, 29], "obtain_equilibrium_strategy_profiles_in_stage_gam": [1, 12, 29], "p_o_given_b_a1_a2": [1, 12, 29], "p_o_given_b_pi_1_pi_2": [1, 12, 29], "rho": [1, 12, 29], "sample_d": [1, 12, 29], "si": [1, 12, 21, 29], "valcomp": [1, 12, 29], "value_of_p1_strategy_stat": [1, 12, 29], "weighted_excess_gap": [1, 12, 29], "kieferwolfowitzag": [1, 13, 29], "batch_gradi": [1, 13, 24, 29], "estimate_gk": [1, 13, 24, 29], "linearprogrammingnormalformgameag": [1, 14, 29], "linear_programming_normal_form": [1, 14, 29], "piagent": [1, 15, 29], "evaluate_polici": [1, 15, 17, 20, 22, 25, 29], "expected_reward_under_polici": [1, 15, 29], "policy_evalu": [1, 15, 29], "policy_improv": [1, 15, 29], "policy_iter": [1, 15, 29], "transition_probability_under_polici": [1, 15, 29], "ppoagent": [1, 16, 29], "ppotrainingcallback": [1, 16, 29], "qlearningag": [1, 17, 29], "create_policy_from_q_t": [1, 17, 20, 29], "eps_greedi": [1, 17, 20, 29], "initialize_count_t": [1, 17, 20, 29], "initialize_q_t": [1, 17, 20, 29], "q_learning_upd": [1, 17, 29], "step_siz": [1, 17, 20, 29], "train_q_learn": [1, 17, 29], "randomsearchag": [1, 18, 29], "random_perturb": [1, 18, 29], "reinforceag": [1, 19, 29], "training_step": [1, 19, 29], "sarsaag": [1, 20, 29], "sarsa_upd": [1, 20, 29], "train_sarsa": [1, 20, 29], "shapleyiterationag": [1, 21, 29], "sondikviag": [1, 22, 29], "compute_all_conditional_plans_conditioned_on_a_t": [1, 22, 29], "sondik_vi_algorithm": [1, 22, 29], "tfpagent": [1, 23, 29], "tspsaagent": [1, 24, 29], "spsa": [1, 9, 24, 29], "standard_ak": [1, 24, 29], "standard_ck": [1, 24, 29], "standard_deltak": [1, 24, 29], "viagent": [1, 25, 29], "create_policy_from_value_funct": [1, 25, 29], "value_iter": [1, 25, 29], "class": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], "simulation_env_config": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25], "simulationenvconfig": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], "emulation_env_config": [2, 4, 5, 6, 7, 8, 9, 10, 13, 14, 16, 18, 19, 23, 24], "union": [2, 4, 5, 6, 7, 8, 10, 13, 14, 16, 18, 19, 23, 24], "none": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28], "emulationenvconfig": [2, 4, 5, 6, 7, 8, 9, 10, 13, 14, 16, 18, 19, 23, 24], "experiment_config": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], "experimentconfig": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], "sourc": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], "abc": 2, "abstract": 2, "repres": [2, 11, 12, 27], "an": [2, 9, 11, 12, 15, 17, 20, 21, 22, 25], "rl": [2, 6, 13, 23, 24], "list": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26], "str": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26], "method": [2, 4, 5, 7, 9, 13], "implement": [2, 6, 8, 11, 12, 13, 15, 16, 23, 24, 25, 26], "subclass": 2, "get": [2, 4, 5, 7, 8, 9, 13, 18, 24], "hyperparamet": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], "experimentexecut": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], "should": [2, 21, 22], "contain": [2, 22], "logic": [2, 6, 8], "result": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], "env": [4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25], "option": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], "training_job": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28], "trainingjobconfig": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28], "save_to_metastor": [4, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25], "bool": [4, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26], "true": [4, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26], "bayesian": [4, 11, 12, 27], "exp_result": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], "experimentresult": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], "seed": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], "int": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26], "random_se": [4, 5, 6, 7, 8, 10, 13, 14, 16, 18, 19, 23, 24], "algorithm": [4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27], "paramet": [4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28], "experi": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25], "object": [4, 5, 7, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 24, 25, 27, 28], "store": [4, 5, 7, 10, 13, 14, 18, 19, 24], "job": [4, 5, 6, 7, 10, 13, 14, 18, 19, 23, 24, 28], "config": [4, 5, 7, 10, 13, 14, 18, 19, 24], "updat": [4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25], "polici": [4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 22, 23, 24, 25], "static": [4, 5, 6, 7, 9, 10, 12, 13, 14, 18, 19, 23, 24, 28], "metric": [4, 5, 6, 7, 9, 10, 13, 14, 18, 19, 23, 24, 27], "dict": [4, 5, 6, 7, 9, 10, 13, 14, 18, 19, 23, 24], "float": [4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], "comput": [4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25], "averag": [4, 5, 6, 7, 10, 13, 14, 17, 18, 19, 20, 23, 24], "aggreg": [4, 5, 6, 7, 10, 13, 14, 18, 19, 23, 24], "multithresholdstoppingpolici": [4, 5, 7, 13, 18, 24], "linearthresholdstoppingpolici": [4, 5, 7, 13, 18, 24], "max_step": [4, 5, 7, 8, 9, 13, 16, 18, 24], "200": [4, 5, 7, 13, 18, 24], "evalu": [4, 5, 6, 7, 9, 12, 13, 15, 17, 18, 20, 22, 23, 24, 25], "given": [4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 18, 19, 23, 24, 26, 28], "mont": [4, 5, 6, 7, 13, 18, 23, 24], "carlo": [4, 5, 6, 7, 13, 18, 23, 24], "util": [4, 5, 7, 9, 12, 13, 15], "vector": [4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 18, 19, 22, 23, 24, 26], "number": [4, 5, 6, 7, 9, 11, 12, 13, 15, 17, 18, 20, 21, 22, 23, 24, 25, 26], "param_dict": 4, "extract": 4, "from": [4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 16, 17, 18, 19, 20, 23, 24, 25], "name": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], "ndarrai": [4, 5, 7, 9, 10, 11, 12, 13, 14, 15, 17, 18, 20, 21, 24, 25, 26], "initi": [4, 5, 7, 11, 12, 13, 17, 18, 20, 22, 24], "randomli": [4, 5, 7, 13, 18, 24, 26], "dimens": [4, 5, 7, 13, 15, 18, 24, 26], "vec": [4, 5, 6, 7, 10, 13, 14, 18, 19, 23, 24], "round": [4, 5, 6, 7, 10, 13, 14, 18, 19, 23, 24], "3": [4, 5, 6, 7, 8, 10, 13, 14, 16, 18, 19, 23, 24, 27], "decim": [4, 5, 6, 7, 10, 13, 14, 18, 19, 23, 24], "perform": [4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 18, 19, 23, 24, 25], "random": [4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27], "us": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 26], "info": [4, 5, 6, 7, 10, 13, 14, 18, 19, 23, 24], "new": [4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 18, 19, 23, 24], "inform": [4, 5, 6, 7, 10, 13, 14, 18, 19, 23, 24], "environ": [4, 5, 6, 7, 10, 13, 14, 18, 19, 23, 24, 27], "cross": [5, 27], "entropi": [5, 27], "defender_simulation_env_config": [6, 23], "attacker_simulation_env_config": [6, 23], "ppo_experiment_config": 6, "de_experiment_config": 6, "vi_experiment_config": 6, "local": [6, 11, 12, 27], "dfsp": [6, 27], "defender_strategi": [6, 23], "mixedppopolici": 6, "attacker_strategi": [6, 23], "tupl": [6, 9, 10, 11, 12, 14, 15, 17, 20, 21, 22, 23, 25], "ppopolici": 6, "learn": [6, 9, 17, 20, 23, 27], "best": [6, 10, 12, 23], "respons": [6, 10, 12, 23], "strategi": [6, 10, 12, 14, 17, 20, 21, 23], "attack": [6, 23, 27], "against": [6, 10, 12, 23, 26], "defend": [6, 9, 13, 23, 24, 27], "game": [6, 10, 12, 14, 21, 23, 27], "valu": [6, 10, 11, 12, 14, 15, 17, 20, 21, 22, 23, 25], "reward": [6, 11, 12, 15, 17, 19, 20, 21, 22, 23, 25], "lineartabularpolici": 6, "follow": [6, 12, 22, 23], "profil": [6, 12, 14, 23], "attacker_v": [6, 23], "defender_v": [6, 23], "when": [6, 11, 12, 23], "current": [6, 9, 11, 12, 13, 15, 18, 23, 24, 25, 26], "x": [6, 12, 15, 23, 26], "calcul": [6, 17, 20, 23], "last": [6, 23], "element": [6, 22, 23], "r": [6, 11, 12, 15, 17, 20, 21, 22, 25, 27], "reduc": 6, "tensor": [6, 9, 11, 12, 15, 19, 21, 26], "reduct": 6, "t": [6, 9, 11, 12, 21, 22, 23, 24, 25, 27], "transit": [6, 11, 12, 15, 21, 22, 25], "configur": [6, 9, 23, 28], "differenti": [7, 27], "evolut": [7, 27], "function": [7, 9, 11, 12, 15, 21, 25, 26], "ensur": [7, 12], "openai": [8, 16], "baselin": [8, 9, 16], "exp_execut": [8, 16], "simulation_nam": [8, 16], "action": [8, 10, 11, 12, 14, 15, 16, 17, 19, 20, 21, 22, 25], "player_typ": [8, 16], "playertyp": [8, 16], "verbos": [8, 12, 16], "0": [8, 9, 11, 12, 16, 17, 20, 21, 22, 25], "100": [8, 16], "10": [8, 11, 12, 16], "save_dir": [8, 16], "gym_env_nam": [8, 16], "basecallback": [8, 16], "callback": [8, 16], "monitor": [8, 16], "emulation_execut": 9, "emulationexecut": 9, "attacker_sequ": 9, "emulationattackeract": 9, "defender_sequ": 9, "emulationdefenderact": 9, "worker_id": 9, "emulation_statistics_window": 9, "emulationstatisticswindow": 9, "30": 9, "emulation_traces_to_save_with_data_collection_job": [9, 27], "1": [9, 11, 12, 13, 14, 15, 21, 22, 24, 25], "thread": 9, "process": [9, 16], "interact": 9, "emul": 9, "execut": 9, "gener": [9, 11, 12, 26], "data": [9, 26], "system_identification_config": 9, "systemidentificationconfig": 9, "The": [9, 11, 12, 15, 22], "system_model": 9, "gaussianmixturesystemmodel": 9, "sample_spac": 9, "system": [9, 15], "model": [9, 26], "sampl": [9, 12, 17, 20], "space": [9, 11, 12, 17, 20], "prob_vector": 9, "probabl": [9, 11, 12, 15, 19, 22, 25], "take": [9, 11, 12], "metrics_dict": 9, "record": 9, "import": 9, "them": 9, "sleep_time_minut": 9, "collect": 9, "data_collector_process": 9, "track": 9, "statist": 9, "baseline_polici": 9, "emulation_statistics_thread": 9, "baseline_system_model": 9, "period": 9, "trace": 9, "emulationtrac": 9, "defender_polici": 9, "fals": [9, 11, 12, 16, 26], "maximum": [9, 12, 21], "step": [9, 11, 12, 13, 15, 17, 18, 19, 20, 24, 25], "boolean": [9, 11, 12, 14, 21], "flag": [9, 11, 12, 14, 21], "indic": [9, 21], "whether": [9, 10, 11, 12, 14, 21, 22, 26], "i": [9, 10, 11, 12, 15, 22, 26], "being": [9, 11, 12], "eval": 9, "recor": 9, "indici": 9, "ar": [9, 12], "through": [9, 12, 24], "emulation_statist": 9, "emulationstatist": 9, "collector": 9, "estim": [9, 11, 13, 23, 24], "fictiti": [10, 27], "plai": [10, 12, 27], "normal": [10, 14, 27], "form": [10, 14, 22, 27], "brown": 10, "1951": 10, "p": [10, 11, 12, 15, 19, 22], "maxim": [10, 12, 14, 21], "oppon": [10, 12], "payoff": 10, "matrix": [10, 12, 14, 15, 21, 22], "player": [10, 12, 14, 21], "minim": [10, 12, 14], "its": [10, 23], "count": [10, 17, 20], "empir": 10, "heurist": [11, 12], "search": [11, 12, 18, 19, 27], "iter": [11, 12, 13, 15, 17, 20, 21, 22, 24, 25, 27], "pomdp": [11, 12, 22, 27], "trei": [11, 12], "smith": [11, 12], "reid": [11, 12], "simmon": [11, 12], "2004": [11, 12], "upper_bound": [11, 12], "b": [11, 12], "refer": 11, "hauskreht": 11, "2000": 11, "approxim": 11, "project": 11, "belief": [11, 12, 22], "onto": 11, "convex": [11, 12], "hull": [11, 12], "upepr": 11, "upper": [11, 12], "point": [11, 12], "set": [11, 12, 14, 21, 22, 26], "s_prime": [11, 12, 17, 20], "o": [11, 12, 22, 27], "z": [11, 12, 22], "filter": [11, 12, 22, 26], "after": [11, 12, 15], "b_prime": [11, 12], "lower_bound": [11, 12, 26], "lp": [11, 12, 14, 26], "uncertainti": 11, "lower": [11, 12, 26], "accuraci": [11, 12], "discount": [11, 12, 15, 17, 19, 20, 21, 22, 25], "factor": [11, 12, 15, 17, 19, 20, 21, 22, 25], "depth": [11, 12], "tree": [11, 12], "corner": [11, 12], "simplex": [11, 12], "correspond": [11, 12], "some": [11, 12, 26], "b0": [11, 12, 22], "sawtooth": 11, "how": [11, 12], "often": [11, 12], "frequent": 11, "compur": 11, "length": 11, "interior_point": 11, "alpha_corn": 11, "induc": [11, 12, 22], "interior": 11, "alpha": [11, 12, 22, 26], "v": [11, 12, 15, 21, 22, 25], "dure": [11, 12], "solv": [11, 12, 15], "next": [11, 12, 17, 20, 25], "latest": [11, 12, 19], "check": [11, 22, 26], "can": [11, 12, 26], "aciton": [11, 12, 21], "tocheck": 11, "possibl": [11, 12, 22], "otherwis": [11, 26], "fasl": 11, "discount_factor": [11, 12, 25], "one": [11, 12, 25], "lookahead": [11, 12, 25], "kernel": [11, 12, 25], "tabl": [11, 12, 17, 20, 25], "next_state_lookahead": [11, 12, 25], "arrai": [11, 12, 25], "decid": [11, 12], "appli": 11, "bellman": [11, 12], "equat": [11, 12], "interv": [11, 12], "horizon": [11, 22], "greedi": [11, 12, 17, 20, 25], "respect": [11, 12], "which": [11, 12], "oper": [11, 12, 25], "cumul": 11, "corner_point": 11, "new_point": 11, "mayb": 11, "add": [11, 12], "0001": [11, 12, 25], "state_to_id": [11, 12, 25], "id": [11, 12, 25], "lookup": [11, 12, 25], "hp": [11, 12, 25], "hack": [11, 12, 25], "converg": [11, 12, 15, 25], "posg": [12, 27], "a1": [12, 14, 20, 21, 27], "a2": [12, 14, 21, 27], "creat": [12, 17, 20, 21, 25, 26], "auxillari": [12, 21], "2": [12, 14, 17, 20, 21, 22, 26], "pi_2": 12, "pi_1_upper_bound": 12, "pi_2_lower_bound": 12, "d": 12, "select": [12, 15, 17, 20], "accord": [12, 17, 20], "argmax_": 12, "b_1": 12, "a_1": 12, "hor\u00e1k": 12, "bosanski": 12, "kova\u0159\u00edk": 12, "kiekintveld": 12, "2020": 12, "time": 12, "equilibrium": [12, 14], "stage": [12, 21], "construct": 12, "lipschitz": 12, "continu": 12, "neighboorhood": 12, "weighted_excess": 12, "weight": [12, 19], "mixtur": 12, "mix": 12, "To": 12, "prove": 12, "we": 12, "requir": 12, "v_ub": 12, "v_lb": 12, "well": 12, "thi": 12, "specif": 12, "u": 12, "where": [12, 15, 22], "teh": 12, "ani": [12, 14], "also": [12, 14], "maximin": [12, 14, 21], "minimax": [12, 14, 21], "val": [12, 14, 21], "envelop": 12, "gap": 12, "horak": 12, "pechoucek": 12, "2017": 12, "neighborhood": 12, "p1": 12, "p2": 12, "zero": 12, "sum": 12, "achiev": 12, "each": [12, 15, 22], "shaplei": [12, 21, 27], "uniform": 12, "singleton": 12, "fulli": 12, "version": 12, "preserv": 12, "properti": 12, "dear": 12, "child": 12, "mani": 12, "maxcomp": 12, "hv": 12, "pointwis": 12, "over": 12, "By": 12, "solut": 12, "found": 12, "e": 12, "whole": 12, "purpos": 12, "abl": [12, 26], "linear": [12, 14, 15, 27], "program": [12, 14, 15, 27], "karel": 12, "phd": 12, "thesi": 12, "2019": 12, "That": 12, "backup": 12, "exact": 12, "behavior": 12, "combin": [12, 22], "p1_strategi": 12, "fix": 12, "mdp": [12, 15, 17, 20, 27], "pi_1": 12, "tri": 12, "keep": 12, "between": 12, "most": 12, "monoton": 12, "increas": 12, "unbound": 12, "lipshitz": 12, "legal": 12, "rang": 12, "sequenc": 12, "need": 12, "2delta": 12, "max_iter": [12, 21], "500": [12, 21], "delta_threshold": [12, 21], "log": [12, 19], "1953": [12, 21], "sg": [12, 21], "stop": [12, 13, 21, 24, 27], "all": [12, 15, 21, 22, 27], "themselv": [12, 21], "alpha_bar": 12, "substituted_alpha": 12, "composit": 12, "consist": 12, "distribut": 12, "expect": [12, 15], "c": [12, 24], "sigma_1": 12, "It": [12, 22], "assum": [12, 15], "further": 12, "sinc": 12, "subsequ": 12, "subgam": 12, "treat": 12, "independ": 12, "For": 12, "exampl": 12, "kiefer": [13, 27], "wolfowitz": [13, 27], "sa": [13, 17, 20], "50": 13, "batch": [13, 15, 17, 20, 22, 24, 25], "gradient": [13, 24], "ck": [13, 24], "perturb": [13, 18, 24], "size": [13, 15, 17, 18, 20, 22, 24, 25], "total": [13, 24], "includ": [13, 24], "evalut": [15, 17, 20, 22, 25], "tabular": [15, 17, 20, 22, 25], "immedi": [15, 22], "interleav": 15, "improv": 15, "guarante": 15, "scalar": [15, 24], "dynam": [15, 23], "algebra": 15, "interpret": [15, 26], "old": 15, "pi_prim": 15, "under": 15, "determinist": 15, "p_pi": 15, "start": [16, 28], "q_tabl": [17, 20], "n_state": [17, 20, 22], "256": [17, 20], "n_action": [17, 20, 22], "5": [17, 20], "count_tabl": [17, 20], "watkin": 17, "determin": [17, 20], "8": [17, 20], "10000": [17, 20], "saved_reward": 19, "saved_log_prob": 19, "policy_network": 19, "fnnwithsoftmax": 19, "encount": 19, "episod": 19, "trajectori": 19, "network": [19, 26], "loss": 19, "eaction": 20, "sondik": [22, 27], "1971": 22, "av": [22, 26], "alreadi": [22, 26], "n_alpha_vectors_t_plus_on": 22, "n_ob": 22, "condit": 22, "plan": 22, "produc": 22, "conditional_plan": 22, "n_alpha_vector": 22, "_i": 22, "_j": 22, "_k": 22, "o_i": 22, "o_j": 22, "o_k": 22, "alphavectorspolici": 22, "aleph": 22, "remov": 22, "domin": [22, 26], "lark": [22, 26], "hammar": [23, 24], "stadler": [23, 24], "23": 23, "Near": 23, "intrus": [23, 24], "mixedmultithresholdstoppingpolici": 23, "2023": 23, "2021": 24, "prevent": 24, "deltak": 24, "direct": 24, "ascent": 24, "index": 24, "a_k": 24, "lambda": 24, "pertrub": 24, "delta_k": 24, "input_dim": 26, "output_dim": 26, "hidden_dim": 26, "num_hidden_lay": 26, "hidden_activ": 26, "relu": 26, "fnn": 26, "gaussian": 26, "output": 26, "parameteriz": 26, "layer": 26, "hidden": 26, "activ": 26, "sub": 26, "torch": 26, "nn": 26, "high": 26, "level": 26, "api": 26, "custom": 26, "propag": 26, "input": 26, "predict": 26, "basic": 26, "case": 26, "verifi": 26, "fit": 26, "alpha_vec": 26, "cassandra": 26, "littman": 26, "zhang": 26, "1997": 26, "alpha_set": 26, "csle": [27, 28], "string": 27, "relat": 27, "among": 27, "baseline_": 27, "eval_": 27, "v1": 27, "exploration_fracion": 27, "mlppolici": 27, "lower_bound_s": 27, "upper_bound_s": 27, "manag": 28, "job_config": 28, "background": 28, "packag": 30, "subpackag": 30, "modul": 30, "content": 30}, "objects": {"": [[29, 0, 0, "-", "csle_agents"]], "csle_agents": [[1, 0, 0, "-", "agents"], [26, 0, 0, "-", "common"], [27, 0, 0, "-", "constants"], [28, 0, 0, "-", "job_controllers"]], "csle_agents.agents": [[2, 0, 0, "-", "base"], [4, 0, 0, "-", "bayesian_optimization"], [5, 0, 0, "-", "cross_entropy"], [6, 0, 0, "-", "dfsp_local"], [7, 0, 0, "-", "differential_evolution"], [8, 0, 0, "-", "dqn"], [9, 0, 0, "-", "dynasec"], [10, 0, 0, "-", "fp"], [11, 0, 0, "-", "hsvi"], [12, 0, 0, "-", "hsvi_os_posg"], [13, 0, 0, "-", "kiefer_wolfowitz"], [14, 0, 0, "-", "lp_nf"], [15, 0, 0, "-", "pi"], [16, 0, 0, "-", "ppo"], [17, 0, 0, "-", "q_learning"], [18, 0, 0, "-", "random_search"], [19, 0, 0, "-", "reinforce"], [20, 0, 0, "-", "sarsa"], [21, 0, 0, "-", "shapley_iteration"], [22, 0, 0, "-", "sondik_vi"], [23, 0, 0, "-", "t_fp"], [24, 0, 0, "-", "t_spsa"], [25, 0, 0, "-", "vi"]], "csle_agents.agents.base": [[2, 0, 0, "-", "base_agent"]], "csle_agents.agents.base.base_agent": [[2, 1, 1, "", "BaseAgent"]], "csle_agents.agents.base.base_agent.BaseAgent": [[2, 2, 1, "", "hparam_names"], [2, 2, 1, "", "train"]], "csle_agents.agents.bayesian_optimization": [[4, 0, 0, "-", "bayes_opt_agent"]], "csle_agents.agents.bayesian_optimization.bayes_opt_agent": [[4, 1, 1, "", "BayesOptAgent"]], "csle_agents.agents.bayesian_optimization.bayes_opt_agent.BayesOptAgent": [[4, 2, 1, "", "bayesian_optimization"], [4, 2, 1, "", "compute_avg_metrics"], [4, 2, 1, "", "eval_theta"], [4, 2, 1, "", "get_policy"], [4, 2, 1, "", "get_theta_vector_from_param_dict"], [4, 2, 1, "", "hparam_names"], [4, 2, 1, "", "initial_theta"], [4, 2, 1, "", "round_vec"], [4, 2, 1, "", "train"], [4, 2, 1, "", "update_metrics"]], "csle_agents.agents.cross_entropy": [[5, 0, 0, "-", "cross_entropy_agent"]], "csle_agents.agents.cross_entropy.cross_entropy_agent": [[5, 1, 1, "", "CrossEntropyAgent"]], "csle_agents.agents.cross_entropy.cross_entropy_agent.CrossEntropyAgent": [[5, 2, 1, "", "compute_avg_metrics"], [5, 2, 1, "", "cross_entropy"], [5, 2, 1, "", "eval_theta"], [5, 2, 1, "", "get_policy"], [5, 2, 1, "", "hparam_names"], [5, 2, 1, "", "initial_theta"], [5, 2, 1, "", "round_vec"], [5, 2, 1, "", "train"], [5, 2, 1, "", "update_metrics"]], "csle_agents.agents.dfsp_local": [[6, 0, 0, "-", "dfsp_local_agent"], [6, 0, 0, "-", "dfsp_local_ppo_agent"]], "csle_agents.agents.dfsp_local.dfsp_local_agent": [[6, 1, 1, "", "DFSPLocalAgent"], [6, 3, 1, "", "reduce_R"], [6, 3, 1, "", "reduce_T"]], "csle_agents.agents.dfsp_local.dfsp_local_agent.DFSPLocalAgent": [[6, 2, 1, "", "attacker_best_response"], [6, 2, 1, "", "compute_avg_metrics"], [6, 2, 1, "", "defender_best_response"], [6, 2, 1, "", "evaluate_attacker_policy"], [6, 2, 1, "", "evaluate_defender_policy"], [6, 2, 1, "", "evaluate_strategy_profile"], [6, 2, 1, "", "exploitability"], [6, 2, 1, "", "hparam_names"], [6, 2, 1, "", "local_dfsp"], [6, 2, 1, "", "round_vec"], [6, 2, 1, "", "running_average"], [6, 2, 1, "", "train"], [6, 2, 1, "", "update_metrics"]], "csle_agents.agents.dfsp_local.dfsp_local_ppo_agent": [[6, 1, 1, "", "DFSPLocalPPOAgent"]], "csle_agents.agents.dfsp_local.dfsp_local_ppo_agent.DFSPLocalPPOAgent": [[6, 2, 1, "", "attacker_best_response"], [6, 2, 1, "", "compute_avg_metrics"], [6, 2, 1, "", "defender_best_response"], [6, 2, 1, "", "evaluate_attacker_policy"], [6, 2, 1, "", "evaluate_defender_policy"], [6, 2, 1, "", "evaluate_strategy_profile"], [6, 2, 1, "", "exploitability"], [6, 2, 1, "", "get_attacker_experiment_config"], [6, 2, 1, "", "get_defender_experiment_config"], [6, 2, 1, "", "hparam_names"], [6, 2, 1, "", "local_dfsp"], [6, 2, 1, "", "round_vec"], [6, 2, 1, "", "running_average"], [6, 2, 1, "", "train"], [6, 2, 1, "", "update_metrics"]], "csle_agents.agents.differential_evolution": [[7, 0, 0, "-", "differential_evolution_agent"]], "csle_agents.agents.differential_evolution.differential_evolution_agent": [[7, 1, 1, "", "DifferentialEvolutionAgent"]], "csle_agents.agents.differential_evolution.differential_evolution_agent.DifferentialEvolutionAgent": [[7, 2, 1, "", "compute_avg_metrics"], [7, 2, 1, "", "differential_evolution"], [7, 2, 1, "", "ensure_bounds"], [7, 2, 1, "", "eval_theta"], [7, 2, 1, "", "get_policy"], [7, 2, 1, "", "hparam_names"], [7, 2, 1, "", "initial_theta"], [7, 2, 1, "", "round_vec"], [7, 2, 1, "", "train"], [7, 2, 1, "", "update_metrics"]], "csle_agents.agents.dqn": [[8, 0, 0, "-", "dqn_agent"]], "csle_agents.agents.dqn.dqn_agent": [[8, 1, 1, "", "DQNAgent"], [8, 1, 1, "", "DQNTrainingCallback"]], "csle_agents.agents.dqn.dqn_agent.DQNAgent": [[8, 2, 1, "", "hparam_names"], [8, 2, 1, "", "train"]], "csle_agents.agents.dynasec": [[9, 0, 0, "-", "dynasec_agent"]], "csle_agents.agents.dynasec.dynasec_agent": [[9, 1, 1, "", "DataCollectorProcess"], [9, 1, 1, "", "DynaSecAgent"], [9, 1, 1, "", "EmulationMonitorThread"], [9, 1, 1, "", "EmulationStatisticsThread"], [9, 1, 1, "", "PolicyEvaluationThread"], [9, 1, 1, "", "PolicyOptimizationProcess"], [9, 1, 1, "", "SystemIdentificationProcess"]], "csle_agents.agents.dynasec.dynasec_agent.DataCollectorProcess": [[9, 2, 1, "", "run"]], "csle_agents.agents.dynasec.dynasec_agent.DynaSecAgent": [[9, 2, 1, "", "get_Z_from_system_model"], [9, 2, 1, "", "get_spsa_experiment_config"], [9, 2, 1, "", "hparam_names"], [9, 2, 1, "", "mean"], [9, 2, 1, "", "record_metrics"], [9, 2, 1, "", "train"]], "csle_agents.agents.dynasec.dynasec_agent.EmulationMonitorThread": [[9, 2, 1, "", "run"]], "csle_agents.agents.dynasec.dynasec_agent.EmulationStatisticsThread": [[9, 2, 1, "", "run"]], "csle_agents.agents.dynasec.dynasec_agent.PolicyEvaluationThread": [[9, 2, 1, "", "eval_traces"], [9, 2, 1, "", "record_metrics"], [9, 2, 1, "", "run"]], "csle_agents.agents.dynasec.dynasec_agent.PolicyOptimizationProcess": [[9, 2, 1, "", "run"]], "csle_agents.agents.dynasec.dynasec_agent.SystemIdentificationProcess": [[9, 2, 1, "", "run"]], "csle_agents.agents.fp": [[10, 0, 0, "-", "fictitious_play_agent"]], "csle_agents.agents.fp.fictitious_play_agent": [[10, 1, 1, "", "FictitiousPlayAgent"]], "csle_agents.agents.fp.fictitious_play_agent.FictitiousPlayAgent": [[10, 2, 1, "", "best_response"], [10, 2, 1, "", "compute_avg_metrics"], [10, 2, 1, "", "compute_empirical_strategy"], [10, 2, 1, "", "fictitious_play"], [10, 2, 1, "", "hparam_names"], [10, 2, 1, "", "round_vec"], [10, 2, 1, "", "train"], [10, 2, 1, "", "update_metrics"]], "csle_agents.agents.hsvi": [[11, 0, 0, "-", "hsvi_agent"]], "csle_agents.agents.hsvi.hsvi_agent": [[11, 1, 1, "", "HSVIAgent"]], "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent": [[11, 2, 1, "", "approximate_projection_sawtooth"], [11, 2, 1, "", "bayes_filter"], [11, 2, 1, "", "excess"], [11, 2, 1, "", "explore"], [11, 2, 1, "", "generate_corner_belief"], [11, 2, 1, "", "hparam_names"], [11, 2, 1, "", "hsvi"], [11, 2, 1, "", "hsvi_algorithm"], [11, 2, 1, "", "initialize_lower_bound"], [11, 2, 1, "", "initialize_upper_bound"], [11, 2, 1, "", "interior_point_belief_val"], [11, 2, 1, "", "local_lower_bound_update"], [11, 2, 1, "", "local_updates"], [11, 2, 1, "", "local_upper_bound_update"], [11, 2, 1, "", "lower_bound_backup"], [11, 2, 1, "", "lower_bound_value"], [11, 2, 1, "", "lp_convex_hull_projection_lp"], [11, 2, 1, "", "next_belief"], [11, 2, 1, "", "observation_possible"], [11, 2, 1, "", "one_step_lookahead"], [11, 2, 1, "", "p_o_given_b_a"], [11, 2, 1, "", "prune_upper_bound"], [11, 2, 1, "", "q"], [11, 2, 1, "", "q_hat_interval"], [11, 2, 1, "", "simulate"], [11, 2, 1, "", "train"], [11, 2, 1, "", "update_corner_points"], [11, 2, 1, "", "upper_bound_backup"], [11, 2, 1, "", "upper_bound_value"], [11, 2, 1, "", "vi"], [11, 2, 1, "", "width"]], "csle_agents.agents.hsvi_os_posg": [[12, 0, 0, "-", "hsvi_os_posg_agent"]], "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent": [[12, 1, 1, "", "HSVIOSPOSGAgent"]], "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent": [[12, 2, 1, "", "auxillary_game"], [12, 2, 1, "", "bayes_filter"], [12, 2, 1, "", "choose_a_o_for_exploration"], [12, 2, 1, "", "combine_weights_and_pure_strategies_into_mixed_strategy"], [12, 2, 1, "", "compute_delta"], [12, 2, 1, "", "compute_equilibrium_strategies_in_matrix_game"], [12, 2, 1, "", "compute_matrix_game_value"], [12, 2, 1, "", "delta_lipschitz_envelope_of_upper_bound_value"], [12, 2, 1, "", "excess"], [12, 2, 1, "", "explore"], [12, 2, 1, "", "generate_corner_belief"], [12, 2, 1, "", "hparam_names"], [12, 2, 1, "", "hsvi"], [12, 2, 1, "", "hsvi_os_posg"], [12, 2, 1, "", "initialize_lower_bound"], [12, 2, 1, "", "initialize_upper_bound"], [12, 2, 1, "", "local_lower_bound_update"], [12, 2, 1, "", "local_updates"], [12, 2, 1, "", "local_upper_bound_update"], [12, 2, 1, "", "lower_bound_backup"], [12, 2, 1, "", "lower_bound_value"], [12, 2, 1, "", "maxcomp_shapley_bellman_operator"], [12, 2, 1, "", "mdp_reward_matrix_p2"], [12, 2, 1, "", "mdp_transition_tensor_p2"], [12, 2, 1, "", "next_belief"], [12, 2, 1, "", "obtain_equilibrium_strategy_profiles_in_stage_game"], [12, 2, 1, "", "one_step_lookahead"], [12, 2, 1, "", "p_o_given_b_a1_a2"], [12, 2, 1, "", "p_o_given_b_pi_1_pi_2"], [12, 2, 1, "", "prune_upper_bound"], [12, 2, 1, "", "rho"], [12, 2, 1, "", "sample_D"], [12, 2, 1, "", "si"], [12, 2, 1, "", "train"], [12, 2, 1, "", "upper_bound_backup"], [12, 2, 1, "", "upper_bound_value"], [12, 2, 1, "", "valcomp"], [12, 2, 1, "", "value_of_p1_strategy_static"], [12, 2, 1, "", "vi"], [12, 2, 1, "", "weighted_excess_gap"], [12, 2, 1, "", "width"]], "csle_agents.agents.kiefer_wolfowitz": [[13, 0, 0, "-", "kiefer_wolfowitz_agent"]], "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent": [[13, 1, 1, "", "KieferWolfowitzAgent"]], "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.KieferWolfowitzAgent": [[13, 2, 1, "", "batch_gradient"], [13, 2, 1, "", "compute_avg_metrics"], [13, 2, 1, "", "estimate_gk"], [13, 2, 1, "", "eval_theta"], [13, 2, 1, "", "get_policy"], [13, 2, 1, "", "hparam_names"], [13, 2, 1, "", "initial_theta"], [13, 2, 1, "", "kiefer_wolfowitz"], [13, 2, 1, "", "round_vec"], [13, 2, 1, "", "train"], [13, 2, 1, "", "update_metrics"]], "csle_agents.agents.lp_nf": [[14, 0, 0, "-", "linear_programming_normal_form_game_agent"]], "csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent": [[14, 1, 1, "", "LinearProgrammingNormalFormGameAgent"]], "csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.LinearProgrammingNormalFormGameAgent": [[14, 2, 1, "", "compute_avg_metrics"], [14, 2, 1, "", "compute_equilibrium_strategies_in_matrix_game"], [14, 2, 1, "", "compute_matrix_game_value"], [14, 2, 1, "", "hparam_names"], [14, 2, 1, "", "linear_programming_normal_form"], [14, 2, 1, "", "round_vec"], [14, 2, 1, "", "train"], [14, 2, 1, "", "update_metrics"]], "csle_agents.agents.pi": [[15, 0, 0, "-", "pi_agent"]], "csle_agents.agents.pi.pi_agent": [[15, 1, 1, "", "PIAgent"]], "csle_agents.agents.pi.pi_agent.PIAgent": [[15, 2, 1, "", "evaluate_policy"], [15, 2, 1, "", "expected_reward_under_policy"], [15, 2, 1, "", "hparam_names"], [15, 2, 1, "", "pi"], [15, 2, 1, "", "policy_evaluation"], [15, 2, 1, "", "policy_improvement"], [15, 2, 1, "", "policy_iteration"], [15, 2, 1, "", "train"], [15, 2, 1, "", "transition_probability_under_policy"]], "csle_agents.agents.ppo": [[16, 0, 0, "-", "ppo_agent"]], "csle_agents.agents.ppo.ppo_agent": [[16, 1, 1, "", "PPOAgent"], [16, 1, 1, "", "PPOTrainingCallback"]], "csle_agents.agents.ppo.ppo_agent.PPOAgent": [[16, 2, 1, "", "hparam_names"], [16, 2, 1, "", "train"]], "csle_agents.agents.q_learning": [[17, 0, 0, "-", "q_learning_agent"]], "csle_agents.agents.q_learning.q_learning_agent": [[17, 1, 1, "", "QLearningAgent"]], "csle_agents.agents.q_learning.q_learning_agent.QLearningAgent": [[17, 2, 1, "", "create_policy_from_q_table"], [17, 2, 1, "", "eps_greedy"], [17, 2, 1, "", "evaluate_policy"], [17, 2, 1, "", "hparam_names"], [17, 2, 1, "", "initialize_count_table"], [17, 2, 1, "", "initialize_q_table"], [17, 2, 1, "", "q_learning"], [17, 2, 1, "", "q_learning_update"], [17, 2, 1, "", "step_size"], [17, 2, 1, "", "train"], [17, 2, 1, "", "train_q_learning"]], "csle_agents.agents.random_search": [[18, 0, 0, "-", "random_search_agent"]], "csle_agents.agents.random_search.random_search_agent": [[18, 1, 1, "", "RandomSearchAgent"]], "csle_agents.agents.random_search.random_search_agent.RandomSearchAgent": [[18, 2, 1, "", "compute_avg_metrics"], [18, 2, 1, "", "eval_theta"], [18, 2, 1, "", "get_policy"], [18, 2, 1, "", "hparam_names"], [18, 2, 1, "", "initial_theta"], [18, 2, 1, "", "random_perturbation"], [18, 2, 1, "", "random_search"], [18, 2, 1, "", "round_vec"], [18, 2, 1, "", "train"], [18, 2, 1, "", "update_metrics"]], "csle_agents.agents.reinforce": [[19, 0, 0, "-", "reinforce_agent"]], "csle_agents.agents.reinforce.reinforce_agent": [[19, 1, 1, "", "ReinforceAgent"]], "csle_agents.agents.reinforce.reinforce_agent.ReinforceAgent": [[19, 2, 1, "", "compute_avg_metrics"], [19, 2, 1, "", "hparam_names"], [19, 2, 1, "", "reinforce"], [19, 2, 1, "", "round_vec"], [19, 2, 1, "", "train"], [19, 2, 1, "", "training_step"], [19, 2, 1, "", "update_metrics"]], "csle_agents.agents.sarsa": [[20, 0, 0, "-", "sarsa_agent"]], "csle_agents.agents.sarsa.sarsa_agent": [[20, 1, 1, "", "SARSAAgent"]], "csle_agents.agents.sarsa.sarsa_agent.SARSAAgent": [[20, 2, 1, "", "create_policy_from_q_table"], [20, 2, 1, "", "eps_greedy"], [20, 2, 1, "", "evaluate_policy"], [20, 2, 1, "", "hparam_names"], [20, 2, 1, "", "initialize_count_table"], [20, 2, 1, "", "initialize_q_table"], [20, 2, 1, "", "q_learning"], [20, 2, 1, "", "sarsa_update"], [20, 2, 1, "", "step_size"], [20, 2, 1, "", "train"], [20, 2, 1, "", "train_sarsa"]], "csle_agents.agents.shapley_iteration": [[21, 0, 0, "-", "shapley_iteration_agent"]], "csle_agents.agents.shapley_iteration.shapley_iteration_agent": [[21, 1, 1, "", "ShapleyIterationAgent"]], "csle_agents.agents.shapley_iteration.shapley_iteration_agent.ShapleyIterationAgent": [[21, 2, 1, "", "auxillary_game"], [21, 2, 1, "", "compute_matrix_game_value"], [21, 2, 1, "", "hparam_names"], [21, 2, 1, "", "shapley_iteration"], [21, 2, 1, "", "si"], [21, 2, 1, "", "train"]], "csle_agents.agents.sondik_vi": [[22, 0, 0, "-", "sondik_vi_agent"]], "csle_agents.agents.sondik_vi.sondik_vi_agent": [[22, 1, 1, "", "SondikVIAgent"]], "csle_agents.agents.sondik_vi.sondik_vi_agent.SondikVIAgent": [[22, 2, 1, "", "check_duplicate"], [22, 2, 1, "", "compute_all_conditional_plans_conditioned_on_a_t"], [22, 2, 1, "", "evaluate_policy"], [22, 2, 1, "", "hparam_names"], [22, 2, 1, "", "prune"], [22, 2, 1, "", "sondik_vi"], [22, 2, 1, "", "sondik_vi_algorithm"], [22, 2, 1, "", "train"]], "csle_agents.agents.t_fp": [[23, 0, 0, "-", "t_fp_agent"]], "csle_agents.agents.t_fp.t_fp_agent": [[23, 1, 1, "", "TFPAgent"]], "csle_agents.agents.t_fp.t_fp_agent.TFPAgent": [[23, 2, 1, "", "attacker_best_response"], [23, 2, 1, "", "compute_avg_metrics"], [23, 2, 1, "", "defender_best_response"], [23, 2, 1, "", "evaluate_attacker_policy"], [23, 2, 1, "", "evaluate_defender_policy"], [23, 2, 1, "", "evaluate_strategy_profile"], [23, 2, 1, "", "exploitability"], [23, 2, 1, "", "get_attacker_experiment_config"], [23, 2, 1, "", "get_defender_experiment_config"], [23, 2, 1, "", "hparam_names"], [23, 2, 1, "", "round_vec"], [23, 2, 1, "", "running_average"], [23, 2, 1, "", "t_fp"], [23, 2, 1, "", "train"], [23, 2, 1, "", "update_metrics"]], "csle_agents.agents.t_spsa": [[24, 0, 0, "-", "t_spsa_agent"]], "csle_agents.agents.t_spsa.t_spsa_agent": [[24, 1, 1, "", "TSPSAAgent"]], "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent": [[24, 2, 1, "", "batch_gradient"], [24, 2, 1, "", "compute_avg_metrics"], [24, 2, 1, "", "estimate_gk"], [24, 2, 1, "", "eval_theta"], [24, 2, 1, "", "get_policy"], [24, 2, 1, "", "hparam_names"], [24, 2, 1, "", "initial_theta"], [24, 2, 1, "", "round_vec"], [24, 2, 1, "", "spsa"], [24, 2, 1, "", "standard_ak"], [24, 2, 1, "", "standard_ck"], [24, 2, 1, "", "standard_deltak"], [24, 2, 1, "", "train"], [24, 2, 1, "", "update_metrics"]], "csle_agents.agents.vi": [[25, 0, 0, "-", "vi_agent"]], "csle_agents.agents.vi.vi_agent": [[25, 1, 1, "", "VIAgent"]], "csle_agents.agents.vi.vi_agent.VIAgent": [[25, 2, 1, "", "create_policy_from_value_function"], [25, 2, 1, "", "evaluate_policy"], [25, 2, 1, "", "hparam_names"], [25, 2, 1, "", "one_step_lookahead"], [25, 2, 1, "", "train"], [25, 2, 1, "", "value_iteration"], [25, 2, 1, "", "vi"]], "csle_agents.common": [[26, 0, 0, "-", "fnn_w_gaussian"], [26, 0, 0, "-", "fnn_w_linear"], [26, 0, 0, "-", "pruning"]], "csle_agents.common.fnn_w_gaussian": [[26, 1, 1, "", "FNNwithGaussian"], [26, 3, 1, "", "test"]], "csle_agents.common.fnn_w_gaussian.FNNwithGaussian": [[26, 2, 1, "", "forward"], [26, 2, 1, "", "get_hidden_activation"]], "csle_agents.common.fnn_w_linear": [[26, 1, 1, "", "FNNwithLinear"], [26, 3, 1, "", "test"]], "csle_agents.common.fnn_w_linear.FNNwithLinear": [[26, 2, 1, "", "forward"], [26, 2, 1, "", "get_hidden_activation"]], "csle_agents.common.pruning": [[26, 3, 1, "", "check_dominance_lp"], [26, 3, 1, "", "check_duplicate"], [26, 3, 1, "", "prune_lower_bound"]], "csle_agents.constants": [[27, 0, 0, "-", "constants"]], "csle_agents.constants.constants": [[27, 1, 1, "", "BAYESIAN_OPTIMIZATION"], [27, 1, 1, "", "COMMON"], [27, 1, 1, "", "CROSS_ENTROPY"], [27, 1, 1, "", "DIFFERENTIAL_EVOLUTION"], [27, 1, 1, "", "DQN"], [27, 1, 1, "", "DYNASEC"], [27, 1, 1, "", "ENV_METRICS"], [27, 1, 1, "", "FICTITIOUS_PLAY"], [27, 1, 1, "", "HSVI"], [27, 1, 1, "", "HSVI_OS_POSG"], [27, 1, 1, "", "KIEFER_WOLFOWITZ"], [27, 1, 1, "", "LOCAL_DFSP"], [27, 1, 1, "", "LP_FOR_NF_GAMES"], [27, 1, 1, "", "PI"], [27, 1, 1, "", "PPO"], [27, 1, 1, "", "Q_LEARNING"], [27, 1, 1, "", "RANDOM_SEARCH"], [27, 1, 1, "", "REINFORCE"], [27, 1, 1, "", "SARSA"], [27, 1, 1, "", "SHAPLEY_ITERATION"], [27, 1, 1, "", "SONDIK_VI"], [27, 1, 1, "", "T_FP"], [27, 1, 1, "", "VI"]], "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION": [[27, 4, 1, "", "L"], [27, 4, 1, "", "N"], [27, 4, 1, "", "PARAMETER_BOUNDS"], [27, 4, 1, "", "PARAMS"], [27, 4, 1, "", "POLICY_TYPE"], [27, 4, 1, "", "STOP_DISTRIBUTION_ATTACKER"], [27, 4, 1, "", "STOP_DISTRIBUTION_DEFENDER"], [27, 4, 1, "", "TARGET"], [27, 4, 1, "", "THETA1"], [27, 4, 1, "", "THETAS"], [27, 4, 1, "", "THRESHOLDS"], [27, 4, 1, "", "UCB"], [27, 4, 1, "", "UCB_KAPPA"], [27, 4, 1, "", "UCB_XI"], [27, 4, 1, "", "UTILITY_FUNCTION"]], "csle_agents.constants.constants.COMMON": [[27, 4, 1, "", "ADAM"], [27, 4, 1, "", "AVERAGE_ATTACKER_RETURN"], [27, 4, 1, "", "AVERAGE_DEFENDER_RETURN"], [27, 4, 1, "", "AVERAGE_HEURISTIC_RETURN"], [27, 4, 1, "", "AVERAGE_RANDOM_RETURN"], [27, 4, 1, "", "AVERAGE_RETURN"], [27, 4, 1, "", "AVERAGE_TIME_HORIZON"], [27, 4, 1, "", "AVERAGE_UPPER_BOUND_RETURN"], [27, 4, 1, "", "BASELINE_PREFIX"], [27, 4, 1, "", "BATCH_SIZE"], [27, 4, 1, "", "CONFIDENCE_INTERVAL"], [27, 4, 1, "", "EVAL_BATCH_SIZE"], [27, 4, 1, "", "EVAL_EVERY"], [27, 4, 1, "", "EVAL_PREFIX"], [27, 4, 1, "", "EXPLOITABILITY"], [27, 4, 1, "", "GAMMA"], [27, 4, 1, "", "L"], [27, 4, 1, "", "LEARNING_RATE"], [27, 4, 1, "", "LEARNING_RATE_DECAY_RATE"], [27, 4, 1, "", "LEARNING_RATE_EXP_DECAY"], [27, 4, 1, "", "MAX_ENV_STEPS"], [27, 4, 1, "", "NUM_CACHED_SIMULATION_TRACES"], [27, 4, 1, "", "NUM_NODES"], [27, 4, 1, "", "NUM_PARALLEL_ENVS"], [27, 4, 1, "", "NUM_TRAINING_TIMESTEPS"], [27, 4, 1, "", "OPTIMIZER"], [27, 4, 1, "", "POLICY_LOSSES"], [27, 4, 1, "", "RUNNING_AVERAGE"], [27, 4, 1, "", "RUNNING_AVERAGE_ATTACKER_RETURN"], [27, 4, 1, "", "RUNNING_AVERAGE_DEFENDER_RETURN"], [27, 4, 1, "", "RUNNING_AVERAGE_EXPLOITABILITY"], [27, 4, 1, "", "RUNNING_AVERAGE_INTRUSION_LENGTH"], [27, 4, 1, "", "RUNNING_AVERAGE_INTRUSION_START"], [27, 4, 1, "", "RUNNING_AVERAGE_RETURN"], [27, 4, 1, "", "RUNNING_AVERAGE_START_POINT_CORRECT"], [27, 4, 1, "", "RUNNING_AVERAGE_TIME_HORIZON"], [27, 4, 1, "", "RUNNING_AVERAGE_WEIGHTED_INTRUSION_PREDICTION_DISTANCE"], [27, 4, 1, "", "RUNTIME"], [27, 4, 1, "", "SAVE_EVERY"], [27, 4, 1, "", "SGD"], [27, 4, 1, "", "START_POINT_CORRECT"], [27, 4, 1, "", "STOPPING_ENVS"], [27, 4, 1, "", "WEIGHTED_INTRUSION_PREDICTION_DISTANCE"]], "csle_agents.constants.constants.CROSS_ENTROPY": [[27, 4, 1, "", "K"], [27, 4, 1, "", "L"], [27, 4, 1, "", "LAMB"], [27, 4, 1, "", "N"], [27, 4, 1, "", "POLICY_TYPE"], [27, 4, 1, "", "STOP_DISTRIBUTION_ATTACKER"], [27, 4, 1, "", "STOP_DISTRIBUTION_DEFENDER"], [27, 4, 1, "", "THETA1"], [27, 4, 1, "", "THETAS"], [27, 4, 1, "", "THRESHOLDS"]], "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION": [[27, 4, 1, "", "BOUNDS"], [27, 4, 1, "", "L"], [27, 4, 1, "", "MUTATE"], [27, 4, 1, "", "N"], [27, 4, 1, "", "POLICY_TYPE"], [27, 4, 1, "", "POPULATION_SIZE"], [27, 4, 1, "", "RECOMBINATION"], [27, 4, 1, "", "STOP_DISTRIBUTION_ATTACKER"], [27, 4, 1, "", "STOP_DISTRIBUTION_DEFENDER"], [27, 4, 1, "", "THETA1"], [27, 4, 1, "", "THETAS"], [27, 4, 1, "", "THRESHOLDS"]], "csle_agents.constants.constants.DQN": [[27, 4, 1, "", "BUFFER_SIZE"], [27, 4, 1, "", "DQN_BATCH_SIZE"], [27, 4, 1, "", "EXPLORATION_FINAL_EPS"], [27, 4, 1, "", "EXPLORATION_FRACTION"], [27, 4, 1, "", "EXPLORATION_INITIAL_EPS"], [27, 4, 1, "", "GRADIENT_STEPS"], [27, 4, 1, "", "LEARNING_STARTS"], [27, 4, 1, "", "MAX_GRAD_NORM"], [27, 4, 1, "", "MLP_POLICY"], [27, 4, 1, "", "N_EPISODES_ROLLOUT"], [27, 4, 1, "", "TARGET_UPDATE_INTERVAL"], [27, 4, 1, "", "TRAIN_FREQ"]], "csle_agents.constants.constants.DYNASEC": [[27, 4, 1, "", "CLIENTS_ARRIVAL_RATE"], [27, 4, 1, "", "EMULATION_MONITOR_SLEEP_TIME"], [27, 4, 1, "", "EMULATION_TRACES_TO_SAVE_W_DATA_COLLECTION_JOB"], [27, 4, 1, "", "INTRUSION_ALERTS_MEAN"], [27, 4, 1, "", "INTRUSION_ALERTS_MEAN_BASELINE"], [27, 4, 1, "", "INTRUSION_START_P"], [27, 4, 1, "", "NO_INTRUSION_ALERTS_MEAN"], [27, 4, 1, "", "NO_INTRUSION_ALERTS_MEAN_BASELINE"], [27, 4, 1, "", "NUM_CLIENTS"], [27, 4, 1, "", "REPLAY_WINDOW_SIZE"], [27, 4, 1, "", "SLEEP_TIME"], [27, 4, 1, "", "STATIC_ATTACKER_TYPE"], [27, 4, 1, "", "TRAINING_EPOCHS"], [27, 4, 1, "", "WARMUP_EPISODES"]], "csle_agents.constants.constants.ENV_METRICS": [[27, 4, 1, "", "ATTACKER_ACTION"], [27, 4, 1, "", "AVERAGE_HEURISTIC_RETURN"], [27, 4, 1, "", "AVERAGE_RANDOM_RETURN"], [27, 4, 1, "", "AVERAGE_UPPER_BOUND_RETURN"], [27, 4, 1, "", "DEFENDER_ACTION"], [27, 4, 1, "", "OBSERVATION"], [27, 4, 1, "", "RETURN"], [27, 4, 1, "", "STATE"], [27, 4, 1, "", "TIME_HORIZON"], [27, 4, 1, "", "TIME_STEP"]], "csle_agents.constants.constants.FICTITIOUS_PLAY": [[27, 4, 1, "", "N"], [27, 4, 1, "", "PAYOFF_MATRIX"], [27, 4, 1, "", "PLAYER_1_PRIOR"], [27, 4, 1, "", "PLAYER_2_PRIOR"]], "csle_agents.constants.constants.HSVI": [[27, 4, 1, "", "ACTION_SPACE"], [27, 4, 1, "", "EPSILON"], [27, 4, 1, "", "INITIAL_BELIEF"], [27, 4, 1, "", "INITIAL_BELIEF_VALUES"], [27, 4, 1, "", "LB_SIZE"], [27, 4, 1, "", "LB_SIZES"], [27, 4, 1, "", "NUMBER_OF_SIMULATIONS"], [27, 4, 1, "", "OBSERVATION_SPACE"], [27, 4, 1, "", "OBSERVATION_TENSOR"], [27, 4, 1, "", "PRUNE_FREQUENCY"], [27, 4, 1, "", "REWARD_TENSOR"], [27, 4, 1, "", "SIMULATE_HORIZON"], [27, 4, 1, "", "SIMULATION_FREQUENCY"], [27, 4, 1, "", "STATE_SPACE"], [27, 4, 1, "", "TRANSITION_TENSOR"], [27, 4, 1, "", "UB_SIZE"], [27, 4, 1, "", "UB_SIZES"], [27, 4, 1, "", "USE_LP"], [27, 4, 1, "", "WIDTH"], [27, 4, 1, "", "WIDTHS"]], "csle_agents.constants.constants.HSVI_OS_POSG": [[27, 4, 1, "", "ACTION_SPACE_PLAYER_1"], [27, 4, 1, "", "ACTION_SPACE_PLAYER_2"], [27, 4, 1, "", "EPSILON"], [27, 4, 1, "", "EXCESSES"], [27, 4, 1, "", "INITIAL_BELIEF"], [27, 4, 1, "", "N"], [27, 4, 1, "", "OBSERVATION_FUNCTION"], [27, 4, 1, "", "OBSERVATION_SPACE"], [27, 4, 1, "", "PRUNE_FREQUENCY"], [27, 4, 1, "", "REWARD_TENSOR"], [27, 4, 1, "", "STATE_SPACE"], [27, 4, 1, "", "TRANSITION_TENSOR"], [27, 4, 1, "", "WIDTHS"]], "csle_agents.constants.constants.KIEFER_WOLFOWITZ": [[27, 4, 1, "", "DELTA"], [27, 4, 1, "", "GRADIENT_BATCH_SIZE"], [27, 4, 1, "", "INITIAL_ALPHA"], [27, 4, 1, "", "L"], [27, 4, 1, "", "N"], [27, 4, 1, "", "POLICY_TYPE"], [27, 4, 1, "", "STOP_DISTRIBUTION_ATTACKER"], [27, 4, 1, "", "STOP_DISTRIBUTION_DEFENDER"], [27, 4, 1, "", "THETA1"], [27, 4, 1, "", "THETAS"], [27, 4, 1, "", "THRESHOLDS"]], "csle_agents.constants.constants.LOCAL_DFSP": [[27, 4, 1, "", "AVERAGE_BEST_RESPONSE_ATTACKER_RETURN"], [27, 4, 1, "", "AVERAGE_BEST_RESPONSE_DEFENDER_RETURN"], [27, 4, 1, "", "BEST_RESPONSE_EVALUATION_ITERATIONS"], [27, 4, 1, "", "EQUILIBRIUM_STRATEGIES_EVALUATION_ITERATIONS"], [27, 4, 1, "", "N_2"], [27, 4, 1, "", "RUNNING_AVERAGE_BEST_RESPONSE_ATTACKER_RETURN"], [27, 4, 1, "", "RUNNING_AVERAGE_BEST_RESPONSE_DEFENDER_RETURN"]], "csle_agents.constants.constants.LP_FOR_NF_GAMES": [[27, 4, 1, "", "ACTION_SPACE_PLAYER_1"], [27, 4, 1, "", "ACTION_SPACE_PLAYER_2"], [27, 4, 1, "", "N"], [27, 4, 1, "", "PAYOFF_MATRIX"]], "csle_agents.constants.constants.PI": [[27, 4, 1, "", "INITIAL_POLICY"], [27, 4, 1, "", "N"], [27, 4, 1, "", "NUM_ACTIONS"], [27, 4, 1, "", "NUM_STATES"], [27, 4, 1, "", "REWARD_TENSOR"], [27, 4, 1, "", "TRANSITION_TENSOR"]], "csle_agents.constants.constants.PPO": [[27, 4, 1, "", "CLIP_RANGE"], [27, 4, 1, "", "CLIP_RANGE_VF"], [27, 4, 1, "", "ENT_COEF"], [27, 4, 1, "", "GAE_LAMBDA"], [27, 4, 1, "", "MAX_GRAD_NORM"], [27, 4, 1, "", "MLP_POLICY"], [27, 4, 1, "", "STEPS_BETWEEN_UPDATES"], [27, 4, 1, "", "TARGET_KL"], [27, 4, 1, "", "VF_COEF"]], "csle_agents.constants.constants.Q_LEARNING": [[27, 4, 1, "", "A"], [27, 4, 1, "", "EPSILON"], [27, 4, 1, "", "INITIAL_STATE_VALUES"], [27, 4, 1, "", "N"], [27, 4, 1, "", "S"]], "csle_agents.constants.constants.RANDOM_SEARCH": [[27, 4, 1, "", "DELTA"], [27, 4, 1, "", "L"], [27, 4, 1, "", "N"], [27, 4, 1, "", "POLICY_TYPE"], [27, 4, 1, "", "STOP_DISTRIBUTION_ATTACKER"], [27, 4, 1, "", "STOP_DISTRIBUTION_DEFENDER"], [27, 4, 1, "", "THETA1"], [27, 4, 1, "", "THETAS"], [27, 4, 1, "", "THRESHOLDS"]], "csle_agents.constants.constants.REINFORCE": [[27, 4, 1, "", "CLIP_GRADIENT"], [27, 4, 1, "", "GRADIENT_BATCH_SIZE"], [27, 4, 1, "", "N"]], "csle_agents.constants.constants.SARSA": [[27, 4, 1, "", "A"], [27, 4, 1, "", "EPSILON"], [27, 4, 1, "", "INITIAL_STATE_VALUES"], [27, 4, 1, "", "N"], [27, 4, 1, "", "S"]], "csle_agents.constants.constants.SHAPLEY_ITERATION": [[27, 4, 1, "", "ACTION_SPACE_PLAYER_1"], [27, 4, 1, "", "ACTION_SPACE_PLAYER_2"], [27, 4, 1, "", "DELTA"], [27, 4, 1, "", "N"], [27, 4, 1, "", "REWARD_TENSOR"], [27, 4, 1, "", "STATE_SPACE"], [27, 4, 1, "", "TRANSITION_TENSOR"]], "csle_agents.constants.constants.SONDIK_VI": [[27, 4, 1, "", "ACTION_SPACE"], [27, 4, 1, "", "INITIAL_BELIEF"], [27, 4, 1, "", "INITIAL_BELIEF_VALUES"], [27, 4, 1, "", "NUM_ALPHA_VECTORS"], [27, 4, 1, "", "OBSERVATION_SPACE"], [27, 4, 1, "", "OBSERVATION_TENSOR"], [27, 4, 1, "", "PLANNING_HORIZON"], [27, 4, 1, "", "REWARD_TENSOR"], [27, 4, 1, "", "STATE_SPACE"], [27, 4, 1, "", "TRANSITION_TENSOR"], [27, 4, 1, "", "USE_PRUNING"]], "csle_agents.constants.constants.T_FP": [[27, 4, 1, "", "ATTACKER_THRESHOLDS"], [27, 4, 1, "", "AVERAGE_BEST_RESPONSE_ATTACKER_RETURN"], [27, 4, 1, "", "AVERAGE_BEST_RESPONSE_DEFENDER_RETURN"], [27, 4, 1, "", "BEST_RESPONSE_EVALUATION_ITERATIONS"], [27, 4, 1, "", "DEFENDER_THRESHOLDS"], [27, 4, 1, "", "EQUILIBRIUM_STRATEGIES_EVALUATION_ITERATIONS"], [27, 4, 1, "", "N_2"], [27, 4, 1, "", "RUNNING_AVERAGE_BEST_RESPONSE_ATTACKER_RETURN"], [27, 4, 1, "", "RUNNING_AVERAGE_BEST_RESPONSE_DEFENDER_RETURN"], [27, 4, 1, "", "THETA1_ATTACKER"], [27, 4, 1, "", "THETA1_DEFENDER"]], "csle_agents.constants.constants.VI": [[27, 4, 1, "", "DELTA"], [27, 4, 1, "", "NUM_ACTIONS"], [27, 4, 1, "", "NUM_STATES"], [27, 4, 1, "", "REWARD_TENSOR"], [27, 4, 1, "", "THETA"], [27, 4, 1, "", "TRANSITION_TENSOR"]], "csle_agents.job_controllers": [[28, 0, 0, "-", "training_job_manager"]], "csle_agents.job_controllers.training_job_manager": [[28, 1, 1, "", "TrainingJobManager"]], "csle_agents.job_controllers.training_job_manager.TrainingJobManager": [[28, 2, 1, "", "run_training_job"], [28, 2, 1, "", "start_training_job_in_background"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:function", "4": "py:attribute"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "function", "Python function"], "4": ["py", "attribute", "Python attribute"]}, "titleterms": {"csle_ag": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "packag": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], "subpackag": [0, 1, 29], "modul": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], "content": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], "agent": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], "base": 2, "submodul": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], "base_ag": 2, "bayes_opt": 3, "bayes_opt_ag": [3, 4], "bayesian_optim": 4, "cross_entropi": 5, "cross_entropy_ag": 5, "dfsp_local": 6, "dfsp_local_ag": 6, "dfsp_local_ppo_ag": 6, "differential_evolut": 7, "differential_evolution_ag": 7, "dqn": 8, "dqn_agent": 8, "dynasec": 9, "dynasec_ag": 9, "fp": 10, "fictitious_play_ag": 10, "hsvi": 11, "hsvi_ag": 11, "hsvi_os_posg": 12, "hsvi_os_posg_ag": 12, "kiefer_wolfowitz": 13, "kiefer_wolfowitz_ag": 13, "lp_nf": 14, "linear_programming_normal_form_game_ag": 14, "pi": 15, "pi_ag": 15, "ppo": 16, "ppo_ag": 16, "q_learn": 17, "q_learning_ag": 17, "random_search": 18, "random_search_ag": 18, "reinforc": 19, "reinforce_ag": 19, "sarsa": 20, "sarsa_ag": 20, "shapley_iter": 21, "shapley_iteration_ag": 21, "sondik_vi": 22, "sondik_vi_ag": 22, "t_fp": 23, "t_fp_agent": 23, "t_spsa": 24, "t_spsa_ag": 24, "vi": 25, "vi_ag": 25, "common": 26, "actor_critic_net": 26, "fnn_w_gaussian": 26, "fnn_w_linear": 26, "prune": 26, "constant": 27, "job_control": 28, "training_job_manag": 28}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"csle_agents package": [[0, "csle-agents-package"], [29, "csle-agents-package"]], "Subpackages": [[0, "subpackages"], [1, "subpackages"], [29, "subpackages"]], "Module contents": [[0, "module-csle_agents"], [1, "module-csle_agents.agents"], [2, "module-csle_agents.agents.base"], [3, "module-contents"], [4, "module-csle_agents.agents.bayesian_optimization"], [5, "module-csle_agents.agents.cross_entropy"], [6, "module-csle_agents.agents.dfsp_local"], [7, "module-csle_agents.agents.differential_evolution"], [8, "module-csle_agents.agents.dqn"], [9, "module-csle_agents.agents.dynasec"], [10, "module-csle_agents.agents.fp"], [11, "module-csle_agents.agents.hsvi"], [12, "module-csle_agents.agents.hsvi_os_posg"], [13, "module-csle_agents.agents.kiefer_wolfowitz"], [14, "module-csle_agents.agents.lp_nf"], [15, "module-csle_agents.agents.pi"], [16, "module-csle_agents.agents.ppo"], [17, "module-csle_agents.agents.q_learning"], [18, "module-csle_agents.agents.random_search"], [19, "module-csle_agents.agents.reinforce"], [20, "module-csle_agents.agents.sarsa"], [21, "module-csle_agents.agents.shapley_iteration"], [22, "module-csle_agents.agents.sondik_vi"], [23, "module-csle_agents.agents.t_fp"], [24, "module-csle_agents.agents.t_spsa"], [25, "module-csle_agents.agents.vi"], [26, "module-csle_agents.common"], [27, "module-csle_agents.constants"], [28, "module-csle_agents.job_controllers"], [29, "module-csle_agents"]], "csle_agents.agents package": [[1, "csle-agents-agents-package"]], "csle_agents.agents.base package": [[2, "csle-agents-agents-base-package"]], "Submodules": [[2, "submodules"], [3, "submodules"], [4, "submodules"], [5, "submodules"], [6, "submodules"], [7, "submodules"], [8, "submodules"], [9, "submodules"], [10, "submodules"], [11, "submodules"], [12, "submodules"], [13, "submodules"], [14, "submodules"], [15, "submodules"], [16, "submodules"], [17, "submodules"], [18, "submodules"], [19, "submodules"], [20, "submodules"], [21, "submodules"], [22, "submodules"], [23, "submodules"], [24, "submodules"], [25, "submodules"], [26, "submodules"], [27, "submodules"], [28, "submodules"]], "csle_agents.agents.base.base_agent module": [[2, "module-csle_agents.agents.base.base_agent"]], "csle_agents.agents.bayes_opt package": [[3, "csle-agents-agents-bayes-opt-package"]], "csle_agents.agents.bayes_opt.bayes_opt_agent module": [[3, "csle-agents-agents-bayes-opt-bayes-opt-agent-module"]], "csle_agents.agents.bayesian_optimization package": [[4, "csle-agents-agents-bayesian-optimization-package"]], "csle_agents.agents.bayesian_optimization.bayes_opt_agent module": [[4, "module-csle_agents.agents.bayesian_optimization.bayes_opt_agent"]], "csle_agents.agents.cross_entropy package": [[5, "csle-agents-agents-cross-entropy-package"]], "csle_agents.agents.cross_entropy.cross_entropy_agent module": [[5, "module-csle_agents.agents.cross_entropy.cross_entropy_agent"]], "csle_agents.agents.dfsp_local package": [[6, "csle-agents-agents-dfsp-local-package"]], "csle_agents.agents.dfsp_local.dfsp_local_agent module": [[6, "module-csle_agents.agents.dfsp_local.dfsp_local_agent"]], "csle_agents.agents.dfsp_local.dfsp_local_ppo_agent module": [[6, "module-csle_agents.agents.dfsp_local.dfsp_local_ppo_agent"]], "csle_agents.agents.differential_evolution package": [[7, "csle-agents-agents-differential-evolution-package"]], "csle_agents.agents.differential_evolution.differential_evolution_agent module": [[7, "module-csle_agents.agents.differential_evolution.differential_evolution_agent"]], "csle_agents.agents.dqn package": [[8, "csle-agents-agents-dqn-package"]], "csle_agents.agents.dqn.dqn_agent module": [[8, "module-csle_agents.agents.dqn.dqn_agent"]], "csle_agents.agents.dynasec package": [[9, "csle-agents-agents-dynasec-package"]], "csle_agents.agents.dynasec.dynasec_agent module": [[9, "module-csle_agents.agents.dynasec.dynasec_agent"]], "csle_agents.agents.fp package": [[10, "csle-agents-agents-fp-package"]], "csle_agents.agents.fp.fictitious_play_agent module": [[10, "module-csle_agents.agents.fp.fictitious_play_agent"]], "csle_agents.agents.hsvi package": [[11, "csle-agents-agents-hsvi-package"]], "csle_agents.agents.hsvi.hsvi_agent module": [[11, "module-csle_agents.agents.hsvi.hsvi_agent"]], "csle_agents.agents.hsvi_os_posg package": [[12, "csle-agents-agents-hsvi-os-posg-package"]], "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent module": [[12, "module-csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent"]], "csle_agents.agents.kiefer_wolfowitz package": [[13, "csle-agents-agents-kiefer-wolfowitz-package"]], "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent module": [[13, "module-csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent"]], "csle_agents.agents.lp_nf package": [[14, "csle-agents-agents-lp-nf-package"]], "csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent module": [[14, "module-csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent"]], "csle_agents.agents.pi package": [[15, "csle-agents-agents-pi-package"]], "csle_agents.agents.pi.pi_agent module": [[15, "module-csle_agents.agents.pi.pi_agent"]], "csle_agents.agents.ppo package": [[16, "csle-agents-agents-ppo-package"]], "csle_agents.agents.ppo.ppo_agent module": [[16, "module-csle_agents.agents.ppo.ppo_agent"]], "csle_agents.agents.q_learning package": [[17, "csle-agents-agents-q-learning-package"]], "csle_agents.agents.q_learning.q_learning_agent module": [[17, "module-csle_agents.agents.q_learning.q_learning_agent"]], "csle_agents.agents.random_search package": [[18, "csle-agents-agents-random-search-package"]], "csle_agents.agents.random_search.random_search_agent module": [[18, "module-csle_agents.agents.random_search.random_search_agent"]], "csle_agents.agents.reinforce package": [[19, "csle-agents-agents-reinforce-package"]], "csle_agents.agents.reinforce.reinforce_agent module": [[19, "module-csle_agents.agents.reinforce.reinforce_agent"]], "csle_agents.agents.sarsa package": [[20, "csle-agents-agents-sarsa-package"]], "csle_agents.agents.sarsa.sarsa_agent module": [[20, "module-csle_agents.agents.sarsa.sarsa_agent"]], "csle_agents.agents.shapley_iteration package": [[21, "csle-agents-agents-shapley-iteration-package"]], "csle_agents.agents.shapley_iteration.shapley_iteration_agent module": [[21, "module-csle_agents.agents.shapley_iteration.shapley_iteration_agent"]], "csle_agents.agents.sondik_vi package": [[22, "csle-agents-agents-sondik-vi-package"]], "csle_agents.agents.sondik_vi.sondik_vi_agent module": [[22, "module-csle_agents.agents.sondik_vi.sondik_vi_agent"]], "csle_agents.agents.t_fp package": [[23, "csle-agents-agents-t-fp-package"]], "csle_agents.agents.t_fp.t_fp_agent module": [[23, "module-csle_agents.agents.t_fp.t_fp_agent"]], "csle_agents.agents.t_spsa package": [[24, "csle-agents-agents-t-spsa-package"]], "csle_agents.agents.t_spsa.t_spsa_agent module": [[24, "module-csle_agents.agents.t_spsa.t_spsa_agent"]], "csle_agents.agents.vi package": [[25, "csle-agents-agents-vi-package"]], "csle_agents.agents.vi.vi_agent module": [[25, "module-csle_agents.agents.vi.vi_agent"]], "csle_agents.common package": [[26, "csle-agents-common-package"]], "csle_agents.common.actor_critic_net module": [[26, "csle-agents-common-actor-critic-net-module"]], "csle_agents.common.fnn_w_gaussian module": [[26, "module-csle_agents.common.fnn_w_gaussian"]], "csle_agents.common.fnn_w_linear module": [[26, "module-csle_agents.common.fnn_w_linear"]], "csle_agents.common.pruning module": [[26, "module-csle_agents.common.pruning"]], "csle_agents.constants package": [[27, "csle-agents-constants-package"]], "csle_agents.constants.constants module": [[27, "module-csle_agents.constants.constants"]], "csle_agents.job_controllers package": [[28, "csle-agents-job-controllers-package"]], "csle_agents.job_controllers.training_job_manager module": [[28, "module-csle_agents.job_controllers.training_job_manager"]], "csle_agents": [[30, "csle-agents"]]}, "indexentries": {"csle_agents": [[0, "module-csle_agents"], [29, "module-csle_agents"]], "module": [[0, "module-csle_agents"], [1, "module-csle_agents.agents"], [2, "module-csle_agents.agents.base"], [2, "module-csle_agents.agents.base.base_agent"], [4, "module-csle_agents.agents.bayesian_optimization"], [4, "module-csle_agents.agents.bayesian_optimization.bayes_opt_agent"], [5, "module-csle_agents.agents.cross_entropy"], [5, "module-csle_agents.agents.cross_entropy.cross_entropy_agent"], [6, "module-csle_agents.agents.dfsp_local"], [6, "module-csle_agents.agents.dfsp_local.dfsp_local_agent"], [6, "module-csle_agents.agents.dfsp_local.dfsp_local_ppo_agent"], [7, "module-csle_agents.agents.differential_evolution"], [7, "module-csle_agents.agents.differential_evolution.differential_evolution_agent"], [8, "module-csle_agents.agents.dqn"], [8, "module-csle_agents.agents.dqn.dqn_agent"], [9, "module-csle_agents.agents.dynasec"], [9, "module-csle_agents.agents.dynasec.dynasec_agent"], [10, "module-csle_agents.agents.fp"], [10, "module-csle_agents.agents.fp.fictitious_play_agent"], [11, "module-csle_agents.agents.hsvi"], [11, "module-csle_agents.agents.hsvi.hsvi_agent"], [12, "module-csle_agents.agents.hsvi_os_posg"], [12, "module-csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent"], [13, "module-csle_agents.agents.kiefer_wolfowitz"], [13, "module-csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent"], [14, "module-csle_agents.agents.lp_nf"], [14, "module-csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent"], [15, "module-csle_agents.agents.pi"], [15, "module-csle_agents.agents.pi.pi_agent"], [16, "module-csle_agents.agents.ppo"], [16, "module-csle_agents.agents.ppo.ppo_agent"], [17, "module-csle_agents.agents.q_learning"], [17, "module-csle_agents.agents.q_learning.q_learning_agent"], [18, "module-csle_agents.agents.random_search"], [18, "module-csle_agents.agents.random_search.random_search_agent"], [19, "module-csle_agents.agents.reinforce"], [19, "module-csle_agents.agents.reinforce.reinforce_agent"], [20, "module-csle_agents.agents.sarsa"], [20, "module-csle_agents.agents.sarsa.sarsa_agent"], [21, "module-csle_agents.agents.shapley_iteration"], [21, "module-csle_agents.agents.shapley_iteration.shapley_iteration_agent"], [22, "module-csle_agents.agents.sondik_vi"], [22, "module-csle_agents.agents.sondik_vi.sondik_vi_agent"], [23, "module-csle_agents.agents.t_fp"], [23, "module-csle_agents.agents.t_fp.t_fp_agent"], [24, "module-csle_agents.agents.t_spsa"], [24, "module-csle_agents.agents.t_spsa.t_spsa_agent"], [25, "module-csle_agents.agents.vi"], [25, "module-csle_agents.agents.vi.vi_agent"], [26, "module-csle_agents.common"], [26, "module-csle_agents.common.fnn_w_gaussian"], [26, "module-csle_agents.common.fnn_w_linear"], [26, "module-csle_agents.common.pruning"], [27, "module-csle_agents.constants"], [27, "module-csle_agents.constants.constants"], [28, "module-csle_agents.job_controllers"], [28, "module-csle_agents.job_controllers.training_job_manager"], [29, "module-csle_agents"]], "csle_agents.agents": [[1, "module-csle_agents.agents"]], "baseagent (class in csle_agents.agents.base.base_agent)": [[2, "csle_agents.agents.base.base_agent.BaseAgent"]], "csle_agents.agents.base": [[2, "module-csle_agents.agents.base"]], "csle_agents.agents.base.base_agent": [[2, "module-csle_agents.agents.base.base_agent"]], "hparam_names() (csle_agents.agents.base.base_agent.baseagent method)": [[2, "csle_agents.agents.base.base_agent.BaseAgent.hparam_names"]], "train() (csle_agents.agents.base.base_agent.baseagent method)": [[2, "csle_agents.agents.base.base_agent.BaseAgent.train"]], "bayesoptagent (class in csle_agents.agents.bayesian_optimization.bayes_opt_agent)": [[4, "csle_agents.agents.bayesian_optimization.bayes_opt_agent.BayesOptAgent"]], "bayesian_optimization() (csle_agents.agents.bayesian_optimization.bayes_opt_agent.bayesoptagent method)": [[4, "csle_agents.agents.bayesian_optimization.bayes_opt_agent.BayesOptAgent.bayesian_optimization"]], "compute_avg_metrics() (csle_agents.agents.bayesian_optimization.bayes_opt_agent.bayesoptagent static method)": [[4, "csle_agents.agents.bayesian_optimization.bayes_opt_agent.BayesOptAgent.compute_avg_metrics"]], "csle_agents.agents.bayesian_optimization": [[4, "module-csle_agents.agents.bayesian_optimization"]], "csle_agents.agents.bayesian_optimization.bayes_opt_agent": [[4, "module-csle_agents.agents.bayesian_optimization.bayes_opt_agent"]], "eval_theta() (csle_agents.agents.bayesian_optimization.bayes_opt_agent.bayesoptagent method)": [[4, "csle_agents.agents.bayesian_optimization.bayes_opt_agent.BayesOptAgent.eval_theta"]], "get_policy() (csle_agents.agents.bayesian_optimization.bayes_opt_agent.bayesoptagent method)": [[4, "csle_agents.agents.bayesian_optimization.bayes_opt_agent.BayesOptAgent.get_policy"]], "get_theta_vector_from_param_dict() (csle_agents.agents.bayesian_optimization.bayes_opt_agent.bayesoptagent static method)": [[4, "csle_agents.agents.bayesian_optimization.bayes_opt_agent.BayesOptAgent.get_theta_vector_from_param_dict"]], "hparam_names() (csle_agents.agents.bayesian_optimization.bayes_opt_agent.bayesoptagent method)": [[4, "csle_agents.agents.bayesian_optimization.bayes_opt_agent.BayesOptAgent.hparam_names"]], "initial_theta() (csle_agents.agents.bayesian_optimization.bayes_opt_agent.bayesoptagent static method)": [[4, "csle_agents.agents.bayesian_optimization.bayes_opt_agent.BayesOptAgent.initial_theta"]], "round_vec() (csle_agents.agents.bayesian_optimization.bayes_opt_agent.bayesoptagent static method)": [[4, "csle_agents.agents.bayesian_optimization.bayes_opt_agent.BayesOptAgent.round_vec"]], "train() (csle_agents.agents.bayesian_optimization.bayes_opt_agent.bayesoptagent method)": [[4, "csle_agents.agents.bayesian_optimization.bayes_opt_agent.BayesOptAgent.train"]], "update_metrics() (csle_agents.agents.bayesian_optimization.bayes_opt_agent.bayesoptagent static method)": [[4, "csle_agents.agents.bayesian_optimization.bayes_opt_agent.BayesOptAgent.update_metrics"]], "crossentropyagent (class in csle_agents.agents.cross_entropy.cross_entropy_agent)": [[5, "csle_agents.agents.cross_entropy.cross_entropy_agent.CrossEntropyAgent"]], "compute_avg_metrics() (csle_agents.agents.cross_entropy.cross_entropy_agent.crossentropyagent static method)": [[5, "csle_agents.agents.cross_entropy.cross_entropy_agent.CrossEntropyAgent.compute_avg_metrics"]], "cross_entropy() (csle_agents.agents.cross_entropy.cross_entropy_agent.crossentropyagent method)": [[5, "csle_agents.agents.cross_entropy.cross_entropy_agent.CrossEntropyAgent.cross_entropy"]], "csle_agents.agents.cross_entropy": [[5, "module-csle_agents.agents.cross_entropy"]], "csle_agents.agents.cross_entropy.cross_entropy_agent": [[5, "module-csle_agents.agents.cross_entropy.cross_entropy_agent"]], "eval_theta() (csle_agents.agents.cross_entropy.cross_entropy_agent.crossentropyagent method)": [[5, "csle_agents.agents.cross_entropy.cross_entropy_agent.CrossEntropyAgent.eval_theta"]], "get_policy() (csle_agents.agents.cross_entropy.cross_entropy_agent.crossentropyagent method)": [[5, "csle_agents.agents.cross_entropy.cross_entropy_agent.CrossEntropyAgent.get_policy"]], "hparam_names() (csle_agents.agents.cross_entropy.cross_entropy_agent.crossentropyagent method)": [[5, "csle_agents.agents.cross_entropy.cross_entropy_agent.CrossEntropyAgent.hparam_names"]], "initial_theta() (csle_agents.agents.cross_entropy.cross_entropy_agent.crossentropyagent static method)": [[5, "csle_agents.agents.cross_entropy.cross_entropy_agent.CrossEntropyAgent.initial_theta"]], "round_vec() (csle_agents.agents.cross_entropy.cross_entropy_agent.crossentropyagent static method)": [[5, "csle_agents.agents.cross_entropy.cross_entropy_agent.CrossEntropyAgent.round_vec"]], "train() (csle_agents.agents.cross_entropy.cross_entropy_agent.crossentropyagent method)": [[5, "csle_agents.agents.cross_entropy.cross_entropy_agent.CrossEntropyAgent.train"]], "update_metrics() (csle_agents.agents.cross_entropy.cross_entropy_agent.crossentropyagent static method)": [[5, "csle_agents.agents.cross_entropy.cross_entropy_agent.CrossEntropyAgent.update_metrics"]], "dfsplocalagent (class in csle_agents.agents.dfsp_local.dfsp_local_agent)": [[6, "csle_agents.agents.dfsp_local.dfsp_local_agent.DFSPLocalAgent"]], "dfsplocalppoagent (class in csle_agents.agents.dfsp_local.dfsp_local_ppo_agent)": [[6, "csle_agents.agents.dfsp_local.dfsp_local_ppo_agent.DFSPLocalPPOAgent"]], "attacker_best_response() (csle_agents.agents.dfsp_local.dfsp_local_agent.dfsplocalagent method)": [[6, "csle_agents.agents.dfsp_local.dfsp_local_agent.DFSPLocalAgent.attacker_best_response"]], "attacker_best_response() (csle_agents.agents.dfsp_local.dfsp_local_ppo_agent.dfsplocalppoagent method)": [[6, "csle_agents.agents.dfsp_local.dfsp_local_ppo_agent.DFSPLocalPPOAgent.attacker_best_response"]], "compute_avg_metrics() (csle_agents.agents.dfsp_local.dfsp_local_agent.dfsplocalagent static method)": [[6, "csle_agents.agents.dfsp_local.dfsp_local_agent.DFSPLocalAgent.compute_avg_metrics"]], "compute_avg_metrics() (csle_agents.agents.dfsp_local.dfsp_local_ppo_agent.dfsplocalppoagent static method)": [[6, "csle_agents.agents.dfsp_local.dfsp_local_ppo_agent.DFSPLocalPPOAgent.compute_avg_metrics"]], "csle_agents.agents.dfsp_local": [[6, "module-csle_agents.agents.dfsp_local"]], "csle_agents.agents.dfsp_local.dfsp_local_agent": [[6, "module-csle_agents.agents.dfsp_local.dfsp_local_agent"]], "csle_agents.agents.dfsp_local.dfsp_local_ppo_agent": [[6, "module-csle_agents.agents.dfsp_local.dfsp_local_ppo_agent"]], "defender_best_response() (csle_agents.agents.dfsp_local.dfsp_local_agent.dfsplocalagent method)": [[6, "csle_agents.agents.dfsp_local.dfsp_local_agent.DFSPLocalAgent.defender_best_response"]], "defender_best_response() (csle_agents.agents.dfsp_local.dfsp_local_ppo_agent.dfsplocalppoagent method)": [[6, "csle_agents.agents.dfsp_local.dfsp_local_ppo_agent.DFSPLocalPPOAgent.defender_best_response"]], "evaluate_attacker_policy() (csle_agents.agents.dfsp_local.dfsp_local_agent.dfsplocalagent method)": [[6, "csle_agents.agents.dfsp_local.dfsp_local_agent.DFSPLocalAgent.evaluate_attacker_policy"]], "evaluate_attacker_policy() (csle_agents.agents.dfsp_local.dfsp_local_ppo_agent.dfsplocalppoagent method)": [[6, "csle_agents.agents.dfsp_local.dfsp_local_ppo_agent.DFSPLocalPPOAgent.evaluate_attacker_policy"]], "evaluate_defender_policy() (csle_agents.agents.dfsp_local.dfsp_local_agent.dfsplocalagent method)": [[6, "csle_agents.agents.dfsp_local.dfsp_local_agent.DFSPLocalAgent.evaluate_defender_policy"]], "evaluate_defender_policy() (csle_agents.agents.dfsp_local.dfsp_local_ppo_agent.dfsplocalppoagent method)": [[6, "csle_agents.agents.dfsp_local.dfsp_local_ppo_agent.DFSPLocalPPOAgent.evaluate_defender_policy"]], "evaluate_strategy_profile() (csle_agents.agents.dfsp_local.dfsp_local_agent.dfsplocalagent method)": [[6, "csle_agents.agents.dfsp_local.dfsp_local_agent.DFSPLocalAgent.evaluate_strategy_profile"]], "evaluate_strategy_profile() (csle_agents.agents.dfsp_local.dfsp_local_ppo_agent.dfsplocalppoagent method)": [[6, "csle_agents.agents.dfsp_local.dfsp_local_ppo_agent.DFSPLocalPPOAgent.evaluate_strategy_profile"]], "exploitability() (csle_agents.agents.dfsp_local.dfsp_local_agent.dfsplocalagent static method)": [[6, "csle_agents.agents.dfsp_local.dfsp_local_agent.DFSPLocalAgent.exploitability"]], "exploitability() (csle_agents.agents.dfsp_local.dfsp_local_ppo_agent.dfsplocalppoagent static method)": [[6, "csle_agents.agents.dfsp_local.dfsp_local_ppo_agent.DFSPLocalPPOAgent.exploitability"]], "get_attacker_experiment_config() (csle_agents.agents.dfsp_local.dfsp_local_ppo_agent.dfsplocalppoagent method)": [[6, "csle_agents.agents.dfsp_local.dfsp_local_ppo_agent.DFSPLocalPPOAgent.get_attacker_experiment_config"]], "get_defender_experiment_config() (csle_agents.agents.dfsp_local.dfsp_local_ppo_agent.dfsplocalppoagent method)": [[6, "csle_agents.agents.dfsp_local.dfsp_local_ppo_agent.DFSPLocalPPOAgent.get_defender_experiment_config"]], "hparam_names() (csle_agents.agents.dfsp_local.dfsp_local_agent.dfsplocalagent method)": [[6, "csle_agents.agents.dfsp_local.dfsp_local_agent.DFSPLocalAgent.hparam_names"]], "hparam_names() (csle_agents.agents.dfsp_local.dfsp_local_ppo_agent.dfsplocalppoagent method)": [[6, "csle_agents.agents.dfsp_local.dfsp_local_ppo_agent.DFSPLocalPPOAgent.hparam_names"]], "local_dfsp() (csle_agents.agents.dfsp_local.dfsp_local_agent.dfsplocalagent method)": [[6, "csle_agents.agents.dfsp_local.dfsp_local_agent.DFSPLocalAgent.local_dfsp"]], "local_dfsp() (csle_agents.agents.dfsp_local.dfsp_local_ppo_agent.dfsplocalppoagent method)": [[6, "csle_agents.agents.dfsp_local.dfsp_local_ppo_agent.DFSPLocalPPOAgent.local_dfsp"]], "reduce_r() (in module csle_agents.agents.dfsp_local.dfsp_local_agent)": [[6, "csle_agents.agents.dfsp_local.dfsp_local_agent.reduce_R"]], "reduce_t() (in module csle_agents.agents.dfsp_local.dfsp_local_agent)": [[6, "csle_agents.agents.dfsp_local.dfsp_local_agent.reduce_T"]], "round_vec() (csle_agents.agents.dfsp_local.dfsp_local_agent.dfsplocalagent static method)": [[6, "csle_agents.agents.dfsp_local.dfsp_local_agent.DFSPLocalAgent.round_vec"]], "round_vec() (csle_agents.agents.dfsp_local.dfsp_local_ppo_agent.dfsplocalppoagent static method)": [[6, "csle_agents.agents.dfsp_local.dfsp_local_ppo_agent.DFSPLocalPPOAgent.round_vec"]], "running_average() (csle_agents.agents.dfsp_local.dfsp_local_agent.dfsplocalagent static method)": [[6, "csle_agents.agents.dfsp_local.dfsp_local_agent.DFSPLocalAgent.running_average"]], "running_average() (csle_agents.agents.dfsp_local.dfsp_local_ppo_agent.dfsplocalppoagent static method)": [[6, "csle_agents.agents.dfsp_local.dfsp_local_ppo_agent.DFSPLocalPPOAgent.running_average"]], "train() (csle_agents.agents.dfsp_local.dfsp_local_agent.dfsplocalagent method)": [[6, "csle_agents.agents.dfsp_local.dfsp_local_agent.DFSPLocalAgent.train"]], "train() (csle_agents.agents.dfsp_local.dfsp_local_ppo_agent.dfsplocalppoagent method)": [[6, "csle_agents.agents.dfsp_local.dfsp_local_ppo_agent.DFSPLocalPPOAgent.train"]], "update_metrics() (csle_agents.agents.dfsp_local.dfsp_local_agent.dfsplocalagent static method)": [[6, "csle_agents.agents.dfsp_local.dfsp_local_agent.DFSPLocalAgent.update_metrics"]], "update_metrics() (csle_agents.agents.dfsp_local.dfsp_local_ppo_agent.dfsplocalppoagent static method)": [[6, "csle_agents.agents.dfsp_local.dfsp_local_ppo_agent.DFSPLocalPPOAgent.update_metrics"]], "differentialevolutionagent (class in csle_agents.agents.differential_evolution.differential_evolution_agent)": [[7, "csle_agents.agents.differential_evolution.differential_evolution_agent.DifferentialEvolutionAgent"]], "compute_avg_metrics() (csle_agents.agents.differential_evolution.differential_evolution_agent.differentialevolutionagent static method)": [[7, "csle_agents.agents.differential_evolution.differential_evolution_agent.DifferentialEvolutionAgent.compute_avg_metrics"]], "csle_agents.agents.differential_evolution": [[7, "module-csle_agents.agents.differential_evolution"]], "csle_agents.agents.differential_evolution.differential_evolution_agent": [[7, "module-csle_agents.agents.differential_evolution.differential_evolution_agent"]], "differential_evolution() (csle_agents.agents.differential_evolution.differential_evolution_agent.differentialevolutionagent method)": [[7, "csle_agents.agents.differential_evolution.differential_evolution_agent.DifferentialEvolutionAgent.differential_evolution"]], "ensure_bounds() (csle_agents.agents.differential_evolution.differential_evolution_agent.differentialevolutionagent method)": [[7, "csle_agents.agents.differential_evolution.differential_evolution_agent.DifferentialEvolutionAgent.ensure_bounds"]], "eval_theta() (csle_agents.agents.differential_evolution.differential_evolution_agent.differentialevolutionagent method)": [[7, "csle_agents.agents.differential_evolution.differential_evolution_agent.DifferentialEvolutionAgent.eval_theta"]], "get_policy() (csle_agents.agents.differential_evolution.differential_evolution_agent.differentialevolutionagent method)": [[7, "csle_agents.agents.differential_evolution.differential_evolution_agent.DifferentialEvolutionAgent.get_policy"]], "hparam_names() (csle_agents.agents.differential_evolution.differential_evolution_agent.differentialevolutionagent method)": [[7, "csle_agents.agents.differential_evolution.differential_evolution_agent.DifferentialEvolutionAgent.hparam_names"]], "initial_theta() (csle_agents.agents.differential_evolution.differential_evolution_agent.differentialevolutionagent static method)": [[7, "csle_agents.agents.differential_evolution.differential_evolution_agent.DifferentialEvolutionAgent.initial_theta"]], "round_vec() (csle_agents.agents.differential_evolution.differential_evolution_agent.differentialevolutionagent static method)": [[7, "csle_agents.agents.differential_evolution.differential_evolution_agent.DifferentialEvolutionAgent.round_vec"]], "train() (csle_agents.agents.differential_evolution.differential_evolution_agent.differentialevolutionagent method)": [[7, "csle_agents.agents.differential_evolution.differential_evolution_agent.DifferentialEvolutionAgent.train"]], "update_metrics() (csle_agents.agents.differential_evolution.differential_evolution_agent.differentialevolutionagent static method)": [[7, "csle_agents.agents.differential_evolution.differential_evolution_agent.DifferentialEvolutionAgent.update_metrics"]], "dqnagent (class in csle_agents.agents.dqn.dqn_agent)": [[8, "csle_agents.agents.dqn.dqn_agent.DQNAgent"]], "dqntrainingcallback (class in csle_agents.agents.dqn.dqn_agent)": [[8, "csle_agents.agents.dqn.dqn_agent.DQNTrainingCallback"]], "csle_agents.agents.dqn": [[8, "module-csle_agents.agents.dqn"]], "csle_agents.agents.dqn.dqn_agent": [[8, "module-csle_agents.agents.dqn.dqn_agent"]], "hparam_names() (csle_agents.agents.dqn.dqn_agent.dqnagent method)": [[8, "csle_agents.agents.dqn.dqn_agent.DQNAgent.hparam_names"]], "train() (csle_agents.agents.dqn.dqn_agent.dqnagent method)": [[8, "csle_agents.agents.dqn.dqn_agent.DQNAgent.train"]], "datacollectorprocess (class in csle_agents.agents.dynasec.dynasec_agent)": [[9, "csle_agents.agents.dynasec.dynasec_agent.DataCollectorProcess"]], "dynasecagent (class in csle_agents.agents.dynasec.dynasec_agent)": [[9, "csle_agents.agents.dynasec.dynasec_agent.DynaSecAgent"]], "emulationmonitorthread (class in csle_agents.agents.dynasec.dynasec_agent)": [[9, "csle_agents.agents.dynasec.dynasec_agent.EmulationMonitorThread"]], "emulationstatisticsthread (class in csle_agents.agents.dynasec.dynasec_agent)": [[9, "csle_agents.agents.dynasec.dynasec_agent.EmulationStatisticsThread"]], "policyevaluationthread (class in csle_agents.agents.dynasec.dynasec_agent)": [[9, "csle_agents.agents.dynasec.dynasec_agent.PolicyEvaluationThread"]], "policyoptimizationprocess (class in csle_agents.agents.dynasec.dynasec_agent)": [[9, "csle_agents.agents.dynasec.dynasec_agent.PolicyOptimizationProcess"]], "systemidentificationprocess (class in csle_agents.agents.dynasec.dynasec_agent)": [[9, "csle_agents.agents.dynasec.dynasec_agent.SystemIdentificationProcess"]], "csle_agents.agents.dynasec": [[9, "module-csle_agents.agents.dynasec"]], "csle_agents.agents.dynasec.dynasec_agent": [[9, "module-csle_agents.agents.dynasec.dynasec_agent"]], "eval_traces() (csle_agents.agents.dynasec.dynasec_agent.policyevaluationthread method)": [[9, "csle_agents.agents.dynasec.dynasec_agent.PolicyEvaluationThread.eval_traces"]], "get_z_from_system_model() (csle_agents.agents.dynasec.dynasec_agent.dynasecagent static method)": [[9, "csle_agents.agents.dynasec.dynasec_agent.DynaSecAgent.get_Z_from_system_model"]], "get_spsa_experiment_config() (csle_agents.agents.dynasec.dynasec_agent.dynasecagent method)": [[9, "csle_agents.agents.dynasec.dynasec_agent.DynaSecAgent.get_spsa_experiment_config"]], "hparam_names() (csle_agents.agents.dynasec.dynasec_agent.dynasecagent method)": [[9, "csle_agents.agents.dynasec.dynasec_agent.DynaSecAgent.hparam_names"]], "mean() (csle_agents.agents.dynasec.dynasec_agent.dynasecagent static method)": [[9, "csle_agents.agents.dynasec.dynasec_agent.DynaSecAgent.mean"]], "record_metrics() (csle_agents.agents.dynasec.dynasec_agent.dynasecagent method)": [[9, "csle_agents.agents.dynasec.dynasec_agent.DynaSecAgent.record_metrics"]], "record_metrics() (csle_agents.agents.dynasec.dynasec_agent.policyevaluationthread method)": [[9, "csle_agents.agents.dynasec.dynasec_agent.PolicyEvaluationThread.record_metrics"]], "run() (csle_agents.agents.dynasec.dynasec_agent.datacollectorprocess method)": [[9, "csle_agents.agents.dynasec.dynasec_agent.DataCollectorProcess.run"]], "run() (csle_agents.agents.dynasec.dynasec_agent.emulationmonitorthread method)": [[9, "csle_agents.agents.dynasec.dynasec_agent.EmulationMonitorThread.run"]], "run() (csle_agents.agents.dynasec.dynasec_agent.emulationstatisticsthread method)": [[9, "csle_agents.agents.dynasec.dynasec_agent.EmulationStatisticsThread.run"]], "run() (csle_agents.agents.dynasec.dynasec_agent.policyevaluationthread method)": [[9, "csle_agents.agents.dynasec.dynasec_agent.PolicyEvaluationThread.run"]], "run() (csle_agents.agents.dynasec.dynasec_agent.policyoptimizationprocess method)": [[9, "csle_agents.agents.dynasec.dynasec_agent.PolicyOptimizationProcess.run"]], "run() (csle_agents.agents.dynasec.dynasec_agent.systemidentificationprocess method)": [[9, "csle_agents.agents.dynasec.dynasec_agent.SystemIdentificationProcess.run"]], "train() (csle_agents.agents.dynasec.dynasec_agent.dynasecagent method)": [[9, "csle_agents.agents.dynasec.dynasec_agent.DynaSecAgent.train"]], "fictitiousplayagent (class in csle_agents.agents.fp.fictitious_play_agent)": [[10, "csle_agents.agents.fp.fictitious_play_agent.FictitiousPlayAgent"]], "best_response() (csle_agents.agents.fp.fictitious_play_agent.fictitiousplayagent method)": [[10, "csle_agents.agents.fp.fictitious_play_agent.FictitiousPlayAgent.best_response"]], "compute_avg_metrics() (csle_agents.agents.fp.fictitious_play_agent.fictitiousplayagent static method)": [[10, "csle_agents.agents.fp.fictitious_play_agent.FictitiousPlayAgent.compute_avg_metrics"]], "compute_empirical_strategy() (csle_agents.agents.fp.fictitious_play_agent.fictitiousplayagent method)": [[10, "csle_agents.agents.fp.fictitious_play_agent.FictitiousPlayAgent.compute_empirical_strategy"]], "csle_agents.agents.fp": [[10, "module-csle_agents.agents.fp"]], "csle_agents.agents.fp.fictitious_play_agent": [[10, "module-csle_agents.agents.fp.fictitious_play_agent"]], "fictitious_play() (csle_agents.agents.fp.fictitious_play_agent.fictitiousplayagent method)": [[10, "csle_agents.agents.fp.fictitious_play_agent.FictitiousPlayAgent.fictitious_play"]], "hparam_names() (csle_agents.agents.fp.fictitious_play_agent.fictitiousplayagent method)": [[10, "csle_agents.agents.fp.fictitious_play_agent.FictitiousPlayAgent.hparam_names"]], "round_vec() (csle_agents.agents.fp.fictitious_play_agent.fictitiousplayagent static method)": [[10, "csle_agents.agents.fp.fictitious_play_agent.FictitiousPlayAgent.round_vec"]], "train() (csle_agents.agents.fp.fictitious_play_agent.fictitiousplayagent method)": [[10, "csle_agents.agents.fp.fictitious_play_agent.FictitiousPlayAgent.train"]], "update_metrics() (csle_agents.agents.fp.fictitious_play_agent.fictitiousplayagent static method)": [[10, "csle_agents.agents.fp.fictitious_play_agent.FictitiousPlayAgent.update_metrics"]], "hsviagent (class in csle_agents.agents.hsvi.hsvi_agent)": [[11, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent"]], "approximate_projection_sawtooth() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[11, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.approximate_projection_sawtooth"]], "bayes_filter() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[11, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.bayes_filter"]], "csle_agents.agents.hsvi": [[11, "module-csle_agents.agents.hsvi"]], "csle_agents.agents.hsvi.hsvi_agent": [[11, "module-csle_agents.agents.hsvi.hsvi_agent"]], "excess() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[11, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.excess"]], "explore() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[11, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.explore"]], "generate_corner_belief() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[11, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.generate_corner_belief"]], "hparam_names() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[11, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.hparam_names"]], "hsvi() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[11, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.hsvi"]], "hsvi_algorithm() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[11, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.hsvi_algorithm"]], "initialize_lower_bound() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[11, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.initialize_lower_bound"]], "initialize_upper_bound() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[11, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.initialize_upper_bound"]], "interior_point_belief_val() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[11, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.interior_point_belief_val"]], "local_lower_bound_update() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[11, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.local_lower_bound_update"]], "local_updates() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[11, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.local_updates"]], "local_upper_bound_update() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[11, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.local_upper_bound_update"]], "lower_bound_backup() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[11, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.lower_bound_backup"]], "lower_bound_value() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[11, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.lower_bound_value"]], "lp_convex_hull_projection_lp() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[11, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.lp_convex_hull_projection_lp"]], "next_belief() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[11, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.next_belief"]], "observation_possible() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[11, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.observation_possible"]], "one_step_lookahead() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[11, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.one_step_lookahead"]], "p_o_given_b_a() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[11, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.p_o_given_b_a"]], "prune_upper_bound() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[11, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.prune_upper_bound"]], "q() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[11, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.q"]], "q_hat_interval() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[11, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.q_hat_interval"]], "simulate() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[11, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.simulate"]], "train() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[11, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.train"]], "update_corner_points() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[11, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.update_corner_points"]], "upper_bound_backup() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[11, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.upper_bound_backup"]], "upper_bound_value() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[11, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.upper_bound_value"]], "vi() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[11, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.vi"]], "width() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[11, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.width"]], "hsviosposgagent (class in csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent"]], "auxillary_game() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.auxillary_game"]], "bayes_filter() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.bayes_filter"]], "choose_a_o_for_exploration() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.choose_a_o_for_exploration"]], "combine_weights_and_pure_strategies_into_mixed_strategy() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.combine_weights_and_pure_strategies_into_mixed_strategy"]], "compute_delta() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.compute_delta"]], "compute_equilibrium_strategies_in_matrix_game() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.compute_equilibrium_strategies_in_matrix_game"]], "compute_matrix_game_value() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.compute_matrix_game_value"]], "csle_agents.agents.hsvi_os_posg": [[12, "module-csle_agents.agents.hsvi_os_posg"]], "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent": [[12, "module-csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent"]], "delta_lipschitz_envelope_of_upper_bound_value() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.delta_lipschitz_envelope_of_upper_bound_value"]], "excess() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.excess"]], "explore() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.explore"]], "generate_corner_belief() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.generate_corner_belief"]], "hparam_names() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.hparam_names"]], "hsvi() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.hsvi"]], "hsvi_os_posg() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.hsvi_os_posg"]], "initialize_lower_bound() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.initialize_lower_bound"]], "initialize_upper_bound() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.initialize_upper_bound"]], "local_lower_bound_update() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.local_lower_bound_update"]], "local_updates() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.local_updates"]], "local_upper_bound_update() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.local_upper_bound_update"]], "lower_bound_backup() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.lower_bound_backup"]], "lower_bound_value() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.lower_bound_value"]], "maxcomp_shapley_bellman_operator() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.maxcomp_shapley_bellman_operator"]], "mdp_reward_matrix_p2() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.mdp_reward_matrix_p2"]], "mdp_transition_tensor_p2() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.mdp_transition_tensor_p2"]], "next_belief() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.next_belief"]], "obtain_equilibrium_strategy_profiles_in_stage_game() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.obtain_equilibrium_strategy_profiles_in_stage_game"]], "one_step_lookahead() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.one_step_lookahead"]], "p_o_given_b_a1_a2() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.p_o_given_b_a1_a2"]], "p_o_given_b_pi_1_pi_2() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.p_o_given_b_pi_1_pi_2"]], "prune_upper_bound() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.prune_upper_bound"]], "rho() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.rho"]], "sample_d() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.sample_D"]], "si() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.si"]], "train() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.train"]], "upper_bound_backup() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.upper_bound_backup"]], "upper_bound_value() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.upper_bound_value"]], "valcomp() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.valcomp"]], "value_of_p1_strategy_static() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.value_of_p1_strategy_static"]], "vi() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.vi"]], "weighted_excess_gap() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.weighted_excess_gap"]], "width() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[12, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.width"]], "kieferwolfowitzagent (class in csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent)": [[13, "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.KieferWolfowitzAgent"]], "batch_gradient() (csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.kieferwolfowitzagent method)": [[13, "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.KieferWolfowitzAgent.batch_gradient"]], "compute_avg_metrics() (csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.kieferwolfowitzagent static method)": [[13, "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.KieferWolfowitzAgent.compute_avg_metrics"]], "csle_agents.agents.kiefer_wolfowitz": [[13, "module-csle_agents.agents.kiefer_wolfowitz"]], "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent": [[13, "module-csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent"]], "estimate_gk() (csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.kieferwolfowitzagent method)": [[13, "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.KieferWolfowitzAgent.estimate_gk"]], "eval_theta() (csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.kieferwolfowitzagent method)": [[13, "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.KieferWolfowitzAgent.eval_theta"]], "get_policy() (csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.kieferwolfowitzagent method)": [[13, "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.KieferWolfowitzAgent.get_policy"]], "hparam_names() (csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.kieferwolfowitzagent method)": [[13, "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.KieferWolfowitzAgent.hparam_names"]], "initial_theta() (csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.kieferwolfowitzagent static method)": [[13, "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.KieferWolfowitzAgent.initial_theta"]], "kiefer_wolfowitz() (csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.kieferwolfowitzagent method)": [[13, "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.KieferWolfowitzAgent.kiefer_wolfowitz"]], "round_vec() (csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.kieferwolfowitzagent static method)": [[13, "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.KieferWolfowitzAgent.round_vec"]], "train() (csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.kieferwolfowitzagent method)": [[13, "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.KieferWolfowitzAgent.train"]], "update_metrics() (csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.kieferwolfowitzagent static method)": [[13, "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.KieferWolfowitzAgent.update_metrics"]], "linearprogrammingnormalformgameagent (class in csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent)": [[14, "csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.LinearProgrammingNormalFormGameAgent"]], "compute_avg_metrics() (csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.linearprogrammingnormalformgameagent static method)": [[14, "csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.LinearProgrammingNormalFormGameAgent.compute_avg_metrics"]], "compute_equilibrium_strategies_in_matrix_game() (csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.linearprogrammingnormalformgameagent method)": [[14, "csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.LinearProgrammingNormalFormGameAgent.compute_equilibrium_strategies_in_matrix_game"]], "compute_matrix_game_value() (csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.linearprogrammingnormalformgameagent method)": [[14, "csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.LinearProgrammingNormalFormGameAgent.compute_matrix_game_value"]], "csle_agents.agents.lp_nf": [[14, "module-csle_agents.agents.lp_nf"]], "csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent": [[14, "module-csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent"]], "hparam_names() (csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.linearprogrammingnormalformgameagent method)": [[14, "csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.LinearProgrammingNormalFormGameAgent.hparam_names"]], "linear_programming_normal_form() (csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.linearprogrammingnormalformgameagent method)": [[14, "csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.LinearProgrammingNormalFormGameAgent.linear_programming_normal_form"]], "round_vec() (csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.linearprogrammingnormalformgameagent static method)": [[14, "csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.LinearProgrammingNormalFormGameAgent.round_vec"]], "train() (csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.linearprogrammingnormalformgameagent method)": [[14, "csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.LinearProgrammingNormalFormGameAgent.train"]], "update_metrics() (csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.linearprogrammingnormalformgameagent static method)": [[14, "csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.LinearProgrammingNormalFormGameAgent.update_metrics"]], "piagent (class in csle_agents.agents.pi.pi_agent)": [[15, "csle_agents.agents.pi.pi_agent.PIAgent"]], "csle_agents.agents.pi": [[15, "module-csle_agents.agents.pi"]], "csle_agents.agents.pi.pi_agent": [[15, "module-csle_agents.agents.pi.pi_agent"]], "evaluate_policy() (csle_agents.agents.pi.pi_agent.piagent method)": [[15, "csle_agents.agents.pi.pi_agent.PIAgent.evaluate_policy"]], "expected_reward_under_policy() (csle_agents.agents.pi.pi_agent.piagent method)": [[15, "csle_agents.agents.pi.pi_agent.PIAgent.expected_reward_under_policy"]], "hparam_names() (csle_agents.agents.pi.pi_agent.piagent method)": [[15, "csle_agents.agents.pi.pi_agent.PIAgent.hparam_names"]], "pi() (csle_agents.agents.pi.pi_agent.piagent method)": [[15, "csle_agents.agents.pi.pi_agent.PIAgent.pi"]], "policy_evaluation() (csle_agents.agents.pi.pi_agent.piagent method)": [[15, "csle_agents.agents.pi.pi_agent.PIAgent.policy_evaluation"]], "policy_improvement() (csle_agents.agents.pi.pi_agent.piagent method)": [[15, "csle_agents.agents.pi.pi_agent.PIAgent.policy_improvement"]], "policy_iteration() (csle_agents.agents.pi.pi_agent.piagent method)": [[15, "csle_agents.agents.pi.pi_agent.PIAgent.policy_iteration"]], "train() (csle_agents.agents.pi.pi_agent.piagent method)": [[15, "csle_agents.agents.pi.pi_agent.PIAgent.train"]], "transition_probability_under_policy() (csle_agents.agents.pi.pi_agent.piagent method)": [[15, "csle_agents.agents.pi.pi_agent.PIAgent.transition_probability_under_policy"]], "ppoagent (class in csle_agents.agents.ppo.ppo_agent)": [[16, "csle_agents.agents.ppo.ppo_agent.PPOAgent"]], "ppotrainingcallback (class in csle_agents.agents.ppo.ppo_agent)": [[16, "csle_agents.agents.ppo.ppo_agent.PPOTrainingCallback"]], "csle_agents.agents.ppo": [[16, "module-csle_agents.agents.ppo"]], "csle_agents.agents.ppo.ppo_agent": [[16, "module-csle_agents.agents.ppo.ppo_agent"]], "hparam_names() (csle_agents.agents.ppo.ppo_agent.ppoagent method)": [[16, "csle_agents.agents.ppo.ppo_agent.PPOAgent.hparam_names"]], "train() (csle_agents.agents.ppo.ppo_agent.ppoagent method)": [[16, "csle_agents.agents.ppo.ppo_agent.PPOAgent.train"]], "qlearningagent (class in csle_agents.agents.q_learning.q_learning_agent)": [[17, "csle_agents.agents.q_learning.q_learning_agent.QLearningAgent"]], "create_policy_from_q_table() (csle_agents.agents.q_learning.q_learning_agent.qlearningagent method)": [[17, "csle_agents.agents.q_learning.q_learning_agent.QLearningAgent.create_policy_from_q_table"]], "csle_agents.agents.q_learning": [[17, "module-csle_agents.agents.q_learning"]], "csle_agents.agents.q_learning.q_learning_agent": [[17, "module-csle_agents.agents.q_learning.q_learning_agent"]], "eps_greedy() (csle_agents.agents.q_learning.q_learning_agent.qlearningagent method)": [[17, "csle_agents.agents.q_learning.q_learning_agent.QLearningAgent.eps_greedy"]], "evaluate_policy() (csle_agents.agents.q_learning.q_learning_agent.qlearningagent method)": [[17, "csle_agents.agents.q_learning.q_learning_agent.QLearningAgent.evaluate_policy"]], "hparam_names() (csle_agents.agents.q_learning.q_learning_agent.qlearningagent method)": [[17, "csle_agents.agents.q_learning.q_learning_agent.QLearningAgent.hparam_names"]], "initialize_count_table() (csle_agents.agents.q_learning.q_learning_agent.qlearningagent method)": [[17, "csle_agents.agents.q_learning.q_learning_agent.QLearningAgent.initialize_count_table"]], "initialize_q_table() (csle_agents.agents.q_learning.q_learning_agent.qlearningagent method)": [[17, "csle_agents.agents.q_learning.q_learning_agent.QLearningAgent.initialize_q_table"]], "q_learning() (csle_agents.agents.q_learning.q_learning_agent.qlearningagent method)": [[17, "csle_agents.agents.q_learning.q_learning_agent.QLearningAgent.q_learning"]], "q_learning_update() (csle_agents.agents.q_learning.q_learning_agent.qlearningagent method)": [[17, "csle_agents.agents.q_learning.q_learning_agent.QLearningAgent.q_learning_update"]], "step_size() (csle_agents.agents.q_learning.q_learning_agent.qlearningagent method)": [[17, "csle_agents.agents.q_learning.q_learning_agent.QLearningAgent.step_size"]], "train() (csle_agents.agents.q_learning.q_learning_agent.qlearningagent method)": [[17, "csle_agents.agents.q_learning.q_learning_agent.QLearningAgent.train"]], "train_q_learning() (csle_agents.agents.q_learning.q_learning_agent.qlearningagent method)": [[17, "csle_agents.agents.q_learning.q_learning_agent.QLearningAgent.train_q_learning"]], "randomsearchagent (class in csle_agents.agents.random_search.random_search_agent)": [[18, "csle_agents.agents.random_search.random_search_agent.RandomSearchAgent"]], "compute_avg_metrics() (csle_agents.agents.random_search.random_search_agent.randomsearchagent static method)": [[18, "csle_agents.agents.random_search.random_search_agent.RandomSearchAgent.compute_avg_metrics"]], "csle_agents.agents.random_search": [[18, "module-csle_agents.agents.random_search"]], "csle_agents.agents.random_search.random_search_agent": [[18, "module-csle_agents.agents.random_search.random_search_agent"]], "eval_theta() (csle_agents.agents.random_search.random_search_agent.randomsearchagent method)": [[18, "csle_agents.agents.random_search.random_search_agent.RandomSearchAgent.eval_theta"]], "get_policy() (csle_agents.agents.random_search.random_search_agent.randomsearchagent method)": [[18, "csle_agents.agents.random_search.random_search_agent.RandomSearchAgent.get_policy"]], "hparam_names() (csle_agents.agents.random_search.random_search_agent.randomsearchagent method)": [[18, "csle_agents.agents.random_search.random_search_agent.RandomSearchAgent.hparam_names"]], "initial_theta() (csle_agents.agents.random_search.random_search_agent.randomsearchagent static method)": [[18, "csle_agents.agents.random_search.random_search_agent.RandomSearchAgent.initial_theta"]], "random_perturbation() (csle_agents.agents.random_search.random_search_agent.randomsearchagent method)": [[18, "csle_agents.agents.random_search.random_search_agent.RandomSearchAgent.random_perturbation"]], "random_search() (csle_agents.agents.random_search.random_search_agent.randomsearchagent method)": [[18, "csle_agents.agents.random_search.random_search_agent.RandomSearchAgent.random_search"]], "round_vec() (csle_agents.agents.random_search.random_search_agent.randomsearchagent static method)": [[18, "csle_agents.agents.random_search.random_search_agent.RandomSearchAgent.round_vec"]], "train() (csle_agents.agents.random_search.random_search_agent.randomsearchagent method)": [[18, "csle_agents.agents.random_search.random_search_agent.RandomSearchAgent.train"]], "update_metrics() (csle_agents.agents.random_search.random_search_agent.randomsearchagent static method)": [[18, "csle_agents.agents.random_search.random_search_agent.RandomSearchAgent.update_metrics"]], "reinforceagent (class in csle_agents.agents.reinforce.reinforce_agent)": [[19, "csle_agents.agents.reinforce.reinforce_agent.ReinforceAgent"]], "compute_avg_metrics() (csle_agents.agents.reinforce.reinforce_agent.reinforceagent static method)": [[19, "csle_agents.agents.reinforce.reinforce_agent.ReinforceAgent.compute_avg_metrics"]], "csle_agents.agents.reinforce": [[19, "module-csle_agents.agents.reinforce"]], "csle_agents.agents.reinforce.reinforce_agent": [[19, "module-csle_agents.agents.reinforce.reinforce_agent"]], "hparam_names() (csle_agents.agents.reinforce.reinforce_agent.reinforceagent method)": [[19, "csle_agents.agents.reinforce.reinforce_agent.ReinforceAgent.hparam_names"]], "reinforce() (csle_agents.agents.reinforce.reinforce_agent.reinforceagent method)": [[19, "csle_agents.agents.reinforce.reinforce_agent.ReinforceAgent.reinforce"]], "round_vec() (csle_agents.agents.reinforce.reinforce_agent.reinforceagent static method)": [[19, "csle_agents.agents.reinforce.reinforce_agent.ReinforceAgent.round_vec"]], "train() (csle_agents.agents.reinforce.reinforce_agent.reinforceagent method)": [[19, "csle_agents.agents.reinforce.reinforce_agent.ReinforceAgent.train"]], "training_step() (csle_agents.agents.reinforce.reinforce_agent.reinforceagent method)": [[19, "csle_agents.agents.reinforce.reinforce_agent.ReinforceAgent.training_step"]], "update_metrics() (csle_agents.agents.reinforce.reinforce_agent.reinforceagent static method)": [[19, "csle_agents.agents.reinforce.reinforce_agent.ReinforceAgent.update_metrics"]], "sarsaagent (class in csle_agents.agents.sarsa.sarsa_agent)": [[20, "csle_agents.agents.sarsa.sarsa_agent.SARSAAgent"]], "create_policy_from_q_table() (csle_agents.agents.sarsa.sarsa_agent.sarsaagent method)": [[20, "csle_agents.agents.sarsa.sarsa_agent.SARSAAgent.create_policy_from_q_table"]], "csle_agents.agents.sarsa": [[20, "module-csle_agents.agents.sarsa"]], "csle_agents.agents.sarsa.sarsa_agent": [[20, "module-csle_agents.agents.sarsa.sarsa_agent"]], "eps_greedy() (csle_agents.agents.sarsa.sarsa_agent.sarsaagent method)": [[20, "csle_agents.agents.sarsa.sarsa_agent.SARSAAgent.eps_greedy"]], "evaluate_policy() (csle_agents.agents.sarsa.sarsa_agent.sarsaagent method)": [[20, "csle_agents.agents.sarsa.sarsa_agent.SARSAAgent.evaluate_policy"]], "hparam_names() (csle_agents.agents.sarsa.sarsa_agent.sarsaagent method)": [[20, "csle_agents.agents.sarsa.sarsa_agent.SARSAAgent.hparam_names"]], "initialize_count_table() (csle_agents.agents.sarsa.sarsa_agent.sarsaagent method)": [[20, "csle_agents.agents.sarsa.sarsa_agent.SARSAAgent.initialize_count_table"]], "initialize_q_table() (csle_agents.agents.sarsa.sarsa_agent.sarsaagent method)": [[20, "csle_agents.agents.sarsa.sarsa_agent.SARSAAgent.initialize_q_table"]], "q_learning() (csle_agents.agents.sarsa.sarsa_agent.sarsaagent method)": [[20, "csle_agents.agents.sarsa.sarsa_agent.SARSAAgent.q_learning"]], "sarsa_update() (csle_agents.agents.sarsa.sarsa_agent.sarsaagent method)": [[20, "csle_agents.agents.sarsa.sarsa_agent.SARSAAgent.sarsa_update"]], "step_size() (csle_agents.agents.sarsa.sarsa_agent.sarsaagent method)": [[20, "csle_agents.agents.sarsa.sarsa_agent.SARSAAgent.step_size"]], "train() (csle_agents.agents.sarsa.sarsa_agent.sarsaagent method)": [[20, "csle_agents.agents.sarsa.sarsa_agent.SARSAAgent.train"]], "train_sarsa() (csle_agents.agents.sarsa.sarsa_agent.sarsaagent method)": [[20, "csle_agents.agents.sarsa.sarsa_agent.SARSAAgent.train_sarsa"]], "shapleyiterationagent (class in csle_agents.agents.shapley_iteration.shapley_iteration_agent)": [[21, "csle_agents.agents.shapley_iteration.shapley_iteration_agent.ShapleyIterationAgent"]], "auxillary_game() (csle_agents.agents.shapley_iteration.shapley_iteration_agent.shapleyiterationagent method)": [[21, "csle_agents.agents.shapley_iteration.shapley_iteration_agent.ShapleyIterationAgent.auxillary_game"]], "compute_matrix_game_value() (csle_agents.agents.shapley_iteration.shapley_iteration_agent.shapleyiterationagent method)": [[21, "csle_agents.agents.shapley_iteration.shapley_iteration_agent.ShapleyIterationAgent.compute_matrix_game_value"]], "csle_agents.agents.shapley_iteration": [[21, "module-csle_agents.agents.shapley_iteration"]], "csle_agents.agents.shapley_iteration.shapley_iteration_agent": [[21, "module-csle_agents.agents.shapley_iteration.shapley_iteration_agent"]], "hparam_names() (csle_agents.agents.shapley_iteration.shapley_iteration_agent.shapleyiterationagent method)": [[21, "csle_agents.agents.shapley_iteration.shapley_iteration_agent.ShapleyIterationAgent.hparam_names"]], "shapley_iteration() (csle_agents.agents.shapley_iteration.shapley_iteration_agent.shapleyiterationagent method)": [[21, "csle_agents.agents.shapley_iteration.shapley_iteration_agent.ShapleyIterationAgent.shapley_iteration"]], "si() (csle_agents.agents.shapley_iteration.shapley_iteration_agent.shapleyiterationagent method)": [[21, "csle_agents.agents.shapley_iteration.shapley_iteration_agent.ShapleyIterationAgent.si"]], "train() (csle_agents.agents.shapley_iteration.shapley_iteration_agent.shapleyiterationagent method)": [[21, "csle_agents.agents.shapley_iteration.shapley_iteration_agent.ShapleyIterationAgent.train"]], "sondikviagent (class in csle_agents.agents.sondik_vi.sondik_vi_agent)": [[22, "csle_agents.agents.sondik_vi.sondik_vi_agent.SondikVIAgent"]], "check_duplicate() (csle_agents.agents.sondik_vi.sondik_vi_agent.sondikviagent method)": [[22, "csle_agents.agents.sondik_vi.sondik_vi_agent.SondikVIAgent.check_duplicate"]], "compute_all_conditional_plans_conditioned_on_a_t() (csle_agents.agents.sondik_vi.sondik_vi_agent.sondikviagent method)": [[22, "csle_agents.agents.sondik_vi.sondik_vi_agent.SondikVIAgent.compute_all_conditional_plans_conditioned_on_a_t"]], "csle_agents.agents.sondik_vi": [[22, "module-csle_agents.agents.sondik_vi"]], "csle_agents.agents.sondik_vi.sondik_vi_agent": [[22, "module-csle_agents.agents.sondik_vi.sondik_vi_agent"]], "evaluate_policy() (csle_agents.agents.sondik_vi.sondik_vi_agent.sondikviagent method)": [[22, "csle_agents.agents.sondik_vi.sondik_vi_agent.SondikVIAgent.evaluate_policy"]], "hparam_names() (csle_agents.agents.sondik_vi.sondik_vi_agent.sondikviagent method)": [[22, "csle_agents.agents.sondik_vi.sondik_vi_agent.SondikVIAgent.hparam_names"]], "prune() (csle_agents.agents.sondik_vi.sondik_vi_agent.sondikviagent method)": [[22, "csle_agents.agents.sondik_vi.sondik_vi_agent.SondikVIAgent.prune"]], "sondik_vi() (csle_agents.agents.sondik_vi.sondik_vi_agent.sondikviagent method)": [[22, "csle_agents.agents.sondik_vi.sondik_vi_agent.SondikVIAgent.sondik_vi"]], "sondik_vi_algorithm() (csle_agents.agents.sondik_vi.sondik_vi_agent.sondikviagent method)": [[22, "csle_agents.agents.sondik_vi.sondik_vi_agent.SondikVIAgent.sondik_vi_algorithm"]], "train() (csle_agents.agents.sondik_vi.sondik_vi_agent.sondikviagent method)": [[22, "csle_agents.agents.sondik_vi.sondik_vi_agent.SondikVIAgent.train"]], "tfpagent (class in csle_agents.agents.t_fp.t_fp_agent)": [[23, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent"]], "attacker_best_response() (csle_agents.agents.t_fp.t_fp_agent.tfpagent method)": [[23, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.attacker_best_response"]], "compute_avg_metrics() (csle_agents.agents.t_fp.t_fp_agent.tfpagent static method)": [[23, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.compute_avg_metrics"]], "csle_agents.agents.t_fp": [[23, "module-csle_agents.agents.t_fp"]], "csle_agents.agents.t_fp.t_fp_agent": [[23, "module-csle_agents.agents.t_fp.t_fp_agent"]], "defender_best_response() (csle_agents.agents.t_fp.t_fp_agent.tfpagent method)": [[23, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.defender_best_response"]], "evaluate_attacker_policy() (csle_agents.agents.t_fp.t_fp_agent.tfpagent method)": [[23, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.evaluate_attacker_policy"]], "evaluate_defender_policy() (csle_agents.agents.t_fp.t_fp_agent.tfpagent method)": [[23, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.evaluate_defender_policy"]], "evaluate_strategy_profile() (csle_agents.agents.t_fp.t_fp_agent.tfpagent method)": [[23, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.evaluate_strategy_profile"]], "exploitability() (csle_agents.agents.t_fp.t_fp_agent.tfpagent static method)": [[23, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.exploitability"]], "get_attacker_experiment_config() (csle_agents.agents.t_fp.t_fp_agent.tfpagent method)": [[23, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.get_attacker_experiment_config"]], "get_defender_experiment_config() (csle_agents.agents.t_fp.t_fp_agent.tfpagent method)": [[23, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.get_defender_experiment_config"]], "hparam_names() (csle_agents.agents.t_fp.t_fp_agent.tfpagent method)": [[23, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.hparam_names"]], "round_vec() (csle_agents.agents.t_fp.t_fp_agent.tfpagent static method)": [[23, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.round_vec"]], "running_average() (csle_agents.agents.t_fp.t_fp_agent.tfpagent static method)": [[23, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.running_average"]], "t_fp() (csle_agents.agents.t_fp.t_fp_agent.tfpagent method)": [[23, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.t_fp"]], "train() (csle_agents.agents.t_fp.t_fp_agent.tfpagent method)": [[23, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.train"]], "update_metrics() (csle_agents.agents.t_fp.t_fp_agent.tfpagent static method)": [[23, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.update_metrics"]], "tspsaagent (class in csle_agents.agents.t_spsa.t_spsa_agent)": [[24, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent"]], "batch_gradient() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent method)": [[24, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.batch_gradient"]], "compute_avg_metrics() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent static method)": [[24, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.compute_avg_metrics"]], "csle_agents.agents.t_spsa": [[24, "module-csle_agents.agents.t_spsa"]], "csle_agents.agents.t_spsa.t_spsa_agent": [[24, "module-csle_agents.agents.t_spsa.t_spsa_agent"]], "estimate_gk() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent method)": [[24, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.estimate_gk"]], "eval_theta() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent method)": [[24, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.eval_theta"]], "get_policy() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent method)": [[24, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.get_policy"]], "hparam_names() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent method)": [[24, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.hparam_names"]], "initial_theta() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent static method)": [[24, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.initial_theta"]], "round_vec() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent static method)": [[24, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.round_vec"]], "spsa() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent method)": [[24, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.spsa"]], "standard_ak() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent static method)": [[24, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.standard_ak"]], "standard_ck() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent static method)": [[24, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.standard_ck"]], "standard_deltak() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent static method)": [[24, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.standard_deltak"]], "train() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent method)": [[24, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.train"]], "update_metrics() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent static method)": [[24, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.update_metrics"]], "viagent (class in csle_agents.agents.vi.vi_agent)": [[25, "csle_agents.agents.vi.vi_agent.VIAgent"]], "create_policy_from_value_function() (csle_agents.agents.vi.vi_agent.viagent method)": [[25, "csle_agents.agents.vi.vi_agent.VIAgent.create_policy_from_value_function"]], "csle_agents.agents.vi": [[25, "module-csle_agents.agents.vi"]], "csle_agents.agents.vi.vi_agent": [[25, "module-csle_agents.agents.vi.vi_agent"]], "evaluate_policy() (csle_agents.agents.vi.vi_agent.viagent method)": [[25, "csle_agents.agents.vi.vi_agent.VIAgent.evaluate_policy"]], "hparam_names() (csle_agents.agents.vi.vi_agent.viagent method)": [[25, "csle_agents.agents.vi.vi_agent.VIAgent.hparam_names"]], "one_step_lookahead() (csle_agents.agents.vi.vi_agent.viagent method)": [[25, "csle_agents.agents.vi.vi_agent.VIAgent.one_step_lookahead"]], "train() (csle_agents.agents.vi.vi_agent.viagent method)": [[25, "csle_agents.agents.vi.vi_agent.VIAgent.train"]], "value_iteration() (csle_agents.agents.vi.vi_agent.viagent method)": [[25, "csle_agents.agents.vi.vi_agent.VIAgent.value_iteration"]], "vi() (csle_agents.agents.vi.vi_agent.viagent method)": [[25, "csle_agents.agents.vi.vi_agent.VIAgent.vi"]], "fnnwithgaussian (class in csle_agents.common.fnn_w_gaussian)": [[26, "csle_agents.common.fnn_w_gaussian.FNNwithGaussian"]], "fnnwithlinear (class in csle_agents.common.fnn_w_linear)": [[26, "csle_agents.common.fnn_w_linear.FNNwithLinear"]], "check_dominance_lp() (in module csle_agents.common.pruning)": [[26, "csle_agents.common.pruning.check_dominance_lp"]], "check_duplicate() (in module csle_agents.common.pruning)": [[26, "csle_agents.common.pruning.check_duplicate"]], "csle_agents.common": [[26, "module-csle_agents.common"]], "csle_agents.common.fnn_w_gaussian": [[26, "module-csle_agents.common.fnn_w_gaussian"]], "csle_agents.common.fnn_w_linear": [[26, "module-csle_agents.common.fnn_w_linear"]], "csle_agents.common.pruning": [[26, "module-csle_agents.common.pruning"]], "forward() (csle_agents.common.fnn_w_gaussian.fnnwithgaussian method)": [[26, "csle_agents.common.fnn_w_gaussian.FNNwithGaussian.forward"]], "forward() (csle_agents.common.fnn_w_linear.fnnwithlinear method)": [[26, "csle_agents.common.fnn_w_linear.FNNwithLinear.forward"]], "get_hidden_activation() (csle_agents.common.fnn_w_gaussian.fnnwithgaussian method)": [[26, "csle_agents.common.fnn_w_gaussian.FNNwithGaussian.get_hidden_activation"]], "get_hidden_activation() (csle_agents.common.fnn_w_linear.fnnwithlinear method)": [[26, "csle_agents.common.fnn_w_linear.FNNwithLinear.get_hidden_activation"]], "prune_lower_bound() (in module csle_agents.common.pruning)": [[26, "csle_agents.common.pruning.prune_lower_bound"]], "test() (in module csle_agents.common.fnn_w_gaussian)": [[26, "csle_agents.common.fnn_w_gaussian.test"]], "test() (in module csle_agents.common.fnn_w_linear)": [[26, "csle_agents.common.fnn_w_linear.test"]], "a (csle_agents.constants.constants.q_learning attribute)": [[27, "csle_agents.constants.constants.Q_LEARNING.A"]], "a (csle_agents.constants.constants.sarsa attribute)": [[27, "csle_agents.constants.constants.SARSA.A"]], "action_space (csle_agents.constants.constants.hsvi attribute)": [[27, "csle_agents.constants.constants.HSVI.ACTION_SPACE"]], "action_space (csle_agents.constants.constants.sondik_vi attribute)": [[27, "csle_agents.constants.constants.SONDIK_VI.ACTION_SPACE"]], "action_space_player_1 (csle_agents.constants.constants.hsvi_os_posg attribute)": [[27, "csle_agents.constants.constants.HSVI_OS_POSG.ACTION_SPACE_PLAYER_1"]], "action_space_player_1 (csle_agents.constants.constants.lp_for_nf_games attribute)": [[27, "csle_agents.constants.constants.LP_FOR_NF_GAMES.ACTION_SPACE_PLAYER_1"]], "action_space_player_1 (csle_agents.constants.constants.shapley_iteration attribute)": [[27, "csle_agents.constants.constants.SHAPLEY_ITERATION.ACTION_SPACE_PLAYER_1"]], "action_space_player_2 (csle_agents.constants.constants.hsvi_os_posg attribute)": [[27, "csle_agents.constants.constants.HSVI_OS_POSG.ACTION_SPACE_PLAYER_2"]], "action_space_player_2 (csle_agents.constants.constants.lp_for_nf_games attribute)": [[27, "csle_agents.constants.constants.LP_FOR_NF_GAMES.ACTION_SPACE_PLAYER_2"]], "action_space_player_2 (csle_agents.constants.constants.shapley_iteration attribute)": [[27, "csle_agents.constants.constants.SHAPLEY_ITERATION.ACTION_SPACE_PLAYER_2"]], "adam (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.ADAM"]], "attacker_action (csle_agents.constants.constants.env_metrics attribute)": [[27, "csle_agents.constants.constants.ENV_METRICS.ATTACKER_ACTION"]], "attacker_thresholds (csle_agents.constants.constants.t_fp attribute)": [[27, "csle_agents.constants.constants.T_FP.ATTACKER_THRESHOLDS"]], "average_attacker_return (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.AVERAGE_ATTACKER_RETURN"]], "average_best_response_attacker_return (csle_agents.constants.constants.local_dfsp attribute)": [[27, "csle_agents.constants.constants.LOCAL_DFSP.AVERAGE_BEST_RESPONSE_ATTACKER_RETURN"]], "average_best_response_attacker_return (csle_agents.constants.constants.t_fp attribute)": [[27, "csle_agents.constants.constants.T_FP.AVERAGE_BEST_RESPONSE_ATTACKER_RETURN"]], "average_best_response_defender_return (csle_agents.constants.constants.local_dfsp attribute)": [[27, "csle_agents.constants.constants.LOCAL_DFSP.AVERAGE_BEST_RESPONSE_DEFENDER_RETURN"]], "average_best_response_defender_return (csle_agents.constants.constants.t_fp attribute)": [[27, "csle_agents.constants.constants.T_FP.AVERAGE_BEST_RESPONSE_DEFENDER_RETURN"]], "average_defender_return (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.AVERAGE_DEFENDER_RETURN"]], "average_heuristic_return (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.AVERAGE_HEURISTIC_RETURN"]], "average_heuristic_return (csle_agents.constants.constants.env_metrics attribute)": [[27, "csle_agents.constants.constants.ENV_METRICS.AVERAGE_HEURISTIC_RETURN"]], "average_random_return (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.AVERAGE_RANDOM_RETURN"]], "average_random_return (csle_agents.constants.constants.env_metrics attribute)": [[27, "csle_agents.constants.constants.ENV_METRICS.AVERAGE_RANDOM_RETURN"]], "average_return (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.AVERAGE_RETURN"]], "average_time_horizon (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.AVERAGE_TIME_HORIZON"]], "average_upper_bound_return (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.AVERAGE_UPPER_BOUND_RETURN"]], "average_upper_bound_return (csle_agents.constants.constants.env_metrics attribute)": [[27, "csle_agents.constants.constants.ENV_METRICS.AVERAGE_UPPER_BOUND_RETURN"]], "baseline_prefix (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.BASELINE_PREFIX"]], "batch_size (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.BATCH_SIZE"]], "bayesian_optimization (class in csle_agents.constants.constants)": [[27, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION"]], "best_response_evaluation_iterations (csle_agents.constants.constants.local_dfsp attribute)": [[27, "csle_agents.constants.constants.LOCAL_DFSP.BEST_RESPONSE_EVALUATION_ITERATIONS"]], "best_response_evaluation_iterations (csle_agents.constants.constants.t_fp attribute)": [[27, "csle_agents.constants.constants.T_FP.BEST_RESPONSE_EVALUATION_ITERATIONS"]], "bounds (csle_agents.constants.constants.differential_evolution attribute)": [[27, "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION.BOUNDS"]], "buffer_size (csle_agents.constants.constants.dqn attribute)": [[27, "csle_agents.constants.constants.DQN.BUFFER_SIZE"]], "clients_arrival_rate (csle_agents.constants.constants.dynasec attribute)": [[27, "csle_agents.constants.constants.DYNASEC.CLIENTS_ARRIVAL_RATE"]], "clip_gradient (csle_agents.constants.constants.reinforce attribute)": [[27, "csle_agents.constants.constants.REINFORCE.CLIP_GRADIENT"]], "clip_range (csle_agents.constants.constants.ppo attribute)": [[27, "csle_agents.constants.constants.PPO.CLIP_RANGE"]], "clip_range_vf (csle_agents.constants.constants.ppo attribute)": [[27, "csle_agents.constants.constants.PPO.CLIP_RANGE_VF"]], "common (class in csle_agents.constants.constants)": [[27, "csle_agents.constants.constants.COMMON"]], "confidence_interval (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.CONFIDENCE_INTERVAL"]], "cross_entropy (class in csle_agents.constants.constants)": [[27, "csle_agents.constants.constants.CROSS_ENTROPY"]], "defender_action (csle_agents.constants.constants.env_metrics attribute)": [[27, "csle_agents.constants.constants.ENV_METRICS.DEFENDER_ACTION"]], "defender_thresholds (csle_agents.constants.constants.t_fp attribute)": [[27, "csle_agents.constants.constants.T_FP.DEFENDER_THRESHOLDS"]], "delta (csle_agents.constants.constants.kiefer_wolfowitz attribute)": [[27, "csle_agents.constants.constants.KIEFER_WOLFOWITZ.DELTA"]], "delta (csle_agents.constants.constants.random_search attribute)": [[27, "csle_agents.constants.constants.RANDOM_SEARCH.DELTA"]], "delta (csle_agents.constants.constants.shapley_iteration attribute)": [[27, "csle_agents.constants.constants.SHAPLEY_ITERATION.DELTA"]], "delta (csle_agents.constants.constants.vi attribute)": [[27, "csle_agents.constants.constants.VI.DELTA"]], "differential_evolution (class in csle_agents.constants.constants)": [[27, "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION"]], "dqn (class in csle_agents.constants.constants)": [[27, "csle_agents.constants.constants.DQN"]], "dqn_batch_size (csle_agents.constants.constants.dqn attribute)": [[27, "csle_agents.constants.constants.DQN.DQN_BATCH_SIZE"]], "dynasec (class in csle_agents.constants.constants)": [[27, "csle_agents.constants.constants.DYNASEC"]], "emulation_monitor_sleep_time (csle_agents.constants.constants.dynasec attribute)": [[27, "csle_agents.constants.constants.DYNASEC.EMULATION_MONITOR_SLEEP_TIME"]], "emulation_traces_to_save_w_data_collection_job (csle_agents.constants.constants.dynasec attribute)": [[27, "csle_agents.constants.constants.DYNASEC.EMULATION_TRACES_TO_SAVE_W_DATA_COLLECTION_JOB"]], "ent_coef (csle_agents.constants.constants.ppo attribute)": [[27, "csle_agents.constants.constants.PPO.ENT_COEF"]], "env_metrics (class in csle_agents.constants.constants)": [[27, "csle_agents.constants.constants.ENV_METRICS"]], "epsilon (csle_agents.constants.constants.hsvi attribute)": [[27, "csle_agents.constants.constants.HSVI.EPSILON"]], "epsilon (csle_agents.constants.constants.hsvi_os_posg attribute)": [[27, "csle_agents.constants.constants.HSVI_OS_POSG.EPSILON"]], "epsilon (csle_agents.constants.constants.q_learning attribute)": [[27, "csle_agents.constants.constants.Q_LEARNING.EPSILON"]], "epsilon (csle_agents.constants.constants.sarsa attribute)": [[27, "csle_agents.constants.constants.SARSA.EPSILON"]], "equilibrium_strategies_evaluation_iterations (csle_agents.constants.constants.local_dfsp attribute)": [[27, "csle_agents.constants.constants.LOCAL_DFSP.EQUILIBRIUM_STRATEGIES_EVALUATION_ITERATIONS"]], "equilibrium_strategies_evaluation_iterations (csle_agents.constants.constants.t_fp attribute)": [[27, "csle_agents.constants.constants.T_FP.EQUILIBRIUM_STRATEGIES_EVALUATION_ITERATIONS"]], "eval_batch_size (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.EVAL_BATCH_SIZE"]], "eval_every (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.EVAL_EVERY"]], "eval_prefix (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.EVAL_PREFIX"]], "excesses (csle_agents.constants.constants.hsvi_os_posg attribute)": [[27, "csle_agents.constants.constants.HSVI_OS_POSG.EXCESSES"]], "exploitability (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.EXPLOITABILITY"]], "exploration_final_eps (csle_agents.constants.constants.dqn attribute)": [[27, "csle_agents.constants.constants.DQN.EXPLORATION_FINAL_EPS"]], "exploration_fraction (csle_agents.constants.constants.dqn attribute)": [[27, "csle_agents.constants.constants.DQN.EXPLORATION_FRACTION"]], "exploration_initial_eps (csle_agents.constants.constants.dqn attribute)": [[27, "csle_agents.constants.constants.DQN.EXPLORATION_INITIAL_EPS"]], "fictitious_play (class in csle_agents.constants.constants)": [[27, "csle_agents.constants.constants.FICTITIOUS_PLAY"]], "gae_lambda (csle_agents.constants.constants.ppo attribute)": [[27, "csle_agents.constants.constants.PPO.GAE_LAMBDA"]], "gamma (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.GAMMA"]], "gradient_batch_size (csle_agents.constants.constants.kiefer_wolfowitz attribute)": [[27, "csle_agents.constants.constants.KIEFER_WOLFOWITZ.GRADIENT_BATCH_SIZE"]], "gradient_batch_size (csle_agents.constants.constants.reinforce attribute)": [[27, "csle_agents.constants.constants.REINFORCE.GRADIENT_BATCH_SIZE"]], "gradient_steps (csle_agents.constants.constants.dqn attribute)": [[27, "csle_agents.constants.constants.DQN.GRADIENT_STEPS"]], "hsvi (class in csle_agents.constants.constants)": [[27, "csle_agents.constants.constants.HSVI"]], "hsvi_os_posg (class in csle_agents.constants.constants)": [[27, "csle_agents.constants.constants.HSVI_OS_POSG"]], "initial_alpha (csle_agents.constants.constants.kiefer_wolfowitz attribute)": [[27, "csle_agents.constants.constants.KIEFER_WOLFOWITZ.INITIAL_ALPHA"]], "initial_belief (csle_agents.constants.constants.hsvi attribute)": [[27, "csle_agents.constants.constants.HSVI.INITIAL_BELIEF"]], "initial_belief (csle_agents.constants.constants.hsvi_os_posg attribute)": [[27, "csle_agents.constants.constants.HSVI_OS_POSG.INITIAL_BELIEF"]], "initial_belief (csle_agents.constants.constants.sondik_vi attribute)": [[27, "csle_agents.constants.constants.SONDIK_VI.INITIAL_BELIEF"]], "initial_belief_values (csle_agents.constants.constants.hsvi attribute)": [[27, "csle_agents.constants.constants.HSVI.INITIAL_BELIEF_VALUES"]], "initial_belief_values (csle_agents.constants.constants.sondik_vi attribute)": [[27, "csle_agents.constants.constants.SONDIK_VI.INITIAL_BELIEF_VALUES"]], "initial_policy (csle_agents.constants.constants.pi attribute)": [[27, "csle_agents.constants.constants.PI.INITIAL_POLICY"]], "initial_state_values (csle_agents.constants.constants.q_learning attribute)": [[27, "csle_agents.constants.constants.Q_LEARNING.INITIAL_STATE_VALUES"]], "initial_state_values (csle_agents.constants.constants.sarsa attribute)": [[27, "csle_agents.constants.constants.SARSA.INITIAL_STATE_VALUES"]], "intrusion_alerts_mean (csle_agents.constants.constants.dynasec attribute)": [[27, "csle_agents.constants.constants.DYNASEC.INTRUSION_ALERTS_MEAN"]], "intrusion_alerts_mean_baseline (csle_agents.constants.constants.dynasec attribute)": [[27, "csle_agents.constants.constants.DYNASEC.INTRUSION_ALERTS_MEAN_BASELINE"]], "intrusion_start_p (csle_agents.constants.constants.dynasec attribute)": [[27, "csle_agents.constants.constants.DYNASEC.INTRUSION_START_P"]], "k (csle_agents.constants.constants.cross_entropy attribute)": [[27, "csle_agents.constants.constants.CROSS_ENTROPY.K"]], "kiefer_wolfowitz (class in csle_agents.constants.constants)": [[27, "csle_agents.constants.constants.KIEFER_WOLFOWITZ"]], "l (csle_agents.constants.constants.bayesian_optimization attribute)": [[27, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.L"]], "l (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.L"]], "l (csle_agents.constants.constants.cross_entropy attribute)": [[27, "csle_agents.constants.constants.CROSS_ENTROPY.L"]], "l (csle_agents.constants.constants.differential_evolution attribute)": [[27, "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION.L"]], "l (csle_agents.constants.constants.kiefer_wolfowitz attribute)": [[27, "csle_agents.constants.constants.KIEFER_WOLFOWITZ.L"]], "l (csle_agents.constants.constants.random_search attribute)": [[27, "csle_agents.constants.constants.RANDOM_SEARCH.L"]], "lamb (csle_agents.constants.constants.cross_entropy attribute)": [[27, "csle_agents.constants.constants.CROSS_ENTROPY.LAMB"]], "lb_size (csle_agents.constants.constants.hsvi attribute)": [[27, "csle_agents.constants.constants.HSVI.LB_SIZE"]], "lb_sizes (csle_agents.constants.constants.hsvi attribute)": [[27, "csle_agents.constants.constants.HSVI.LB_SIZES"]], "learning_rate (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.LEARNING_RATE"]], "learning_rate_decay_rate (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.LEARNING_RATE_DECAY_RATE"]], "learning_rate_exp_decay (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.LEARNING_RATE_EXP_DECAY"]], "learning_starts (csle_agents.constants.constants.dqn attribute)": [[27, "csle_agents.constants.constants.DQN.LEARNING_STARTS"]], "local_dfsp (class in csle_agents.constants.constants)": [[27, "csle_agents.constants.constants.LOCAL_DFSP"]], "lp_for_nf_games (class in csle_agents.constants.constants)": [[27, "csle_agents.constants.constants.LP_FOR_NF_GAMES"]], "max_env_steps (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.MAX_ENV_STEPS"]], "max_grad_norm (csle_agents.constants.constants.dqn attribute)": [[27, "csle_agents.constants.constants.DQN.MAX_GRAD_NORM"]], "max_grad_norm (csle_agents.constants.constants.ppo attribute)": [[27, "csle_agents.constants.constants.PPO.MAX_GRAD_NORM"]], "mlp_policy (csle_agents.constants.constants.dqn attribute)": [[27, "csle_agents.constants.constants.DQN.MLP_POLICY"]], "mlp_policy (csle_agents.constants.constants.ppo attribute)": [[27, "csle_agents.constants.constants.PPO.MLP_POLICY"]], "mutate (csle_agents.constants.constants.differential_evolution attribute)": [[27, "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION.MUTATE"]], "n (csle_agents.constants.constants.bayesian_optimization attribute)": [[27, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.N"]], "n (csle_agents.constants.constants.cross_entropy attribute)": [[27, "csle_agents.constants.constants.CROSS_ENTROPY.N"]], "n (csle_agents.constants.constants.differential_evolution attribute)": [[27, "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION.N"]], "n (csle_agents.constants.constants.fictitious_play attribute)": [[27, "csle_agents.constants.constants.FICTITIOUS_PLAY.N"]], "n (csle_agents.constants.constants.hsvi_os_posg attribute)": [[27, "csle_agents.constants.constants.HSVI_OS_POSG.N"]], "n (csle_agents.constants.constants.kiefer_wolfowitz attribute)": [[27, "csle_agents.constants.constants.KIEFER_WOLFOWITZ.N"]], "n (csle_agents.constants.constants.lp_for_nf_games attribute)": [[27, "csle_agents.constants.constants.LP_FOR_NF_GAMES.N"]], "n (csle_agents.constants.constants.pi attribute)": [[27, "csle_agents.constants.constants.PI.N"]], "n (csle_agents.constants.constants.q_learning attribute)": [[27, "csle_agents.constants.constants.Q_LEARNING.N"]], "n (csle_agents.constants.constants.random_search attribute)": [[27, "csle_agents.constants.constants.RANDOM_SEARCH.N"]], "n (csle_agents.constants.constants.reinforce attribute)": [[27, "csle_agents.constants.constants.REINFORCE.N"]], "n (csle_agents.constants.constants.sarsa attribute)": [[27, "csle_agents.constants.constants.SARSA.N"]], "n (csle_agents.constants.constants.shapley_iteration attribute)": [[27, "csle_agents.constants.constants.SHAPLEY_ITERATION.N"]], "no_intrusion_alerts_mean (csle_agents.constants.constants.dynasec attribute)": [[27, "csle_agents.constants.constants.DYNASEC.NO_INTRUSION_ALERTS_MEAN"]], "no_intrusion_alerts_mean_baseline (csle_agents.constants.constants.dynasec attribute)": [[27, "csle_agents.constants.constants.DYNASEC.NO_INTRUSION_ALERTS_MEAN_BASELINE"]], "number_of_simulations (csle_agents.constants.constants.hsvi attribute)": [[27, "csle_agents.constants.constants.HSVI.NUMBER_OF_SIMULATIONS"]], "num_actions (csle_agents.constants.constants.pi attribute)": [[27, "csle_agents.constants.constants.PI.NUM_ACTIONS"]], "num_actions (csle_agents.constants.constants.vi attribute)": [[27, "csle_agents.constants.constants.VI.NUM_ACTIONS"]], "num_alpha_vectors (csle_agents.constants.constants.sondik_vi attribute)": [[27, "csle_agents.constants.constants.SONDIK_VI.NUM_ALPHA_VECTORS"]], "num_cached_simulation_traces (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.NUM_CACHED_SIMULATION_TRACES"]], "num_clients (csle_agents.constants.constants.dynasec attribute)": [[27, "csle_agents.constants.constants.DYNASEC.NUM_CLIENTS"]], "num_nodes (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.NUM_NODES"]], "num_parallel_envs (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.NUM_PARALLEL_ENVS"]], "num_states (csle_agents.constants.constants.pi attribute)": [[27, "csle_agents.constants.constants.PI.NUM_STATES"]], "num_states (csle_agents.constants.constants.vi attribute)": [[27, "csle_agents.constants.constants.VI.NUM_STATES"]], "num_training_timesteps (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.NUM_TRAINING_TIMESTEPS"]], "n_2 (csle_agents.constants.constants.local_dfsp attribute)": [[27, "csle_agents.constants.constants.LOCAL_DFSP.N_2"]], "n_2 (csle_agents.constants.constants.t_fp attribute)": [[27, "csle_agents.constants.constants.T_FP.N_2"]], "n_episodes_rollout (csle_agents.constants.constants.dqn attribute)": [[27, "csle_agents.constants.constants.DQN.N_EPISODES_ROLLOUT"]], "observation (csle_agents.constants.constants.env_metrics attribute)": [[27, "csle_agents.constants.constants.ENV_METRICS.OBSERVATION"]], "observation_function (csle_agents.constants.constants.hsvi_os_posg attribute)": [[27, "csle_agents.constants.constants.HSVI_OS_POSG.OBSERVATION_FUNCTION"]], "observation_space (csle_agents.constants.constants.hsvi attribute)": [[27, "csle_agents.constants.constants.HSVI.OBSERVATION_SPACE"]], "observation_space (csle_agents.constants.constants.hsvi_os_posg attribute)": [[27, "csle_agents.constants.constants.HSVI_OS_POSG.OBSERVATION_SPACE"]], "observation_space (csle_agents.constants.constants.sondik_vi attribute)": [[27, "csle_agents.constants.constants.SONDIK_VI.OBSERVATION_SPACE"]], "observation_tensor (csle_agents.constants.constants.hsvi attribute)": [[27, "csle_agents.constants.constants.HSVI.OBSERVATION_TENSOR"]], "observation_tensor (csle_agents.constants.constants.sondik_vi attribute)": [[27, "csle_agents.constants.constants.SONDIK_VI.OBSERVATION_TENSOR"]], "optimizer (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.OPTIMIZER"]], "parameter_bounds (csle_agents.constants.constants.bayesian_optimization attribute)": [[27, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.PARAMETER_BOUNDS"]], "params (csle_agents.constants.constants.bayesian_optimization attribute)": [[27, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.PARAMS"]], "payoff_matrix (csle_agents.constants.constants.fictitious_play attribute)": [[27, "csle_agents.constants.constants.FICTITIOUS_PLAY.PAYOFF_MATRIX"]], "payoff_matrix (csle_agents.constants.constants.lp_for_nf_games attribute)": [[27, "csle_agents.constants.constants.LP_FOR_NF_GAMES.PAYOFF_MATRIX"]], "pi (class in csle_agents.constants.constants)": [[27, "csle_agents.constants.constants.PI"]], "planning_horizon (csle_agents.constants.constants.sondik_vi attribute)": [[27, "csle_agents.constants.constants.SONDIK_VI.PLANNING_HORIZON"]], "player_1_prior (csle_agents.constants.constants.fictitious_play attribute)": [[27, "csle_agents.constants.constants.FICTITIOUS_PLAY.PLAYER_1_PRIOR"]], "player_2_prior (csle_agents.constants.constants.fictitious_play attribute)": [[27, "csle_agents.constants.constants.FICTITIOUS_PLAY.PLAYER_2_PRIOR"]], "policy_losses (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.POLICY_LOSSES"]], "policy_type (csle_agents.constants.constants.bayesian_optimization attribute)": [[27, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.POLICY_TYPE"]], "policy_type (csle_agents.constants.constants.cross_entropy attribute)": [[27, "csle_agents.constants.constants.CROSS_ENTROPY.POLICY_TYPE"]], "policy_type (csle_agents.constants.constants.differential_evolution attribute)": [[27, "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION.POLICY_TYPE"]], "policy_type (csle_agents.constants.constants.kiefer_wolfowitz attribute)": [[27, "csle_agents.constants.constants.KIEFER_WOLFOWITZ.POLICY_TYPE"]], "policy_type (csle_agents.constants.constants.random_search attribute)": [[27, "csle_agents.constants.constants.RANDOM_SEARCH.POLICY_TYPE"]], "population_size (csle_agents.constants.constants.differential_evolution attribute)": [[27, "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION.POPULATION_SIZE"]], "ppo (class in csle_agents.constants.constants)": [[27, "csle_agents.constants.constants.PPO"]], "prune_frequency (csle_agents.constants.constants.hsvi attribute)": [[27, "csle_agents.constants.constants.HSVI.PRUNE_FREQUENCY"]], "prune_frequency (csle_agents.constants.constants.hsvi_os_posg attribute)": [[27, "csle_agents.constants.constants.HSVI_OS_POSG.PRUNE_FREQUENCY"]], "q_learning (class in csle_agents.constants.constants)": [[27, "csle_agents.constants.constants.Q_LEARNING"]], "random_search (class in csle_agents.constants.constants)": [[27, "csle_agents.constants.constants.RANDOM_SEARCH"]], "recombination (csle_agents.constants.constants.differential_evolution attribute)": [[27, "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION.RECOMBINATION"]], "reinforce (class in csle_agents.constants.constants)": [[27, "csle_agents.constants.constants.REINFORCE"]], "replay_window_size (csle_agents.constants.constants.dynasec attribute)": [[27, "csle_agents.constants.constants.DYNASEC.REPLAY_WINDOW_SIZE"]], "return (csle_agents.constants.constants.env_metrics attribute)": [[27, "csle_agents.constants.constants.ENV_METRICS.RETURN"]], "reward_tensor (csle_agents.constants.constants.hsvi attribute)": [[27, "csle_agents.constants.constants.HSVI.REWARD_TENSOR"]], "reward_tensor (csle_agents.constants.constants.hsvi_os_posg attribute)": [[27, "csle_agents.constants.constants.HSVI_OS_POSG.REWARD_TENSOR"]], "reward_tensor (csle_agents.constants.constants.pi attribute)": [[27, "csle_agents.constants.constants.PI.REWARD_TENSOR"]], "reward_tensor (csle_agents.constants.constants.shapley_iteration attribute)": [[27, "csle_agents.constants.constants.SHAPLEY_ITERATION.REWARD_TENSOR"]], "reward_tensor (csle_agents.constants.constants.sondik_vi attribute)": [[27, "csle_agents.constants.constants.SONDIK_VI.REWARD_TENSOR"]], "reward_tensor (csle_agents.constants.constants.vi attribute)": [[27, "csle_agents.constants.constants.VI.REWARD_TENSOR"]], "running_average (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.RUNNING_AVERAGE"]], "running_average_attacker_return (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.RUNNING_AVERAGE_ATTACKER_RETURN"]], "running_average_best_response_attacker_return (csle_agents.constants.constants.local_dfsp attribute)": [[27, "csle_agents.constants.constants.LOCAL_DFSP.RUNNING_AVERAGE_BEST_RESPONSE_ATTACKER_RETURN"]], "running_average_best_response_attacker_return (csle_agents.constants.constants.t_fp attribute)": [[27, "csle_agents.constants.constants.T_FP.RUNNING_AVERAGE_BEST_RESPONSE_ATTACKER_RETURN"]], "running_average_best_response_defender_return (csle_agents.constants.constants.local_dfsp attribute)": [[27, "csle_agents.constants.constants.LOCAL_DFSP.RUNNING_AVERAGE_BEST_RESPONSE_DEFENDER_RETURN"]], "running_average_best_response_defender_return (csle_agents.constants.constants.t_fp attribute)": [[27, "csle_agents.constants.constants.T_FP.RUNNING_AVERAGE_BEST_RESPONSE_DEFENDER_RETURN"]], "running_average_defender_return (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.RUNNING_AVERAGE_DEFENDER_RETURN"]], "running_average_exploitability (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.RUNNING_AVERAGE_EXPLOITABILITY"]], "running_average_intrusion_length (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.RUNNING_AVERAGE_INTRUSION_LENGTH"]], "running_average_intrusion_start (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.RUNNING_AVERAGE_INTRUSION_START"]], "running_average_return (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.RUNNING_AVERAGE_RETURN"]], "running_average_start_point_correct (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.RUNNING_AVERAGE_START_POINT_CORRECT"]], "running_average_time_horizon (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.RUNNING_AVERAGE_TIME_HORIZON"]], "running_average_weighted_intrusion_prediction_distance (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.RUNNING_AVERAGE_WEIGHTED_INTRUSION_PREDICTION_DISTANCE"]], "runtime (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.RUNTIME"]], "s (csle_agents.constants.constants.q_learning attribute)": [[27, "csle_agents.constants.constants.Q_LEARNING.S"]], "s (csle_agents.constants.constants.sarsa attribute)": [[27, "csle_agents.constants.constants.SARSA.S"]], "sarsa (class in csle_agents.constants.constants)": [[27, "csle_agents.constants.constants.SARSA"]], "save_every (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.SAVE_EVERY"]], "sgd (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.SGD"]], "shapley_iteration (class in csle_agents.constants.constants)": [[27, "csle_agents.constants.constants.SHAPLEY_ITERATION"]], "simulate_horizon (csle_agents.constants.constants.hsvi attribute)": [[27, "csle_agents.constants.constants.HSVI.SIMULATE_HORIZON"]], "simulation_frequency (csle_agents.constants.constants.hsvi attribute)": [[27, "csle_agents.constants.constants.HSVI.SIMULATION_FREQUENCY"]], "sleep_time (csle_agents.constants.constants.dynasec attribute)": [[27, "csle_agents.constants.constants.DYNASEC.SLEEP_TIME"]], "sondik_vi (class in csle_agents.constants.constants)": [[27, "csle_agents.constants.constants.SONDIK_VI"]], "start_point_correct (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.START_POINT_CORRECT"]], "state (csle_agents.constants.constants.env_metrics attribute)": [[27, "csle_agents.constants.constants.ENV_METRICS.STATE"]], "state_space (csle_agents.constants.constants.hsvi attribute)": [[27, "csle_agents.constants.constants.HSVI.STATE_SPACE"]], "state_space (csle_agents.constants.constants.hsvi_os_posg attribute)": [[27, "csle_agents.constants.constants.HSVI_OS_POSG.STATE_SPACE"]], "state_space (csle_agents.constants.constants.shapley_iteration attribute)": [[27, "csle_agents.constants.constants.SHAPLEY_ITERATION.STATE_SPACE"]], "state_space (csle_agents.constants.constants.sondik_vi attribute)": [[27, "csle_agents.constants.constants.SONDIK_VI.STATE_SPACE"]], "static_attacker_type (csle_agents.constants.constants.dynasec attribute)": [[27, "csle_agents.constants.constants.DYNASEC.STATIC_ATTACKER_TYPE"]], "steps_between_updates (csle_agents.constants.constants.ppo attribute)": [[27, "csle_agents.constants.constants.PPO.STEPS_BETWEEN_UPDATES"]], "stopping_envs (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.STOPPING_ENVS"]], "stop_distribution_attacker (csle_agents.constants.constants.bayesian_optimization attribute)": [[27, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.STOP_DISTRIBUTION_ATTACKER"]], "stop_distribution_attacker (csle_agents.constants.constants.cross_entropy attribute)": [[27, "csle_agents.constants.constants.CROSS_ENTROPY.STOP_DISTRIBUTION_ATTACKER"]], "stop_distribution_attacker (csle_agents.constants.constants.differential_evolution attribute)": [[27, "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION.STOP_DISTRIBUTION_ATTACKER"]], "stop_distribution_attacker (csle_agents.constants.constants.kiefer_wolfowitz attribute)": [[27, "csle_agents.constants.constants.KIEFER_WOLFOWITZ.STOP_DISTRIBUTION_ATTACKER"]], "stop_distribution_attacker (csle_agents.constants.constants.random_search attribute)": [[27, "csle_agents.constants.constants.RANDOM_SEARCH.STOP_DISTRIBUTION_ATTACKER"]], "stop_distribution_defender (csle_agents.constants.constants.bayesian_optimization attribute)": [[27, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.STOP_DISTRIBUTION_DEFENDER"]], "stop_distribution_defender (csle_agents.constants.constants.cross_entropy attribute)": [[27, "csle_agents.constants.constants.CROSS_ENTROPY.STOP_DISTRIBUTION_DEFENDER"]], "stop_distribution_defender (csle_agents.constants.constants.differential_evolution attribute)": [[27, "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION.STOP_DISTRIBUTION_DEFENDER"]], "stop_distribution_defender (csle_agents.constants.constants.kiefer_wolfowitz attribute)": [[27, "csle_agents.constants.constants.KIEFER_WOLFOWITZ.STOP_DISTRIBUTION_DEFENDER"]], "stop_distribution_defender (csle_agents.constants.constants.random_search attribute)": [[27, "csle_agents.constants.constants.RANDOM_SEARCH.STOP_DISTRIBUTION_DEFENDER"]], "target (csle_agents.constants.constants.bayesian_optimization attribute)": [[27, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.TARGET"]], "target_kl (csle_agents.constants.constants.ppo attribute)": [[27, "csle_agents.constants.constants.PPO.TARGET_KL"]], "target_update_interval (csle_agents.constants.constants.dqn attribute)": [[27, "csle_agents.constants.constants.DQN.TARGET_UPDATE_INTERVAL"]], "theta (csle_agents.constants.constants.vi attribute)": [[27, "csle_agents.constants.constants.VI.THETA"]], "theta1 (csle_agents.constants.constants.bayesian_optimization attribute)": [[27, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.THETA1"]], "theta1 (csle_agents.constants.constants.cross_entropy attribute)": [[27, "csle_agents.constants.constants.CROSS_ENTROPY.THETA1"]], "theta1 (csle_agents.constants.constants.differential_evolution attribute)": [[27, "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION.THETA1"]], "theta1 (csle_agents.constants.constants.kiefer_wolfowitz attribute)": [[27, "csle_agents.constants.constants.KIEFER_WOLFOWITZ.THETA1"]], "theta1 (csle_agents.constants.constants.random_search attribute)": [[27, "csle_agents.constants.constants.RANDOM_SEARCH.THETA1"]], "theta1_attacker (csle_agents.constants.constants.t_fp attribute)": [[27, "csle_agents.constants.constants.T_FP.THETA1_ATTACKER"]], "theta1_defender (csle_agents.constants.constants.t_fp attribute)": [[27, "csle_agents.constants.constants.T_FP.THETA1_DEFENDER"]], "thetas (csle_agents.constants.constants.bayesian_optimization attribute)": [[27, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.THETAS"]], "thetas (csle_agents.constants.constants.cross_entropy attribute)": [[27, "csle_agents.constants.constants.CROSS_ENTROPY.THETAS"]], "thetas (csle_agents.constants.constants.differential_evolution attribute)": [[27, "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION.THETAS"]], "thetas (csle_agents.constants.constants.kiefer_wolfowitz attribute)": [[27, "csle_agents.constants.constants.KIEFER_WOLFOWITZ.THETAS"]], "thetas (csle_agents.constants.constants.random_search attribute)": [[27, "csle_agents.constants.constants.RANDOM_SEARCH.THETAS"]], "thresholds (csle_agents.constants.constants.bayesian_optimization attribute)": [[27, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.THRESHOLDS"]], "thresholds (csle_agents.constants.constants.cross_entropy attribute)": [[27, "csle_agents.constants.constants.CROSS_ENTROPY.THRESHOLDS"]], "thresholds (csle_agents.constants.constants.differential_evolution attribute)": [[27, "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION.THRESHOLDS"]], "thresholds (csle_agents.constants.constants.kiefer_wolfowitz attribute)": [[27, "csle_agents.constants.constants.KIEFER_WOLFOWITZ.THRESHOLDS"]], "thresholds (csle_agents.constants.constants.random_search attribute)": [[27, "csle_agents.constants.constants.RANDOM_SEARCH.THRESHOLDS"]], "time_horizon (csle_agents.constants.constants.env_metrics attribute)": [[27, "csle_agents.constants.constants.ENV_METRICS.TIME_HORIZON"]], "time_step (csle_agents.constants.constants.env_metrics attribute)": [[27, "csle_agents.constants.constants.ENV_METRICS.TIME_STEP"]], "training_epochs (csle_agents.constants.constants.dynasec attribute)": [[27, "csle_agents.constants.constants.DYNASEC.TRAINING_EPOCHS"]], "train_freq (csle_agents.constants.constants.dqn attribute)": [[27, "csle_agents.constants.constants.DQN.TRAIN_FREQ"]], "transition_tensor (csle_agents.constants.constants.hsvi attribute)": [[27, "csle_agents.constants.constants.HSVI.TRANSITION_TENSOR"]], "transition_tensor (csle_agents.constants.constants.hsvi_os_posg attribute)": [[27, "csle_agents.constants.constants.HSVI_OS_POSG.TRANSITION_TENSOR"]], "transition_tensor (csle_agents.constants.constants.pi attribute)": [[27, "csle_agents.constants.constants.PI.TRANSITION_TENSOR"]], "transition_tensor (csle_agents.constants.constants.shapley_iteration attribute)": [[27, "csle_agents.constants.constants.SHAPLEY_ITERATION.TRANSITION_TENSOR"]], "transition_tensor (csle_agents.constants.constants.sondik_vi attribute)": [[27, "csle_agents.constants.constants.SONDIK_VI.TRANSITION_TENSOR"]], "transition_tensor (csle_agents.constants.constants.vi attribute)": [[27, "csle_agents.constants.constants.VI.TRANSITION_TENSOR"]], "t_fp (class in csle_agents.constants.constants)": [[27, "csle_agents.constants.constants.T_FP"]], "ub_size (csle_agents.constants.constants.hsvi attribute)": [[27, "csle_agents.constants.constants.HSVI.UB_SIZE"]], "ub_sizes (csle_agents.constants.constants.hsvi attribute)": [[27, "csle_agents.constants.constants.HSVI.UB_SIZES"]], "ucb (csle_agents.constants.constants.bayesian_optimization attribute)": [[27, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.UCB"]], "ucb_kappa (csle_agents.constants.constants.bayesian_optimization attribute)": [[27, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.UCB_KAPPA"]], "ucb_xi (csle_agents.constants.constants.bayesian_optimization attribute)": [[27, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.UCB_XI"]], "use_lp (csle_agents.constants.constants.hsvi attribute)": [[27, "csle_agents.constants.constants.HSVI.USE_LP"]], "use_pruning (csle_agents.constants.constants.sondik_vi attribute)": [[27, "csle_agents.constants.constants.SONDIK_VI.USE_PRUNING"]], "utility_function (csle_agents.constants.constants.bayesian_optimization attribute)": [[27, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.UTILITY_FUNCTION"]], "vf_coef (csle_agents.constants.constants.ppo attribute)": [[27, "csle_agents.constants.constants.PPO.VF_COEF"]], "vi (class in csle_agents.constants.constants)": [[27, "csle_agents.constants.constants.VI"]], "warmup_episodes (csle_agents.constants.constants.dynasec attribute)": [[27, "csle_agents.constants.constants.DYNASEC.WARMUP_EPISODES"]], "weighted_intrusion_prediction_distance (csle_agents.constants.constants.common attribute)": [[27, "csle_agents.constants.constants.COMMON.WEIGHTED_INTRUSION_PREDICTION_DISTANCE"]], "width (csle_agents.constants.constants.hsvi attribute)": [[27, "csle_agents.constants.constants.HSVI.WIDTH"]], "widths (csle_agents.constants.constants.hsvi attribute)": [[27, "csle_agents.constants.constants.HSVI.WIDTHS"]], "widths (csle_agents.constants.constants.hsvi_os_posg attribute)": [[27, "csle_agents.constants.constants.HSVI_OS_POSG.WIDTHS"]], "csle_agents.constants": [[27, "module-csle_agents.constants"]], "csle_agents.constants.constants": [[27, "module-csle_agents.constants.constants"]], "trainingjobmanager (class in csle_agents.job_controllers.training_job_manager)": [[28, "csle_agents.job_controllers.training_job_manager.TrainingJobManager"]], "csle_agents.job_controllers": [[28, "module-csle_agents.job_controllers"]], "csle_agents.job_controllers.training_job_manager": [[28, "module-csle_agents.job_controllers.training_job_manager"]], "run_training_job() (csle_agents.job_controllers.training_job_manager.trainingjobmanager static method)": [[28, "csle_agents.job_controllers.training_job_manager.TrainingJobManager.run_training_job"]], "start_training_job_in_background() (csle_agents.job_controllers.training_job_manager.trainingjobmanager static method)": [[28, "csle_agents.job_controllers.training_job_manager.TrainingJobManager.start_training_job_in_background"]]}})