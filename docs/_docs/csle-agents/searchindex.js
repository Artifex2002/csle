Search.setIndex({"docnames": ["csle_agents", "csle_agents.agents", "csle_agents.agents.base", "csle_agents.agents.bayes_opt", "csle_agents.agents.cross_entropy", "csle_agents.agents.differential_evolution", "csle_agents.agents.dqn", "csle_agents.agents.dynasec", "csle_agents.agents.fp", "csle_agents.agents.hsvi", "csle_agents.agents.hsvi_os_posg", "csle_agents.agents.kiefer_wolfowitz", "csle_agents.agents.lp_nf", "csle_agents.agents.pi", "csle_agents.agents.ppo", "csle_agents.agents.q_learning", "csle_agents.agents.random_search", "csle_agents.agents.reinforce", "csle_agents.agents.sarsa", "csle_agents.agents.shapley_iteration", "csle_agents.agents.sondik_vi", "csle_agents.agents.t_fp", "csle_agents.agents.t_spsa", "csle_agents.agents.vi", "csle_agents.common", "csle_agents.constants", "csle_agents.job_controllers", "index", "modules"], "filenames": ["csle_agents.rst", "csle_agents.agents.rst", "csle_agents.agents.base.rst", "csle_agents.agents.bayes_opt.rst", "csle_agents.agents.cross_entropy.rst", "csle_agents.agents.differential_evolution.rst", "csle_agents.agents.dqn.rst", "csle_agents.agents.dynasec.rst", "csle_agents.agents.fp.rst", "csle_agents.agents.hsvi.rst", "csle_agents.agents.hsvi_os_posg.rst", "csle_agents.agents.kiefer_wolfowitz.rst", "csle_agents.agents.lp_nf.rst", "csle_agents.agents.pi.rst", "csle_agents.agents.ppo.rst", "csle_agents.agents.q_learning.rst", "csle_agents.agents.random_search.rst", "csle_agents.agents.reinforce.rst", "csle_agents.agents.sarsa.rst", "csle_agents.agents.shapley_iteration.rst", "csle_agents.agents.sondik_vi.rst", "csle_agents.agents.t_fp.rst", "csle_agents.agents.t_spsa.rst", "csle_agents.agents.vi.rst", "csle_agents.common.rst", "csle_agents.constants.rst", "csle_agents.job_controllers.rst", "index.rst", "modules.rst"], "titles": ["csle_agents package", "csle_agents.agents package", "csle_agents.agents.base package", "csle_agents.agents.bayes_opt package", "csle_agents.agents.cross_entropy package", "csle_agents.agents.differential_evolution package", "csle_agents.agents.dqn package", "csle_agents.agents.dynasec package", "csle_agents.agents.fp package", "csle_agents.agents.hsvi package", "csle_agents.agents.hsvi_os_posg package", "csle_agents.agents.kiefer_wolfowitz package", "csle_agents.agents.lp_nf package", "csle_agents.agents.pi package", "csle_agents.agents.ppo package", "csle_agents.agents.q_learning package", "csle_agents.agents.random_search package", "csle_agents.agents.reinforce package", "csle_agents.agents.sarsa package", "csle_agents.agents.shapley_iteration package", "csle_agents.agents.sondik_vi package", "csle_agents.agents.t_fp package", "csle_agents.agents.t_spsa package", "csle_agents.agents.vi package", "csle_agents.common package", "csle_agents.constants package", "csle_agents.job_controllers package", "csle_agents package", "csle_agents"], "terms": {"agent": [0, 25, 27, 28], "base": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27], "submodul": [0, 1, 27, 28], "base_ag": [0, 1, 27], "bayes_opt": [0, 1, 27], "bayes_opt_ag": [0, 1, 27], "cross_entropi": [0, 1, 25, 27], "cross_entropy_ag": [0, 1, 27], "differential_evolut": [0, 1, 25, 27], "differential_evolution_ag": [0, 1, 27], "dqn": [0, 1, 25, 27], "dqn_agent": [0, 1, 27], "dynasec": [0, 1, 25, 27], "dynasec_ag": [0, 1, 27], "fp": [0, 1, 21, 25, 27], "fictitious_play_ag": [0, 1, 27], "hsvi": [0, 1, 10, 25, 27], "hsvi_ag": [0, 1, 27], "hsvi_os_posg": [0, 1, 25, 27], "hsvi_os_posg_ag": [0, 1, 27], "kiefer_wolfowitz": [0, 1, 25, 27], "kiefer_wolfowitz_ag": [0, 1, 27], "lp_nf": [0, 1, 10, 27], "linear_programming_normal_form_game_ag": [0, 1, 27], "pi": [0, 1, 10, 25, 27], "pi_ag": [0, 1, 27], "ppo": [0, 1, 25, 27], "ppo_ag": [0, 1, 27], "q_learn": [0, 1, 18, 25, 27], "q_learning_ag": [0, 1, 27], "random_search": [0, 1, 25, 27], "random_search_ag": [0, 1, 27], "reinforc": [0, 1, 7, 25, 27], "reinforce_ag": [0, 1, 27], "sarsa": [0, 1, 25, 27], "sarsa_ag": [0, 1, 27], "shapley_iter": [0, 1, 25, 27], "shapley_iteration_ag": [0, 1, 27], "sondik_vi": [0, 1, 25, 27], "sondik_vi_ag": [0, 1, 27], "t_fp": [0, 1, 25, 27], "t_fp_agent": [0, 1, 27], "t_spsa": [0, 1, 27], "t_spsa_ag": [0, 1, 27], "vi": [0, 1, 9, 10, 25, 27], "vi_ag": [0, 1, 27], "common": [0, 25, 27, 28], "actor_critic_net": [0, 27, 28], "fnn_w_gaussian": [0, 27, 28], "fnnwithgaussian": [0, 24, 27], "forward": [0, 24, 27], "get_hidden_activ": [0, 24, 27], "train": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27], "test": [0, 24, 27], "fnn_w_linear": [0, 27, 28], "fnnwithlinear": [0, 24, 27], "prune": [0, 1, 9, 10, 20, 27, 28], "check_dominance_lp": [0, 24, 27], "check_dupl": [0, 1, 20, 24, 27], "prune_lower_bound": [0, 24, 27], "constant": [0, 27, 28], "bayesian_optim": [0, 1, 3, 25, 27], "l": [0, 3, 4, 5, 6, 10, 11, 14, 16, 19, 22, 25, 27], "n": [0, 13, 15, 18, 21, 25, 27], "parameter_bound": [0, 25, 27], "param": [0, 9, 10, 13, 20, 23, 25, 27], "stop_distribution_attack": [0, 25, 27], "stop_distribution_defend": [0, 25, 27], "target": [0, 25, 27], "theta1": [0, 25, 27], "theta": [0, 3, 4, 5, 9, 10, 11, 16, 22, 23, 25, 27], "threshold": [0, 3, 4, 5, 9, 10, 11, 16, 19, 21, 22, 23, 25, 27], "ucb": [0, 25, 27], "ucb_kappa": [0, 25, 27], "ucb_xi": [0, 25, 27], "utility_funct": [0, 25, 27], "adam": [0, 25, 27], "average_attacker_return": [0, 25, 27], "average_defender_return": [0, 25, 27], "average_random_return": [0, 25, 27], "average_return": [0, 23, 25, 27], "average_time_horizon": [0, 25, 27], "average_upper_bound_return": [0, 25, 27], "baseline_prefix": [0, 25, 27], "batch_siz": [0, 25, 27], "confidence_interv": [0, 25, 27], "eval_batch_s": [0, 6, 13, 14, 15, 18, 20, 23, 25, 27], "eval_everi": [0, 6, 14, 25, 27], "eval_prefix": [0, 25, 27], "exploit": [0, 1, 21, 25, 27], "gamma": [0, 9, 10, 13, 15, 17, 18, 19, 20, 25, 27], "learning_r": [0, 25, 27], "learning_rate_decay_r": [0, 25, 27], "learning_rate_exp_decai": [0, 25, 27], "max_env_step": [0, 25, 27], "num_cached_simulation_trac": [0, 25, 27], "num_nod": [0, 25, 27], "num_parallel_env": [0, 25, 27], "num_training_timestep": [0, 25, 27], "optim": [0, 3, 7, 10, 13, 17, 22, 25, 27], "policy_loss": [0, 25, 27], "running_averag": [0, 1, 21, 25, 27], "running_average_attacker_return": [0, 25, 27], "running_average_defender_return": [0, 25, 27], "running_average_exploit": [0, 25, 27], "running_average_intrusion_length": [0, 25, 27], "running_average_intrusion_start": [0, 25, 27], "running_average_return": [0, 25, 27], "running_average_start_point_correct": [0, 25, 27], "running_average_time_horizon": [0, 25, 27], "running_average_weighted_intrusion_prediction_dist": [0, 25, 27], "runtim": [0, 25, 27], "save_everi": [0, 6, 14, 25, 27], "sgd": [0, 25, 27], "start_point_correct": [0, 25, 27], "stopping_env": [0, 25, 27], "weighted_intrusion_prediction_dist": [0, 25, 27], "k": [0, 11, 22, 25, 27], "lamb": [0, 22, 25, 27], "bound": [0, 5, 9, 10, 24, 25, 27], "mutat": [0, 25, 27], "population_s": [0, 25, 27], "recombin": [0, 25, 27], "buffer_s": [0, 25, 27], "dqn_batch_siz": [0, 25, 27], "exploration_final_ep": [0, 25, 27], "exploration_fract": [0, 25, 27], "exploration_initial_ep": [0, 25, 27], "gradient_step": [0, 25, 27], "learning_start": [0, 25, 27], "max_grad_norm": [0, 25, 27], "mlp_polici": [0, 25, 27], "n_episodes_rollout": [0, 25, 27], "target_update_interv": [0, 25, 27], "train_freq": [0, 25, 27], "clients_arrival_r": [0, 25, 27], "emulation_monitor_sleep_tim": [0, 25, 27], "emulation_traces_to_save_w_data_collection_job": [0, 25, 27], "intrusion_alerts_mean": [0, 25, 27], "intrusion_alerts_mean_baselin": [0, 25, 27], "intrusion_start_p": [0, 7, 25, 27], "no_intrusion_alerts_mean": [0, 25, 27], "no_intrusion_alerts_mean_baselin": [0, 25, 27], "num_client": [0, 25, 27], "replay_window_s": [0, 25, 27], "sleep_tim": [0, 7, 25, 27], "static_attacker_typ": [0, 25, 27], "training_epoch": [0, 25, 27], "warmup_episod": [0, 25, 27], "env_metr": [0, 25, 27], "attacker_act": [0, 25, 27], "defender_act": [0, 25, 27], "observ": [0, 9, 10, 20, 25, 27], "return": [0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27], "state": [0, 6, 9, 10, 13, 14, 15, 18, 19, 20, 23, 24, 25, 27], "time_horizon": [0, 25, 27], "time_step": [0, 25, 27], "fictitious_plai": [0, 1, 8, 25, 27], "payoff_matrix": [0, 25, 27], "player_1_prior": [0, 25, 27], "player_2_prior": [0, 25, 27], "action_spac": [0, 25, 27], "epsilon": [0, 9, 10, 15, 18, 22, 25, 27], "initial_belief": [0, 25, 27], "initial_belief_valu": [0, 25, 27], "lb_size": [0, 25, 27], "number_of_simul": [0, 9, 25, 27], "observation_spac": [0, 25, 27], "observation_tensor": [0, 25, 27], "prune_frequ": [0, 9, 10, 25, 27], "reward_tensor": [0, 25, 27], "simulate_horizon": [0, 9, 25, 27], "simulation_frequ": [0, 9, 25, 27], "state_spac": [0, 25, 27], "transition_tensor": [0, 25, 27], "ub_siz": [0, 25, 27], "use_lp": [0, 25, 27], "width": [0, 1, 9, 10, 25, 27], "action_space_player_1": [0, 25, 27], "action_space_player_2": [0, 25, 27], "excess": [0, 1, 9, 10, 25, 27], "observation_funct": [0, 25, 27], "delta": [0, 10, 11, 16, 23, 25, 27], "gradient_batch_s": [0, 11, 22, 25, 27], "initial_alpha": [0, 25, 27], "lp_for_nf_gam": [0, 25, 27], "initial_polici": [0, 25, 27], "num_act": [0, 9, 10, 13, 15, 18, 23, 25, 27], "num_stat": [0, 9, 10, 13, 15, 18, 23, 25, 27], "clip_rang": [0, 25, 27], "clip_range_vf": [0, 25, 27], "ent_coef": [0, 25, 27], "gae_lambda": [0, 25, 27], "steps_between_upd": [0, 25, 27], "target_kl": [0, 25, 27], "vf_coef": [0, 25, 27], "A": [0, 6, 8, 9, 10, 12, 14, 15, 18, 19, 22, 24, 25, 27], "initial_state_valu": [0, 25, 27], "": [0, 9, 10, 15, 17, 18, 19, 20, 24, 25, 27], "clip_gradi": [0, 25, 27], "num_alpha_vector": [0, 25, 27], "planning_horizon": [0, 25, 27], "use_prun": [0, 20, 25, 27], "attacker_threshold": [0, 21, 25, 27], "average_best_response_attacker_return": [0, 25, 27], "average_best_response_defender_return": [0, 25, 27], "best_response_evaluation_iter": [0, 25, 27], "defender_threshold": [0, 21, 25, 27], "equilibrium_strategies_evaluation_iter": [0, 25, 27], "n_2": [0, 25, 27], "running_average_best_response_attacker_return": [0, 25, 27], "running_average_best_response_defender_return": [0, 25, 27], "theta1_attack": [0, 25, 27], "theta1_defend": [0, 25, 27], "job_control": [0, 27, 28], "training_job_manag": [0, 27, 28], "baseag": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 27], "hparam_nam": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 27], "class": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26], "simulation_env_config": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23], "simulationenvconfig": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "emulation_env_config": [2, 3, 4, 5, 6, 7, 8, 11, 12, 14, 16, 17, 21, 22], "none": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26], "emulationenvconfig": [2, 3, 4, 5, 6, 7, 8, 11, 12, 14, 16, 17, 21, 22], "experiment_config": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "experimentconfig": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "sourc": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26], "abc": 2, "abstract": 2, "repres": [2, 9, 10, 25], "an": [2, 7, 9, 10, 13, 15, 18, 19, 20, 23], "rl": [2, 11, 21, 22], "list": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "str": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "experimentexecut": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "input_dim": 24, "int": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "output_dim": 24, "hidden_dim": 24, "num_hidden_lay": 24, "2": [10, 12, 15, 18, 19, 20, 24], "hidden_activ": 24, "relu": 24, "implement": [6, 9, 10, 11, 13, 14, 21, 22, 23, 24], "fnn": 24, "gaussian": 24, "output": 24, "parameteriz": 24, "number": [9, 10, 11, 13, 15, 18, 19, 20, 21, 22, 23, 24], "layer": 24, "dimens": [3, 4, 5, 11, 13, 16, 22, 24], "hidden": 24, "activ": 24, "sub": 24, "torch": 24, "nn": 24, "abl": [10, 24], "us": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 24], "high": 24, "level": 24, "api": 24, "creat": [10, 15, 18, 19, 23, 24], "custom": 24, "network": [17, 24], "x": [10, 13, 21, 24], "propag": 24, "paramet": [3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26], "input": 24, "tensor": [9, 10, 13, 17, 19, 24], "predict": 24, "interpret": [13, 24], "function": [5, 7, 9, 10, 13, 19, 23, 24], "bool": [3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24], "basic": 24, "case": 24, "verifi": 24, "model": [7, 24], "can": [9, 10, 24], "fit": 24, "some": [9, 10, 24], "randomli": [3, 4, 5, 11, 16, 22, 24], "gener": [7, 9, 10, 24], "data": [7, 24], "alpha_vec": 24, "ndarrai": [3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 22, 23, 24], "q": [1, 9, 15, 18, 24, 25, 27], "lp": [9, 10, 12, 24], "check": [9, 20, 24], "whether": [8, 9, 10, 12, 19, 20, 24], "given": [3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 21, 22, 24, 26], "alpha": [9, 10, 20, 24], "vector": [3, 4, 5, 8, 9, 10, 11, 12, 13, 16, 17, 20, 21, 22, 24], "i": [8, 9, 10, 13, 20, 24], "domin": [20, 24], "cassandra": 24, "littman": 24, "zhang": 24, "1997": 24, "set": [9, 10, 12, 19, 20, 24], "against": [8, 10, 21, 24], "otherwis": [9, 24], "alpha_set": 24, "av": [20, 24], "alreadi": [20, 24], "true": [3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24], "fals": [7, 9, 10, 24], "lower_bound": [9, 10, 24], "lark": [20, 24], "filter": [9, 10, 20, 24], "algorithm": [3, 4, 5, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], "lower": [9, 10, 24], "current": [9, 10, 11, 13, 16, 21, 22, 23, 24], "csle": [25, 26], "object": [3, 4, 5, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 25, 26], "string": 25, "relat": 25, "bayesian": [3, 9, 10, 25], "among": 25, "all": [10, 13, 19, 20, 25], "baseline_": 25, "eval_": 25, "3": [3, 4, 5, 6, 8, 11, 12, 14, 16, 17, 21, 22, 25], "stop": [10, 11, 19, 22, 25], "game": [8, 10, 12, 19, 21, 25], "v1": 25, "mdp": [10, 13, 15, 18, 25], "attack": [21, 25], "pomdp": [9, 10, 20, 25], "defend": [11, 21, 22, 25], "cross": [4, 25], "entropi": [4, 25], "differenti": [5, 25], "evolut": [5, 25], "exploration_fracion": 25, "mlppolici": 25, "emulation_traces_to_save_with_data_collection_job": [7, 25], "environ": [3, 4, 5, 8, 11, 12, 16, 17, 21, 22, 25], "metric": [3, 4, 5, 7, 8, 11, 12, 16, 17, 21, 22, 25], "a2": [10, 12, 19, 25], "a1": [10, 12, 18, 19, 25], "o": [9, 10, 20, 25], "r": [9, 10, 13, 15, 18, 19, 20, 23, 25], "t": [7, 9, 10, 19, 20, 21, 22, 23, 25], "fictiti": [8, 25], "plai": [8, 10, 25], "lower_bound_s": 25, "upper_bound_s": 25, "posg": [10, 25], "kiefer": [11, 25], "wolfowitz": [11, 25], "linear": [10, 12, 13, 25], "program": [10, 12, 13, 25], "normal": [8, 12, 25], "form": [8, 12, 20, 25], "learn": [7, 15, 18, 21, 25], "random": [3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25], "search": [9, 10, 16, 17, 25], "shaplei": [10, 19, 25], "iter": [9, 10, 11, 13, 15, 18, 19, 20, 22, 23, 25], "sondik": [20, 25], "packag": 28, "subpackag": 28, "modul": 28, "content": 28, "trainingjobmanag": [0, 26, 27], "run_training_job": [0, 26, 27], "start_training_job_in_background": [0, 26, 27], "bayesoptag": [1, 3, 27], "compute_avg_metr": [1, 3, 4, 5, 8, 11, 12, 16, 17, 21, 22, 27], "eval_theta": [1, 3, 4, 5, 11, 16, 22, 27], "get_theta_vector_from_param_dict": [1, 3, 27], "initial_theta": [1, 3, 4, 5, 11, 16, 22, 27], "round_vec": [1, 3, 4, 5, 8, 11, 12, 16, 17, 21, 22, 27], "update_metr": [1, 3, 4, 5, 8, 11, 12, 16, 17, 21, 22, 27], "crossentropyag": [1, 4, 27], "differentialevolutionag": [1, 5, 27], "ensure_bound": [1, 5, 27], "dqnagent": [1, 6, 27], "dqntrainingcallback": [1, 6, 27], "datacollectorprocess": [1, 7, 27], "run": [1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27], "dynasecag": [1, 7, 27], "get_z_from_system_model": [1, 7, 27], "get_spsa_experiment_config": [1, 7, 27], "mean": [1, 7, 20, 27], "record_metr": [1, 7, 27], "emulationmonitorthread": [1, 7, 27], "emulationstatisticsthread": [1, 7, 27], "policyevaluationthread": [1, 7, 27], "eval_trac": [1, 7, 27], "policyoptimizationprocess": [1, 7, 27], "systemidentificationprocess": [1, 7, 27], "fictitiousplayag": [1, 8, 27], "best_respons": [1, 8, 27], "compute_empirical_strategi": [1, 8, 27], "hsviagent": [1, 9, 27], "approximate_projection_sawtooth": [1, 9, 27], "bayes_filt": [1, 9, 10, 27], "explor": [1, 9, 10, 15, 18, 27], "generate_corner_belief": [1, 9, 10, 27], "hsvi_algorithm": [1, 9, 27], "initialize_lower_bound": [1, 9, 10, 27], "initialize_upper_bound": [1, 9, 10, 27], "interior_point_belief_v": [1, 9, 27], "local_lower_bound_upd": [1, 9, 10, 27], "local_upd": [1, 9, 10, 27], "local_upper_bound_upd": [1, 9, 10, 27], "lower_bound_backup": [1, 9, 10, 27], "lower_bound_valu": [1, 9, 10, 27], "lp_convex_hull_projection_lp": [1, 9, 27], "next_belief": [1, 9, 10, 27], "observation_poss": [1, 9, 27], "one_step_lookahead": [1, 9, 10, 23, 27], "p_o_given_b_a": [1, 9, 27], "prune_upper_bound": [1, 9, 10, 27], "q_hat_interv": [1, 9, 27], "simul": [1, 3, 4, 5, 9, 11, 16, 20, 22, 27], "update_corner_point": [1, 9, 27], "upper_bound_backup": [1, 9, 10, 27], "upper_bound_valu": [1, 9, 10, 27], "hsviosposgag": [1, 10, 27], "auxillary_gam": [1, 10, 19, 27], "choose_a_o_for_explor": [1, 10, 27], "combine_weights_and_pure_strategies_into_mixed_strategi": [1, 10, 27], "compute_delta": [1, 10, 27], "compute_equilibrium_strategies_in_matrix_gam": [1, 10, 12, 27], "compute_matrix_game_valu": [1, 10, 12, 19, 27], "delta_lipschitz_envelope_of_upper_bound_valu": [1, 10, 27], "maxcomp_shapley_bellman_oper": [1, 10, 27], "mdp_reward_matrix_p2": [1, 10, 27], "mdp_transition_tensor_p2": [1, 10, 27], "obtain_equilibrium_strategy_profiles_in_stage_gam": [1, 10, 27], "p_o_given_b_a1_a2": [1, 10, 27], "p_o_given_b_pi_1_pi_2": [1, 10, 27], "rho": [1, 10, 27], "sample_d": [1, 10, 27], "si": [1, 10, 19, 27], "valcomp": [1, 10, 27], "value_of_p1_strategy_stat": [1, 10, 27], "weighted_excess_gap": [1, 10, 27], "kieferwolfowitzag": [1, 11, 27], "batch_gradi": [1, 11, 22, 27], "estimate_gk": [1, 11, 22, 27], "linearprogrammingnormalformgameag": [1, 12, 27], "linear_programming_normal_form": [1, 12, 27], "piagent": [1, 13, 27], "evaluate_polici": [1, 13, 15, 18, 20, 23, 27], "expected_reward_under_polici": [1, 13, 27], "policy_evalu": [1, 13, 27], "policy_improv": [1, 13, 27], "policy_iter": [1, 13, 27], "transition_probability_under_polici": [1, 13, 27], "ppoagent": [1, 14, 27], "ppotrainingcallback": [1, 14, 27], "qlearningag": [1, 15, 27], "create_policy_from_q_t": [1, 15, 18, 27], "eps_greedi": [1, 15, 18, 27], "initialize_count_t": [1, 15, 18, 27], "initialize_q_t": [1, 15, 18, 27], "q_learning_upd": [1, 15, 27], "step_siz": [1, 15, 18, 27], "train_q_learn": [1, 15, 27], "randomsearchag": [1, 16, 27], "random_perturb": [1, 16, 27], "reinforceag": [1, 17, 27], "training_step": [1, 17, 27], "sarsaag": [1, 18, 27], "sarsa_upd": [1, 18, 27], "train_sarsa": [1, 18, 27], "shapleyiterationag": [1, 19, 27], "sondikviag": [1, 20, 27], "compute_all_conditional_plans_conditioned_on_a_t": [1, 20, 27], "sondik_vi_algorithm": [1, 20, 27], "tfpagent": [1, 21, 27], "attacker_best_respons": [1, 21, 27], "defender_best_respons": [1, 21, 27], "evaluate_attacker_polici": [1, 21, 27], "evaluate_defender_polici": [1, 21, 27], "evaluate_strategy_profil": [1, 21, 27], "get_attacker_experiment_config": [1, 21, 27], "get_defender_experiment_config": [1, 21, 27], "tspsaagent": [1, 22, 27], "spsa": [1, 7, 22, 27], "standard_ak": [1, 22, 27], "standard_ck": [1, 22, 27], "standard_deltak": [1, 22, 27], "viagent": [1, 23, 27], "create_policy_from_value_funct": [1, 23, 27], "value_iter": [1, 23, 27], "union": [2, 3, 4, 5, 6, 8, 11, 12, 14, 16, 17, 21, 22], "env": [3, 4, 5, 6, 7, 8, 11, 12, 14, 16, 17, 21, 22], "option": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "training_job": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26], "trainingjobconfig": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26], "save_to_metastor": [3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23], "exp_result": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "experimentresult": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "seed": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "random_se": [3, 4, 5, 6, 8, 11, 12, 14, 16, 17, 21, 22], "experi": [3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23], "result": [3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23], "store": [3, 4, 5, 8, 11, 12, 16, 17, 22], "job": [3, 4, 5, 8, 11, 12, 16, 17, 22, 26], "config": [3, 4, 5, 8, 11, 12, 16, 17, 22], "updat": [3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23], "polici": [3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 20, 21, 22, 23], "static": [3, 4, 5, 7, 8, 10, 11, 12, 16, 17, 21, 22, 26], "dict": [3, 4, 5, 7, 8, 11, 12, 16, 17, 21, 22], "float": [3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "comput": [3, 4, 5, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23], "averag": [3, 4, 5, 8, 11, 12, 15, 16, 17, 18, 21, 22], "aggreg": [3, 4, 5, 8, 11, 12, 16, 17, 21, 22], "multithresholdstoppingpolici": [3, 4, 5, 11, 16, 22], "max_step": [3, 4, 5, 6, 7, 11, 14, 16, 22], "200": [3, 4, 5, 11, 16, 22], "evalu": [3, 4, 5, 7, 10, 11, 13, 15, 16, 18, 20, 21, 22, 23], "mont": [3, 4, 5, 11, 16, 21, 22], "carlo": [3, 4, 5, 11, 16, 21, 22], "param_dict": 3, "extract": 3, "from": [3, 4, 5, 6, 7, 8, 10, 11, 12, 14, 15, 16, 17, 18, 21, 22, 23], "hyperparamet": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "name": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "initi": [3, 4, 5, 9, 10, 11, 15, 16, 18, 20, 22], "vec": [3, 4, 5, 8, 11, 12, 16, 17, 21, 22], "round": [3, 4, 5, 8, 11, 12, 16, 17, 21, 22], "decim": [3, 4, 5, 8, 11, 12, 16, 17, 21, 22], "perform": [3, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 21, 22, 23], "info": [3, 4, 5, 8, 11, 12, 16, 17, 21, 22], "new": [3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 21, 22], "inform": [3, 4, 5, 8, 11, 12, 16, 17, 21, 22], "method": 4, "util": [5, 7, 10, 13], "ensur": [5, 10], "openai": [6, 14], "baselin": [6, 7, 14], "exp_execut": [6, 14], "simulation_nam": [6, 14], "action": [6, 8, 9, 10, 12, 13, 14, 15, 17, 18, 19, 20, 23], "player_typ": [6, 14], "playertyp": [6, 14], "verbos": [6, 10, 14], "0": [6, 7, 9, 10, 14, 15, 18, 19, 20, 23], "100": [6, 14], "10": [6, 9, 10, 14], "save_dir": [6, 14], "gym_env_nam": [6, 14], "basecallback": [6, 14], "callback": [6, 14], "monitor": [6, 14], "emulation_execut": 7, "emulationexecut": 7, "attacker_sequ": 7, "emulationattackeract": 7, "defender_sequ": 7, "emulationdefenderact": 7, "worker_id": 7, "emulation_statistics_window": 7, "emulationstatisticswindow": 7, "30": 7, "1": [7, 9, 10, 11, 12, 13, 19, 20, 22, 23], "thread": 7, "process": 7, "interact": 7, "emul": 7, "execut": 7, "system_identification_config": 7, "systemidentificationconfig": 7, "system_model": 7, "gaussianmixturesystemmodel": 7, "sample_spac": 7, "tupl": [7, 8, 9, 10, 12, 13, 15, 18, 19, 20, 21, 23], "configur": [7, 21, 26], "prob_vector": 7, "metrics_dict": 7, "record": 7, "import": 7, "them": 7, "sleep_time_minut": 7, "collect": 7, "data_collector_process": 7, "track": 7, "statist": 7, "baseline_polici": 7, "emulation_statistics_thread": 7, "baseline_system_model": 7, "period": 7, "trace": 7, "emulationtrac": 7, "defender_polici": 7, "eval": 7, "through": [7, 10, 22], "system": [7, 13], "emulation_statist": 7, "emulationstatist": 7, "collector": 7, "estim": [7, 9, 11, 21, 22], "brown": 8, "1951": 8, "p": [8, 9, 10, 13, 17, 20], "maxim": [8, 10, 12, 19], "best": [8, 10, 21], "respons": [8, 10, 21], "oppon": [8, 10], "strategi": [8, 10, 12, 15, 18, 19, 21], "payoff": 8, "matrix": [8, 10, 12, 13, 19, 20], "player": [8, 10, 12, 19], "minim": [8, 10, 12], "its": [8, 21], "valu": [8, 9, 10, 12, 13, 15, 18, 19, 20, 21, 23], "count": [8, 15, 18], "empir": 8, "heurist": [9, 10], "trei": [9, 10], "smith": [9, 10], "reid": [9, 10], "simmon": [9, 10], "2004": [9, 10], "upper_bound": [9, 10], "b": [9, 10], "refer": 9, "hauskreht": 9, "2000": 9, "approxim": 9, "project": 9, "belief": [9, 10, 20], "onto": 9, "convex": [9, 10], "hull": [9, 10], "upepr": 9, "upper": [9, 10], "point": [9, 10], "s_prime": [9, 10, 15, 18], "z": [9, 10, 20], "being": [9, 10], "when": [9, 10, 21], "after": [9, 10, 13], "take": [9, 10], "transit": [9, 10, 13, 19, 20, 23], "b_prime": [9, 10], "uncertainti": 9, "accuraci": [9, 10], "discount": [9, 10, 13, 15, 17, 18, 19, 20, 23], "factor": [9, 10, 13, 15, 17, 18, 19, 20, 23], "depth": [9, 10], "tree": [9, 10], "reward": [9, 10, 13, 15, 17, 18, 19, 20, 21, 23], "corner": [9, 10], "simplex": [9, 10], "correspond": [9, 10], "probabl": [9, 10, 13, 17, 20, 23], "b0": [9, 10, 20], "sawtooth": 9, "how": [9, 10], "often": [9, 10], "frequent": 9, "compur": 9, "length": 9, "interior_point": 9, "alpha_corn": 9, "induc": [9, 10, 20], "interior": 9, "local": [9, 10], "v": [9, 10, 13, 19, 20, 23], "boolean": [9, 10, 12, 19], "flag": [9, 10, 12, 19], "The": [9, 10, 13, 20], "dure": [9, 10], "solv": [9, 10, 13], "next": [9, 10, 15, 18, 23], "latest": [9, 10, 17], "space": [9, 10, 15, 18], "aciton": [9, 10, 19], "tocheck": 9, "possibl": [9, 10, 20], "fasl": 9, "discount_factor": [9, 10, 23], "one": [9, 10, 23], "step": [9, 10, 11, 13, 15, 16, 17, 18, 22, 23], "lookahead": [9, 10, 23], "kernel": [9, 10, 23], "tabl": [9, 10, 15, 18, 23], "next_state_lookahead": [9, 10, 23], "arrai": [9, 10, 23], "decid": [9, 10], "appli": 9, "bellman": [9, 10], "equat": [9, 10], "interv": [9, 10], "horizon": [9, 20], "greedi": [9, 10, 15, 18, 23], "respect": [9, 10], "which": [9, 10], "oper": [9, 10, 23], "cumul": 9, "corner_point": 9, "new_point": 9, "mayb": 9, "add": [9, 10], "0001": [9, 10, 23], "state_to_id": [9, 10, 23], "id": [9, 10, 23], "lookup": [9, 10, 23], "hp": [9, 10, 23], "hack": [9, 10, 23], "converg": [9, 10, 13, 23], "auxillari": [10, 19], "pi_2": 10, "follow": [10, 20, 21], "pi_1_upper_bound": 10, "pi_2_lower_bound": 10, "d": 10, "select": [10, 13, 15, 18], "accord": [10, 15, 18], "argmax_": 10, "b_1": 10, "a_1": 10, "hor\u00e1k": 10, "bosanski": 10, "kova\u0159\u00edk": 10, "kiekintveld": 10, "2020": 10, "time": 10, "equilibrium": [10, 12], "stage": [10, 19], "construct": 10, "lipschitz": 10, "continu": 10, "neighboorhood": 10, "weighted_excess": 10, "weight": [10, 17], "mixtur": 10, "mix": 10, "To": 10, "prove": 10, "we": 10, "requir": 10, "v_ub": 10, "v_lb": 10, "ar": 10, "well": 10, "thi": 10, "specif": 10, "u": 10, "where": [10, 13, 20], "teh": 10, "profil": [10, 12, 21], "ani": [10, 12], "also": [10, 12], "maximin": [10, 12, 19], "minimax": [10, 12, 19], "val": [10, 12, 19], "envelop": 10, "gap": 10, "horak": 10, "pechoucek": 10, "2017": 10, "neighborhood": 10, "p1": 10, "p2": 10, "zero": 10, "sum": 10, "achiev": 10, "each": [10, 13, 20], "uniform": 10, "singleton": 10, "fulli": 10, "version": 10, "preserv": 10, "properti": 10, "dear": 10, "child": 10, "mani": 10, "maxcomp": 10, "hv": 10, "pointwis": 10, "maximum": [10, 19], "over": 10, "By": 10, "solut": 10, "found": 10, "e": 10, "whole": 10, "purpos": 10, "karel": 10, "phd": 10, "thesi": 10, "2019": 10, "That": 10, "backup": 10, "exact": 10, "behavior": 10, "combin": [10, 20], "p1_strategi": 10, "fix": 10, "pi_1": 10, "tri": 10, "keep": 10, "between": 10, "most": 10, "monoton": 10, "increas": 10, "unbound": 10, "lipshitz": 10, "sampl": [10, 15, 18], "legal": 10, "rang": 10, "sequenc": 10, "need": 10, "2delta": 10, "max_iter": [10, 19], "500": [10, 19], "delta_threshold": [10, 19], "log": [10, 17], "1953": [10, 19], "sg": [10, 19], "themselv": [10, 19], "alpha_bar": 10, "substituted_alpha": 10, "composit": 10, "consist": 10, "distribut": 10, "expect": [10, 13], "c": [10, 22], "sigma_1": 10, "It": [10, 20], "assum": [10, 13], "further": 10, "sinc": 10, "subsequ": 10, "subgam": 10, "treat": 10, "independ": 10, "For": 10, "exampl": 10, "sa": [11, 15, 18], "50": 11, "batch": [11, 13, 15, 18, 20, 22, 23], "gradient": [11, 22], "ck": [11, 22], "perturb": [11, 16, 22], "size": [11, 13, 15, 16, 18, 20, 22, 23], "total": [11, 22], "includ": [11, 22], "evalut": [13, 15, 18, 20, 23], "tabular": [13, 15, 18, 20, 23], "immedi": [13, 20], "interleav": 13, "improv": 13, "guarante": 13, "scalar": [13, 22], "dynam": 13, "algebra": 13, "old": 13, "pi_prim": 13, "under": 13, "determinist": 13, "p_pi": 13, "start": [14, 26], "q_tabl": [15, 18], "n_state": [15, 18, 20], "256": [15, 18], "n_action": [15, 18, 20], "5": [15, 18], "count_tabl": [15, 18], "watkin": 15, "determin": [15, 18], "calcul": [15, 18, 21], "8": [15, 18], "10000": [15, 18], "saved_reward": 17, "saved_log_prob": 17, "policy_network": 17, "fnnwithsoftmax": 17, "encount": 17, "episod": 17, "trajectori": 17, "loss": 17, "eaction": 18, "indic": 19, "should": [19, 20], "1971": 20, "n_alpha_vectors_t_plus_on": 20, "n_ob": 20, "condit": 20, "plan": 20, "produc": 20, "conditional_plan": 20, "contain": 20, "element": [20, 21], "n_alpha_vector": 20, "_i": 20, "_j": 20, "_k": 20, "o_i": 20, "o_j": 20, "o_k": 20, "alphavectorspolici": 20, "aleph": 20, "remov": 20, "defender_simulation_env_config": 21, "attacker_simulation_env_config": 21, "todo": 21, "defender_strategi": 21, "mixedmultithresholdstoppingpolici": 21, "attacker_strategi": 21, "attacker_v": 21, "defender_v": 21, "last": 21, "hammar": 22, "stadler": 22, "2021": 22, "intrus": 22, "prevent": 22, "deltak": 22, "direct": 22, "get": 22, "ascent": 22, "index": 22, "a_k": 22, "lambda": 22, "pertrub": 22, "delta_k": 22, "manag": 26, "job_config": 26, "background": 26}, "objects": {"": [[27, 0, 0, "-", "csle_agents"]], "csle_agents": [[1, 0, 0, "-", "agents"], [24, 0, 0, "-", "common"], [25, 0, 0, "-", "constants"], [26, 0, 0, "-", "job_controllers"]], "csle_agents.agents": [[2, 0, 0, "-", "base"], [3, 0, 0, "-", "bayes_opt"], [4, 0, 0, "-", "cross_entropy"], [5, 0, 0, "-", "differential_evolution"], [6, 0, 0, "-", "dqn"], [7, 0, 0, "-", "dynasec"], [8, 0, 0, "-", "fp"], [9, 0, 0, "-", "hsvi"], [10, 0, 0, "-", "hsvi_os_posg"], [11, 0, 0, "-", "kiefer_wolfowitz"], [12, 0, 0, "-", "lp_nf"], [13, 0, 0, "-", "pi"], [14, 0, 0, "-", "ppo"], [15, 0, 0, "-", "q_learning"], [16, 0, 0, "-", "random_search"], [17, 0, 0, "-", "reinforce"], [18, 0, 0, "-", "sarsa"], [19, 0, 0, "-", "shapley_iteration"], [20, 0, 0, "-", "sondik_vi"], [21, 0, 0, "-", "t_fp"], [22, 0, 0, "-", "t_spsa"], [23, 0, 0, "-", "vi"]], "csle_agents.agents.base": [[2, 0, 0, "-", "base_agent"]], "csle_agents.agents.base.base_agent": [[2, 1, 1, "", "BaseAgent"]], "csle_agents.agents.base.base_agent.BaseAgent": [[2, 2, 1, "", "hparam_names"], [2, 2, 1, "", "train"]], "csle_agents.agents.bayes_opt": [[3, 0, 0, "-", "bayes_opt_agent"]], "csle_agents.agents.bayes_opt.bayes_opt_agent": [[3, 1, 1, "", "BayesOptAgent"]], "csle_agents.agents.bayes_opt.bayes_opt_agent.BayesOptAgent": [[3, 2, 1, "", "bayesian_optimization"], [3, 2, 1, "", "compute_avg_metrics"], [3, 2, 1, "", "eval_theta"], [3, 2, 1, "", "get_theta_vector_from_param_dict"], [3, 2, 1, "", "hparam_names"], [3, 2, 1, "", "initial_theta"], [3, 2, 1, "", "round_vec"], [3, 2, 1, "", "train"], [3, 2, 1, "", "update_metrics"]], "csle_agents.agents.cross_entropy": [[4, 0, 0, "-", "cross_entropy_agent"]], "csle_agents.agents.cross_entropy.cross_entropy_agent": [[4, 1, 1, "", "CrossEntropyAgent"]], "csle_agents.agents.cross_entropy.cross_entropy_agent.CrossEntropyAgent": [[4, 2, 1, "", "compute_avg_metrics"], [4, 2, 1, "", "cross_entropy"], [4, 2, 1, "", "eval_theta"], [4, 2, 1, "", "hparam_names"], [4, 2, 1, "", "initial_theta"], [4, 2, 1, "", "round_vec"], [4, 2, 1, "", "train"], [4, 2, 1, "", "update_metrics"]], "csle_agents.agents.differential_evolution": [[5, 0, 0, "-", "differential_evolution_agent"]], "csle_agents.agents.differential_evolution.differential_evolution_agent": [[5, 1, 1, "", "DifferentialEvolutionAgent"]], "csle_agents.agents.differential_evolution.differential_evolution_agent.DifferentialEvolutionAgent": [[5, 2, 1, "", "compute_avg_metrics"], [5, 2, 1, "", "differential_evolution"], [5, 2, 1, "", "ensure_bounds"], [5, 2, 1, "", "eval_theta"], [5, 2, 1, "", "hparam_names"], [5, 2, 1, "", "initial_theta"], [5, 2, 1, "", "round_vec"], [5, 2, 1, "", "train"], [5, 2, 1, "", "update_metrics"]], "csle_agents.agents.dqn": [[6, 0, 0, "-", "dqn_agent"]], "csle_agents.agents.dqn.dqn_agent": [[6, 1, 1, "", "DQNAgent"], [6, 1, 1, "", "DQNTrainingCallback"]], "csle_agents.agents.dqn.dqn_agent.DQNAgent": [[6, 2, 1, "", "hparam_names"], [6, 2, 1, "", "train"]], "csle_agents.agents.dynasec": [[7, 0, 0, "-", "dynasec_agent"]], "csle_agents.agents.dynasec.dynasec_agent": [[7, 1, 1, "", "DataCollectorProcess"], [7, 1, 1, "", "DynaSecAgent"], [7, 1, 1, "", "EmulationMonitorThread"], [7, 1, 1, "", "EmulationStatisticsThread"], [7, 1, 1, "", "PolicyEvaluationThread"], [7, 1, 1, "", "PolicyOptimizationProcess"], [7, 1, 1, "", "SystemIdentificationProcess"]], "csle_agents.agents.dynasec.dynasec_agent.DataCollectorProcess": [[7, 2, 1, "", "run"]], "csle_agents.agents.dynasec.dynasec_agent.DynaSecAgent": [[7, 2, 1, "", "get_Z_from_system_model"], [7, 2, 1, "", "get_spsa_experiment_config"], [7, 2, 1, "", "hparam_names"], [7, 2, 1, "", "mean"], [7, 2, 1, "", "record_metrics"], [7, 2, 1, "", "train"]], "csle_agents.agents.dynasec.dynasec_agent.EmulationMonitorThread": [[7, 2, 1, "", "run"]], "csle_agents.agents.dynasec.dynasec_agent.EmulationStatisticsThread": [[7, 2, 1, "", "run"]], "csle_agents.agents.dynasec.dynasec_agent.PolicyEvaluationThread": [[7, 2, 1, "", "eval_traces"], [7, 2, 1, "", "record_metrics"], [7, 2, 1, "", "run"]], "csle_agents.agents.dynasec.dynasec_agent.PolicyOptimizationProcess": [[7, 2, 1, "", "run"]], "csle_agents.agents.dynasec.dynasec_agent.SystemIdentificationProcess": [[7, 2, 1, "", "run"]], "csle_agents.agents.fp": [[8, 0, 0, "-", "fictitious_play_agent"]], "csle_agents.agents.fp.fictitious_play_agent": [[8, 1, 1, "", "FictitiousPlayAgent"]], "csle_agents.agents.fp.fictitious_play_agent.FictitiousPlayAgent": [[8, 2, 1, "", "best_response"], [8, 2, 1, "", "compute_avg_metrics"], [8, 2, 1, "", "compute_empirical_strategy"], [8, 2, 1, "", "fictitious_play"], [8, 2, 1, "", "hparam_names"], [8, 2, 1, "", "round_vec"], [8, 2, 1, "", "train"], [8, 2, 1, "", "update_metrics"]], "csle_agents.agents.hsvi": [[9, 0, 0, "-", "hsvi_agent"]], "csle_agents.agents.hsvi.hsvi_agent": [[9, 1, 1, "", "HSVIAgent"]], "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent": [[9, 2, 1, "", "approximate_projection_sawtooth"], [9, 2, 1, "", "bayes_filter"], [9, 2, 1, "", "excess"], [9, 2, 1, "", "explore"], [9, 2, 1, "", "generate_corner_belief"], [9, 2, 1, "", "hparam_names"], [9, 2, 1, "", "hsvi"], [9, 2, 1, "", "hsvi_algorithm"], [9, 2, 1, "", "initialize_lower_bound"], [9, 2, 1, "", "initialize_upper_bound"], [9, 2, 1, "", "interior_point_belief_val"], [9, 2, 1, "", "local_lower_bound_update"], [9, 2, 1, "", "local_updates"], [9, 2, 1, "", "local_upper_bound_update"], [9, 2, 1, "", "lower_bound_backup"], [9, 2, 1, "", "lower_bound_value"], [9, 2, 1, "", "lp_convex_hull_projection_lp"], [9, 2, 1, "", "next_belief"], [9, 2, 1, "", "observation_possible"], [9, 2, 1, "", "one_step_lookahead"], [9, 2, 1, "", "p_o_given_b_a"], [9, 2, 1, "", "prune_upper_bound"], [9, 2, 1, "", "q"], [9, 2, 1, "", "q_hat_interval"], [9, 2, 1, "", "simulate"], [9, 2, 1, "", "train"], [9, 2, 1, "", "update_corner_points"], [9, 2, 1, "", "upper_bound_backup"], [9, 2, 1, "", "upper_bound_value"], [9, 2, 1, "", "vi"], [9, 2, 1, "", "width"]], "csle_agents.agents.hsvi_os_posg": [[10, 0, 0, "-", "hsvi_os_posg_agent"]], "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent": [[10, 1, 1, "", "HSVIOSPOSGAgent"]], "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent": [[10, 2, 1, "", "auxillary_game"], [10, 2, 1, "", "bayes_filter"], [10, 2, 1, "", "choose_a_o_for_exploration"], [10, 2, 1, "", "combine_weights_and_pure_strategies_into_mixed_strategy"], [10, 2, 1, "", "compute_delta"], [10, 2, 1, "", "compute_equilibrium_strategies_in_matrix_game"], [10, 2, 1, "", "compute_matrix_game_value"], [10, 2, 1, "", "delta_lipschitz_envelope_of_upper_bound_value"], [10, 2, 1, "", "excess"], [10, 2, 1, "", "explore"], [10, 2, 1, "", "generate_corner_belief"], [10, 2, 1, "", "hparam_names"], [10, 2, 1, "", "hsvi"], [10, 2, 1, "", "hsvi_os_posg"], [10, 2, 1, "", "initialize_lower_bound"], [10, 2, 1, "", "initialize_upper_bound"], [10, 2, 1, "", "local_lower_bound_update"], [10, 2, 1, "", "local_updates"], [10, 2, 1, "", "local_upper_bound_update"], [10, 2, 1, "", "lower_bound_backup"], [10, 2, 1, "", "lower_bound_value"], [10, 2, 1, "", "maxcomp_shapley_bellman_operator"], [10, 2, 1, "", "mdp_reward_matrix_p2"], [10, 2, 1, "", "mdp_transition_tensor_p2"], [10, 2, 1, "", "next_belief"], [10, 2, 1, "", "obtain_equilibrium_strategy_profiles_in_stage_game"], [10, 2, 1, "", "one_step_lookahead"], [10, 2, 1, "", "p_o_given_b_a1_a2"], [10, 2, 1, "", "p_o_given_b_pi_1_pi_2"], [10, 2, 1, "", "prune_upper_bound"], [10, 2, 1, "", "rho"], [10, 2, 1, "", "sample_D"], [10, 2, 1, "", "si"], [10, 2, 1, "", "train"], [10, 2, 1, "", "upper_bound_backup"], [10, 2, 1, "", "upper_bound_value"], [10, 2, 1, "", "valcomp"], [10, 2, 1, "", "value_of_p1_strategy_static"], [10, 2, 1, "", "vi"], [10, 2, 1, "", "weighted_excess_gap"], [10, 2, 1, "", "width"]], "csle_agents.agents.kiefer_wolfowitz": [[11, 0, 0, "-", "kiefer_wolfowitz_agent"]], "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent": [[11, 1, 1, "", "KieferWolfowitzAgent"]], "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.KieferWolfowitzAgent": [[11, 2, 1, "", "batch_gradient"], [11, 2, 1, "", "compute_avg_metrics"], [11, 2, 1, "", "estimate_gk"], [11, 2, 1, "", "eval_theta"], [11, 2, 1, "", "hparam_names"], [11, 2, 1, "", "initial_theta"], [11, 2, 1, "", "kiefer_wolfowitz"], [11, 2, 1, "", "round_vec"], [11, 2, 1, "", "train"], [11, 2, 1, "", "update_metrics"]], "csle_agents.agents.lp_nf": [[12, 0, 0, "-", "linear_programming_normal_form_game_agent"]], "csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent": [[12, 1, 1, "", "LinearProgrammingNormalFormGameAgent"]], "csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.LinearProgrammingNormalFormGameAgent": [[12, 2, 1, "", "compute_avg_metrics"], [12, 2, 1, "", "compute_equilibrium_strategies_in_matrix_game"], [12, 2, 1, "", "compute_matrix_game_value"], [12, 2, 1, "", "hparam_names"], [12, 2, 1, "", "linear_programming_normal_form"], [12, 2, 1, "", "round_vec"], [12, 2, 1, "", "train"], [12, 2, 1, "", "update_metrics"]], "csle_agents.agents.pi": [[13, 0, 0, "-", "pi_agent"]], "csle_agents.agents.pi.pi_agent": [[13, 1, 1, "", "PIAgent"]], "csle_agents.agents.pi.pi_agent.PIAgent": [[13, 2, 1, "", "evaluate_policy"], [13, 2, 1, "", "expected_reward_under_policy"], [13, 2, 1, "", "hparam_names"], [13, 2, 1, "", "pi"], [13, 2, 1, "", "policy_evaluation"], [13, 2, 1, "", "policy_improvement"], [13, 2, 1, "", "policy_iteration"], [13, 2, 1, "", "train"], [13, 2, 1, "", "transition_probability_under_policy"]], "csle_agents.agents.ppo": [[14, 0, 0, "-", "ppo_agent"]], "csle_agents.agents.ppo.ppo_agent": [[14, 1, 1, "", "PPOAgent"], [14, 1, 1, "", "PPOTrainingCallback"]], "csle_agents.agents.ppo.ppo_agent.PPOAgent": [[14, 2, 1, "", "hparam_names"], [14, 2, 1, "", "train"]], "csle_agents.agents.q_learning": [[15, 0, 0, "-", "q_learning_agent"]], "csle_agents.agents.q_learning.q_learning_agent": [[15, 1, 1, "", "QLearningAgent"]], "csle_agents.agents.q_learning.q_learning_agent.QLearningAgent": [[15, 2, 1, "", "create_policy_from_q_table"], [15, 2, 1, "", "eps_greedy"], [15, 2, 1, "", "evaluate_policy"], [15, 2, 1, "", "hparam_names"], [15, 2, 1, "", "initialize_count_table"], [15, 2, 1, "", "initialize_q_table"], [15, 2, 1, "", "q_learning"], [15, 2, 1, "", "q_learning_update"], [15, 2, 1, "", "step_size"], [15, 2, 1, "", "train"], [15, 2, 1, "", "train_q_learning"]], "csle_agents.agents.random_search": [[16, 0, 0, "-", "random_search_agent"]], "csle_agents.agents.random_search.random_search_agent": [[16, 1, 1, "", "RandomSearchAgent"]], "csle_agents.agents.random_search.random_search_agent.RandomSearchAgent": [[16, 2, 1, "", "compute_avg_metrics"], [16, 2, 1, "", "eval_theta"], [16, 2, 1, "", "hparam_names"], [16, 2, 1, "", "initial_theta"], [16, 2, 1, "", "random_perturbation"], [16, 2, 1, "", "random_search"], [16, 2, 1, "", "round_vec"], [16, 2, 1, "", "train"], [16, 2, 1, "", "update_metrics"]], "csle_agents.agents.reinforce": [[17, 0, 0, "-", "reinforce_agent"]], "csle_agents.agents.reinforce.reinforce_agent": [[17, 1, 1, "", "ReinforceAgent"]], "csle_agents.agents.reinforce.reinforce_agent.ReinforceAgent": [[17, 2, 1, "", "compute_avg_metrics"], [17, 2, 1, "", "hparam_names"], [17, 2, 1, "", "reinforce"], [17, 2, 1, "", "round_vec"], [17, 2, 1, "", "train"], [17, 2, 1, "", "training_step"], [17, 2, 1, "", "update_metrics"]], "csle_agents.agents.sarsa": [[18, 0, 0, "-", "sarsa_agent"]], "csle_agents.agents.sarsa.sarsa_agent": [[18, 1, 1, "", "SARSAAgent"]], "csle_agents.agents.sarsa.sarsa_agent.SARSAAgent": [[18, 2, 1, "", "create_policy_from_q_table"], [18, 2, 1, "", "eps_greedy"], [18, 2, 1, "", "evaluate_policy"], [18, 2, 1, "", "hparam_names"], [18, 2, 1, "", "initialize_count_table"], [18, 2, 1, "", "initialize_q_table"], [18, 2, 1, "", "q_learning"], [18, 2, 1, "", "sarsa_update"], [18, 2, 1, "", "step_size"], [18, 2, 1, "", "train"], [18, 2, 1, "", "train_sarsa"]], "csle_agents.agents.shapley_iteration": [[19, 0, 0, "-", "shapley_iteration_agent"]], "csle_agents.agents.shapley_iteration.shapley_iteration_agent": [[19, 1, 1, "", "ShapleyIterationAgent"]], "csle_agents.agents.shapley_iteration.shapley_iteration_agent.ShapleyIterationAgent": [[19, 2, 1, "", "auxillary_game"], [19, 2, 1, "", "compute_matrix_game_value"], [19, 2, 1, "", "hparam_names"], [19, 2, 1, "", "shapley_iteration"], [19, 2, 1, "", "si"], [19, 2, 1, "", "train"]], "csle_agents.agents.sondik_vi": [[20, 0, 0, "-", "sondik_vi_agent"]], "csle_agents.agents.sondik_vi.sondik_vi_agent": [[20, 1, 1, "", "SondikVIAgent"]], "csle_agents.agents.sondik_vi.sondik_vi_agent.SondikVIAgent": [[20, 2, 1, "", "check_duplicate"], [20, 2, 1, "", "compute_all_conditional_plans_conditioned_on_a_t"], [20, 2, 1, "", "evaluate_policy"], [20, 2, 1, "", "hparam_names"], [20, 2, 1, "", "prune"], [20, 2, 1, "", "sondik_vi"], [20, 2, 1, "", "sondik_vi_algorithm"], [20, 2, 1, "", "train"]], "csle_agents.agents.t_fp": [[21, 0, 0, "-", "t_fp_agent"]], "csle_agents.agents.t_fp.t_fp_agent": [[21, 1, 1, "", "TFPAgent"]], "csle_agents.agents.t_fp.t_fp_agent.TFPAgent": [[21, 2, 1, "", "attacker_best_response"], [21, 2, 1, "", "compute_avg_metrics"], [21, 2, 1, "", "defender_best_response"], [21, 2, 1, "", "evaluate_attacker_policy"], [21, 2, 1, "", "evaluate_defender_policy"], [21, 2, 1, "", "evaluate_strategy_profile"], [21, 2, 1, "", "exploitability"], [21, 2, 1, "", "get_attacker_experiment_config"], [21, 2, 1, "", "get_defender_experiment_config"], [21, 2, 1, "", "hparam_names"], [21, 2, 1, "", "round_vec"], [21, 2, 1, "", "running_average"], [21, 2, 1, "", "t_fp"], [21, 2, 1, "", "train"], [21, 2, 1, "", "update_metrics"]], "csle_agents.agents.t_spsa": [[22, 0, 0, "-", "t_spsa_agent"]], "csle_agents.agents.t_spsa.t_spsa_agent": [[22, 1, 1, "", "TSPSAAgent"]], "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent": [[22, 2, 1, "", "batch_gradient"], [22, 2, 1, "", "compute_avg_metrics"], [22, 2, 1, "", "estimate_gk"], [22, 2, 1, "", "eval_theta"], [22, 2, 1, "", "hparam_names"], [22, 2, 1, "", "initial_theta"], [22, 2, 1, "", "round_vec"], [22, 2, 1, "", "spsa"], [22, 2, 1, "", "standard_ak"], [22, 2, 1, "", "standard_ck"], [22, 2, 1, "", "standard_deltak"], [22, 2, 1, "", "train"], [22, 2, 1, "", "update_metrics"]], "csle_agents.agents.vi": [[23, 0, 0, "-", "vi_agent"]], "csle_agents.agents.vi.vi_agent": [[23, 1, 1, "", "VIAgent"]], "csle_agents.agents.vi.vi_agent.VIAgent": [[23, 2, 1, "", "create_policy_from_value_function"], [23, 2, 1, "", "evaluate_policy"], [23, 2, 1, "", "hparam_names"], [23, 2, 1, "", "one_step_lookahead"], [23, 2, 1, "", "train"], [23, 2, 1, "", "value_iteration"], [23, 2, 1, "", "vi"]], "csle_agents.common": [[24, 0, 0, "-", "fnn_w_gaussian"], [24, 0, 0, "-", "fnn_w_linear"], [24, 0, 0, "-", "pruning"]], "csle_agents.common.fnn_w_gaussian": [[24, 1, 1, "", "FNNwithGaussian"], [24, 4, 1, "", "test"]], "csle_agents.common.fnn_w_gaussian.FNNwithGaussian": [[24, 2, 1, "", "forward"], [24, 2, 1, "", "get_hidden_activation"], [24, 3, 1, "", "training"]], "csle_agents.common.fnn_w_linear": [[24, 1, 1, "", "FNNwithLinear"], [24, 4, 1, "", "test"]], "csle_agents.common.fnn_w_linear.FNNwithLinear": [[24, 2, 1, "", "forward"], [24, 2, 1, "", "get_hidden_activation"], [24, 3, 1, "", "training"]], "csle_agents.common.pruning": [[24, 4, 1, "", "check_dominance_lp"], [24, 4, 1, "", "check_duplicate"], [24, 4, 1, "", "prune_lower_bound"]], "csle_agents.constants": [[25, 0, 0, "-", "constants"]], "csle_agents.constants.constants": [[25, 1, 1, "", "BAYESIAN_OPTIMIZATION"], [25, 1, 1, "", "COMMON"], [25, 1, 1, "", "CROSS_ENTROPY"], [25, 1, 1, "", "DIFFERENTIAL_EVOLUTION"], [25, 1, 1, "", "DQN"], [25, 1, 1, "", "DYNASEC"], [25, 1, 1, "", "ENV_METRICS"], [25, 1, 1, "", "FICTITIOUS_PLAY"], [25, 1, 1, "", "HSVI"], [25, 1, 1, "", "HSVI_OS_POSG"], [25, 1, 1, "", "KIEFER_WOLFOWITZ"], [25, 1, 1, "", "LP_FOR_NF_GAMES"], [25, 1, 1, "", "PI"], [25, 1, 1, "", "PPO"], [25, 1, 1, "", "Q_LEARNING"], [25, 1, 1, "", "RANDOM_SEARCH"], [25, 1, 1, "", "REINFORCE"], [25, 1, 1, "", "SARSA"], [25, 1, 1, "", "SHAPLEY_ITERATION"], [25, 1, 1, "", "SONDIK_VI"], [25, 1, 1, "", "T_FP"], [25, 1, 1, "", "VI"]], "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION": [[25, 3, 1, "", "L"], [25, 3, 1, "", "N"], [25, 3, 1, "", "PARAMETER_BOUNDS"], [25, 3, 1, "", "PARAMS"], [25, 3, 1, "", "STOP_DISTRIBUTION_ATTACKER"], [25, 3, 1, "", "STOP_DISTRIBUTION_DEFENDER"], [25, 3, 1, "", "TARGET"], [25, 3, 1, "", "THETA1"], [25, 3, 1, "", "THETAS"], [25, 3, 1, "", "THRESHOLDS"], [25, 3, 1, "", "UCB"], [25, 3, 1, "", "UCB_KAPPA"], [25, 3, 1, "", "UCB_XI"], [25, 3, 1, "", "UTILITY_FUNCTION"]], "csle_agents.constants.constants.COMMON": [[25, 3, 1, "", "ADAM"], [25, 3, 1, "", "AVERAGE_ATTACKER_RETURN"], [25, 3, 1, "", "AVERAGE_DEFENDER_RETURN"], [25, 3, 1, "", "AVERAGE_RANDOM_RETURN"], [25, 3, 1, "", "AVERAGE_RETURN"], [25, 3, 1, "", "AVERAGE_TIME_HORIZON"], [25, 3, 1, "", "AVERAGE_UPPER_BOUND_RETURN"], [25, 3, 1, "", "BASELINE_PREFIX"], [25, 3, 1, "", "BATCH_SIZE"], [25, 3, 1, "", "CONFIDENCE_INTERVAL"], [25, 3, 1, "", "EVAL_BATCH_SIZE"], [25, 3, 1, "", "EVAL_EVERY"], [25, 3, 1, "", "EVAL_PREFIX"], [25, 3, 1, "", "EXPLOITABILITY"], [25, 3, 1, "", "GAMMA"], [25, 3, 1, "", "L"], [25, 3, 1, "", "LEARNING_RATE"], [25, 3, 1, "", "LEARNING_RATE_DECAY_RATE"], [25, 3, 1, "", "LEARNING_RATE_EXP_DECAY"], [25, 3, 1, "", "MAX_ENV_STEPS"], [25, 3, 1, "", "NUM_CACHED_SIMULATION_TRACES"], [25, 3, 1, "", "NUM_NODES"], [25, 3, 1, "", "NUM_PARALLEL_ENVS"], [25, 3, 1, "", "NUM_TRAINING_TIMESTEPS"], [25, 3, 1, "", "OPTIMIZER"], [25, 3, 1, "", "POLICY_LOSSES"], [25, 3, 1, "", "RUNNING_AVERAGE"], [25, 3, 1, "", "RUNNING_AVERAGE_ATTACKER_RETURN"], [25, 3, 1, "", "RUNNING_AVERAGE_DEFENDER_RETURN"], [25, 3, 1, "", "RUNNING_AVERAGE_EXPLOITABILITY"], [25, 3, 1, "", "RUNNING_AVERAGE_INTRUSION_LENGTH"], [25, 3, 1, "", "RUNNING_AVERAGE_INTRUSION_START"], [25, 3, 1, "", "RUNNING_AVERAGE_RETURN"], [25, 3, 1, "", "RUNNING_AVERAGE_START_POINT_CORRECT"], [25, 3, 1, "", "RUNNING_AVERAGE_TIME_HORIZON"], [25, 3, 1, "", "RUNNING_AVERAGE_WEIGHTED_INTRUSION_PREDICTION_DISTANCE"], [25, 3, 1, "", "RUNTIME"], [25, 3, 1, "", "SAVE_EVERY"], [25, 3, 1, "", "SGD"], [25, 3, 1, "", "START_POINT_CORRECT"], [25, 3, 1, "", "STOPPING_ENVS"], [25, 3, 1, "", "WEIGHTED_INTRUSION_PREDICTION_DISTANCE"]], "csle_agents.constants.constants.CROSS_ENTROPY": [[25, 3, 1, "", "K"], [25, 3, 1, "", "L"], [25, 3, 1, "", "LAMB"], [25, 3, 1, "", "N"], [25, 3, 1, "", "STOP_DISTRIBUTION_ATTACKER"], [25, 3, 1, "", "STOP_DISTRIBUTION_DEFENDER"], [25, 3, 1, "", "THETA1"], [25, 3, 1, "", "THETAS"], [25, 3, 1, "", "THRESHOLDS"]], "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION": [[25, 3, 1, "", "BOUNDS"], [25, 3, 1, "", "L"], [25, 3, 1, "", "MUTATE"], [25, 3, 1, "", "N"], [25, 3, 1, "", "POPULATION_SIZE"], [25, 3, 1, "", "RECOMBINATION"], [25, 3, 1, "", "STOP_DISTRIBUTION_ATTACKER"], [25, 3, 1, "", "STOP_DISTRIBUTION_DEFENDER"], [25, 3, 1, "", "THETA1"], [25, 3, 1, "", "THETAS"], [25, 3, 1, "", "THRESHOLDS"]], "csle_agents.constants.constants.DQN": [[25, 3, 1, "", "BUFFER_SIZE"], [25, 3, 1, "", "DQN_BATCH_SIZE"], [25, 3, 1, "", "EXPLORATION_FINAL_EPS"], [25, 3, 1, "", "EXPLORATION_FRACTION"], [25, 3, 1, "", "EXPLORATION_INITIAL_EPS"], [25, 3, 1, "", "GRADIENT_STEPS"], [25, 3, 1, "", "LEARNING_STARTS"], [25, 3, 1, "", "MAX_GRAD_NORM"], [25, 3, 1, "", "MLP_POLICY"], [25, 3, 1, "", "N_EPISODES_ROLLOUT"], [25, 3, 1, "", "TARGET_UPDATE_INTERVAL"], [25, 3, 1, "", "TRAIN_FREQ"]], "csle_agents.constants.constants.DYNASEC": [[25, 3, 1, "", "CLIENTS_ARRIVAL_RATE"], [25, 3, 1, "", "EMULATION_MONITOR_SLEEP_TIME"], [25, 3, 1, "", "EMULATION_TRACES_TO_SAVE_W_DATA_COLLECTION_JOB"], [25, 3, 1, "", "INTRUSION_ALERTS_MEAN"], [25, 3, 1, "", "INTRUSION_ALERTS_MEAN_BASELINE"], [25, 3, 1, "", "INTRUSION_START_P"], [25, 3, 1, "", "NO_INTRUSION_ALERTS_MEAN"], [25, 3, 1, "", "NO_INTRUSION_ALERTS_MEAN_BASELINE"], [25, 3, 1, "", "NUM_CLIENTS"], [25, 3, 1, "", "REPLAY_WINDOW_SIZE"], [25, 3, 1, "", "SLEEP_TIME"], [25, 3, 1, "", "STATIC_ATTACKER_TYPE"], [25, 3, 1, "", "TRAINING_EPOCHS"], [25, 3, 1, "", "WARMUP_EPISODES"]], "csle_agents.constants.constants.ENV_METRICS": [[25, 3, 1, "", "ATTACKER_ACTION"], [25, 3, 1, "", "AVERAGE_RANDOM_RETURN"], [25, 3, 1, "", "AVERAGE_UPPER_BOUND_RETURN"], [25, 3, 1, "", "DEFENDER_ACTION"], [25, 3, 1, "", "OBSERVATION"], [25, 3, 1, "", "RETURN"], [25, 3, 1, "", "STATE"], [25, 3, 1, "", "TIME_HORIZON"], [25, 3, 1, "", "TIME_STEP"]], "csle_agents.constants.constants.FICTITIOUS_PLAY": [[25, 3, 1, "", "N"], [25, 3, 1, "", "PAYOFF_MATRIX"], [25, 3, 1, "", "PLAYER_1_PRIOR"], [25, 3, 1, "", "PLAYER_2_PRIOR"]], "csle_agents.constants.constants.HSVI": [[25, 3, 1, "", "ACTION_SPACE"], [25, 3, 1, "", "EPSILON"], [25, 3, 1, "", "INITIAL_BELIEF"], [25, 3, 1, "", "INITIAL_BELIEF_VALUES"], [25, 3, 1, "", "LB_SIZE"], [25, 3, 1, "", "LB_SIZES"], [25, 3, 1, "", "NUMBER_OF_SIMULATIONS"], [25, 3, 1, "", "OBSERVATION_SPACE"], [25, 3, 1, "", "OBSERVATION_TENSOR"], [25, 3, 1, "", "PRUNE_FREQUENCY"], [25, 3, 1, "", "REWARD_TENSOR"], [25, 3, 1, "", "SIMULATE_HORIZON"], [25, 3, 1, "", "SIMULATION_FREQUENCY"], [25, 3, 1, "", "STATE_SPACE"], [25, 3, 1, "", "TRANSITION_TENSOR"], [25, 3, 1, "", "UB_SIZE"], [25, 3, 1, "", "UB_SIZES"], [25, 3, 1, "", "USE_LP"], [25, 3, 1, "", "WIDTH"], [25, 3, 1, "", "WIDTHS"]], "csle_agents.constants.constants.HSVI_OS_POSG": [[25, 3, 1, "", "ACTION_SPACE_PLAYER_1"], [25, 3, 1, "", "ACTION_SPACE_PLAYER_2"], [25, 3, 1, "", "EPSILON"], [25, 3, 1, "", "EXCESSES"], [25, 3, 1, "", "INITIAL_BELIEF"], [25, 3, 1, "", "N"], [25, 3, 1, "", "OBSERVATION_FUNCTION"], [25, 3, 1, "", "OBSERVATION_SPACE"], [25, 3, 1, "", "PRUNE_FREQUENCY"], [25, 3, 1, "", "REWARD_TENSOR"], [25, 3, 1, "", "STATE_SPACE"], [25, 3, 1, "", "TRANSITION_TENSOR"], [25, 3, 1, "", "WIDTHS"]], "csle_agents.constants.constants.KIEFER_WOLFOWITZ": [[25, 3, 1, "", "DELTA"], [25, 3, 1, "", "GRADIENT_BATCH_SIZE"], [25, 3, 1, "", "INITIAL_ALPHA"], [25, 3, 1, "", "L"], [25, 3, 1, "", "N"], [25, 3, 1, "", "STOP_DISTRIBUTION_ATTACKER"], [25, 3, 1, "", "STOP_DISTRIBUTION_DEFENDER"], [25, 3, 1, "", "THETA1"], [25, 3, 1, "", "THETAS"], [25, 3, 1, "", "THRESHOLDS"]], "csle_agents.constants.constants.LP_FOR_NF_GAMES": [[25, 3, 1, "", "ACTION_SPACE_PLAYER_1"], [25, 3, 1, "", "ACTION_SPACE_PLAYER_2"], [25, 3, 1, "", "N"], [25, 3, 1, "", "PAYOFF_MATRIX"]], "csle_agents.constants.constants.PI": [[25, 3, 1, "", "INITIAL_POLICY"], [25, 3, 1, "", "N"], [25, 3, 1, "", "NUM_ACTIONS"], [25, 3, 1, "", "NUM_STATES"], [25, 3, 1, "", "REWARD_TENSOR"], [25, 3, 1, "", "TRANSITION_TENSOR"]], "csle_agents.constants.constants.PPO": [[25, 3, 1, "", "CLIP_RANGE"], [25, 3, 1, "", "CLIP_RANGE_VF"], [25, 3, 1, "", "ENT_COEF"], [25, 3, 1, "", "GAE_LAMBDA"], [25, 3, 1, "", "MAX_GRAD_NORM"], [25, 3, 1, "", "MLP_POLICY"], [25, 3, 1, "", "STEPS_BETWEEN_UPDATES"], [25, 3, 1, "", "TARGET_KL"], [25, 3, 1, "", "VF_COEF"]], "csle_agents.constants.constants.Q_LEARNING": [[25, 3, 1, "", "A"], [25, 3, 1, "", "EPSILON"], [25, 3, 1, "", "INITIAL_STATE_VALUES"], [25, 3, 1, "", "N"], [25, 3, 1, "", "S"]], "csle_agents.constants.constants.RANDOM_SEARCH": [[25, 3, 1, "", "DELTA"], [25, 3, 1, "", "L"], [25, 3, 1, "", "N"], [25, 3, 1, "", "STOP_DISTRIBUTION_ATTACKER"], [25, 3, 1, "", "STOP_DISTRIBUTION_DEFENDER"], [25, 3, 1, "", "THETA1"], [25, 3, 1, "", "THETAS"], [25, 3, 1, "", "THRESHOLDS"]], "csle_agents.constants.constants.REINFORCE": [[25, 3, 1, "", "CLIP_GRADIENT"], [25, 3, 1, "", "GRADIENT_BATCH_SIZE"], [25, 3, 1, "", "N"]], "csle_agents.constants.constants.SARSA": [[25, 3, 1, "", "A"], [25, 3, 1, "", "EPSILON"], [25, 3, 1, "", "INITIAL_STATE_VALUES"], [25, 3, 1, "", "N"], [25, 3, 1, "", "S"]], "csle_agents.constants.constants.SHAPLEY_ITERATION": [[25, 3, 1, "", "ACTION_SPACE_PLAYER_1"], [25, 3, 1, "", "ACTION_SPACE_PLAYER_2"], [25, 3, 1, "", "DELTA"], [25, 3, 1, "", "N"], [25, 3, 1, "", "REWARD_TENSOR"], [25, 3, 1, "", "STATE_SPACE"], [25, 3, 1, "", "TRANSITION_TENSOR"]], "csle_agents.constants.constants.SONDIK_VI": [[25, 3, 1, "", "ACTION_SPACE"], [25, 3, 1, "", "INITIAL_BELIEF"], [25, 3, 1, "", "INITIAL_BELIEF_VALUES"], [25, 3, 1, "", "NUM_ALPHA_VECTORS"], [25, 3, 1, "", "OBSERVATION_SPACE"], [25, 3, 1, "", "OBSERVATION_TENSOR"], [25, 3, 1, "", "PLANNING_HORIZON"], [25, 3, 1, "", "REWARD_TENSOR"], [25, 3, 1, "", "STATE_SPACE"], [25, 3, 1, "", "TRANSITION_TENSOR"], [25, 3, 1, "", "USE_PRUNING"]], "csle_agents.constants.constants.T_FP": [[25, 3, 1, "", "ATTACKER_THRESHOLDS"], [25, 3, 1, "", "AVERAGE_BEST_RESPONSE_ATTACKER_RETURN"], [25, 3, 1, "", "AVERAGE_BEST_RESPONSE_DEFENDER_RETURN"], [25, 3, 1, "", "BEST_RESPONSE_EVALUATION_ITERATIONS"], [25, 3, 1, "", "DEFENDER_THRESHOLDS"], [25, 3, 1, "", "EQUILIBRIUM_STRATEGIES_EVALUATION_ITERATIONS"], [25, 3, 1, "", "N_2"], [25, 3, 1, "", "RUNNING_AVERAGE_BEST_RESPONSE_ATTACKER_RETURN"], [25, 3, 1, "", "RUNNING_AVERAGE_BEST_RESPONSE_DEFENDER_RETURN"], [25, 3, 1, "", "THETA1_ATTACKER"], [25, 3, 1, "", "THETA1_DEFENDER"]], "csle_agents.constants.constants.VI": [[25, 3, 1, "", "DELTA"], [25, 3, 1, "", "NUM_ACTIONS"], [25, 3, 1, "", "NUM_STATES"], [25, 3, 1, "", "REWARD_TENSOR"], [25, 3, 1, "", "THETA"], [25, 3, 1, "", "TRANSITION_TENSOR"]], "csle_agents.job_controllers": [[26, 0, 0, "-", "training_job_manager"]], "csle_agents.job_controllers.training_job_manager": [[26, 1, 1, "", "TrainingJobManager"]], "csle_agents.job_controllers.training_job_manager.TrainingJobManager": [[26, 2, 1, "", "run_training_job"], [26, 2, 1, "", "start_training_job_in_background"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:attribute", "4": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "attribute", "Python attribute"], "4": ["py", "function", "Python function"]}, "titleterms": {"csle_ag": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], "packag": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27], "subpackag": [0, 1, 27], "modul": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27], "content": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27], "agent": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "base": 2, "submodul": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26], "base_ag": 2, "bayes_opt": 3, "bayes_opt_ag": 3, "cross_entropi": 4, "cross_entropy_ag": 4, "differential_evolut": 5, "differential_evolution_ag": 5, "dqn": 6, "dqn_agent": 6, "dynasec": 7, "dynasec_ag": 7, "fp": 8, "fictitious_play_ag": 8, "hsvi": 9, "hsvi_ag": 9, "hsvi_os_posg": 10, "hsvi_os_posg_ag": 10, "kiefer_wolfowitz": 11, "kiefer_wolfowitz_ag": 11, "lp_nf": 12, "linear_programming_normal_form_game_ag": 12, "pi": 13, "pi_ag": 13, "ppo": 14, "ppo_ag": 14, "q_learn": 15, "q_learning_ag": 15, "random_search": 16, "random_search_ag": 16, "reinforc": 17, "reinforce_ag": 17, "sarsa": 18, "sarsa_ag": 18, "shapley_iter": 19, "shapley_iteration_ag": 19, "sondik_vi": 20, "sondik_vi_ag": 20, "t_fp": 21, "t_fp_agent": 21, "t_spsa": 22, "t_spsa_ag": 22, "vi": 23, "vi_ag": 23, "common": 24, "actor_critic_net": 24, "fnn_w_gaussian": 24, "fnn_w_linear": 24, "prune": 24, "constant": 25, "job_control": 26, "training_job_manag": 26}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"csle_agents package": [[0, "csle-agents-package"], [27, "csle-agents-package"]], "Subpackages": [[0, "subpackages"], [1, "subpackages"], [27, "subpackages"]], "Module contents": [[0, "module-csle_agents"], [1, "module-csle_agents.agents"], [2, "module-csle_agents.agents.base"], [3, "module-csle_agents.agents.bayes_opt"], [4, "module-csle_agents.agents.cross_entropy"], [5, "module-csle_agents.agents.differential_evolution"], [6, "module-csle_agents.agents.dqn"], [7, "module-csle_agents.agents.dynasec"], [8, "module-csle_agents.agents.fp"], [9, "module-csle_agents.agents.hsvi"], [10, "module-csle_agents.agents.hsvi_os_posg"], [11, "module-csle_agents.agents.kiefer_wolfowitz"], [12, "module-csle_agents.agents.lp_nf"], [13, "module-csle_agents.agents.pi"], [14, "module-csle_agents.agents.ppo"], [15, "module-csle_agents.agents.q_learning"], [16, "module-csle_agents.agents.random_search"], [17, "module-csle_agents.agents.reinforce"], [18, "module-csle_agents.agents.sarsa"], [19, "module-csle_agents.agents.shapley_iteration"], [20, "module-csle_agents.agents.sondik_vi"], [21, "module-csle_agents.agents.t_fp"], [22, "module-csle_agents.agents.t_spsa"], [23, "module-csle_agents.agents.vi"], [24, "module-csle_agents.common"], [25, "module-csle_agents.constants"], [26, "module-csle_agents.job_controllers"], [27, "module-csle_agents"]], "csle_agents.agents package": [[1, "csle-agents-agents-package"]], "csle_agents.agents.base package": [[2, "csle-agents-agents-base-package"]], "Submodules": [[2, "submodules"], [3, "submodules"], [4, "submodules"], [5, "submodules"], [6, "submodules"], [7, "submodules"], [8, "submodules"], [9, "submodules"], [10, "submodules"], [11, "submodules"], [12, "submodules"], [13, "submodules"], [14, "submodules"], [15, "submodules"], [16, "submodules"], [17, "submodules"], [18, "submodules"], [19, "submodules"], [20, "submodules"], [21, "submodules"], [22, "submodules"], [23, "submodules"], [24, "submodules"], [25, "submodules"], [26, "submodules"]], "csle_agents.agents.base.base_agent module": [[2, "module-csle_agents.agents.base.base_agent"]], "csle_agents.agents.bayes_opt package": [[3, "csle-agents-agents-bayes-opt-package"]], "csle_agents.agents.bayes_opt.bayes_opt_agent module": [[3, "module-csle_agents.agents.bayes_opt.bayes_opt_agent"]], "csle_agents.agents.cross_entropy package": [[4, "csle-agents-agents-cross-entropy-package"]], "csle_agents.agents.cross_entropy.cross_entropy_agent module": [[4, "module-csle_agents.agents.cross_entropy.cross_entropy_agent"]], "csle_agents.agents.differential_evolution package": [[5, "csle-agents-agents-differential-evolution-package"]], "csle_agents.agents.differential_evolution.differential_evolution_agent module": [[5, "module-csle_agents.agents.differential_evolution.differential_evolution_agent"]], "csle_agents.agents.dqn package": [[6, "csle-agents-agents-dqn-package"]], "csle_agents.agents.dqn.dqn_agent module": [[6, "module-csle_agents.agents.dqn.dqn_agent"]], "csle_agents.agents.dynasec package": [[7, "csle-agents-agents-dynasec-package"]], "csle_agents.agents.dynasec.dynasec_agent module": [[7, "module-csle_agents.agents.dynasec.dynasec_agent"]], "csle_agents.agents.fp package": [[8, "csle-agents-agents-fp-package"]], "csle_agents.agents.fp.fictitious_play_agent module": [[8, "module-csle_agents.agents.fp.fictitious_play_agent"]], "csle_agents.agents.hsvi package": [[9, "csle-agents-agents-hsvi-package"]], "csle_agents.agents.hsvi.hsvi_agent module": [[9, "module-csle_agents.agents.hsvi.hsvi_agent"]], "csle_agents.agents.hsvi_os_posg package": [[10, "csle-agents-agents-hsvi-os-posg-package"]], "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent module": [[10, "module-csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent"]], "csle_agents.agents.kiefer_wolfowitz package": [[11, "csle-agents-agents-kiefer-wolfowitz-package"]], "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent module": [[11, "module-csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent"]], "csle_agents.agents.lp_nf package": [[12, "csle-agents-agents-lp-nf-package"]], "csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent module": [[12, "module-csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent"]], "csle_agents.agents.pi package": [[13, "csle-agents-agents-pi-package"]], "csle_agents.agents.pi.pi_agent module": [[13, "module-csle_agents.agents.pi.pi_agent"]], "csle_agents.agents.ppo package": [[14, "csle-agents-agents-ppo-package"]], "csle_agents.agents.ppo.ppo_agent module": [[14, "module-csle_agents.agents.ppo.ppo_agent"]], "csle_agents.agents.q_learning package": [[15, "csle-agents-agents-q-learning-package"]], "csle_agents.agents.q_learning.q_learning_agent module": [[15, "module-csle_agents.agents.q_learning.q_learning_agent"]], "csle_agents.agents.random_search package": [[16, "csle-agents-agents-random-search-package"]], "csle_agents.agents.random_search.random_search_agent module": [[16, "module-csle_agents.agents.random_search.random_search_agent"]], "csle_agents.agents.reinforce package": [[17, "csle-agents-agents-reinforce-package"]], "csle_agents.agents.reinforce.reinforce_agent module": [[17, "module-csle_agents.agents.reinforce.reinforce_agent"]], "csle_agents.agents.sarsa package": [[18, "csle-agents-agents-sarsa-package"]], "csle_agents.agents.sarsa.sarsa_agent module": [[18, "module-csle_agents.agents.sarsa.sarsa_agent"]], "csle_agents.agents.shapley_iteration package": [[19, "csle-agents-agents-shapley-iteration-package"]], "csle_agents.agents.shapley_iteration.shapley_iteration_agent module": [[19, "module-csle_agents.agents.shapley_iteration.shapley_iteration_agent"]], "csle_agents.agents.sondik_vi package": [[20, "csle-agents-agents-sondik-vi-package"]], "csle_agents.agents.sondik_vi.sondik_vi_agent module": [[20, "module-csle_agents.agents.sondik_vi.sondik_vi_agent"]], "csle_agents.agents.t_fp package": [[21, "csle-agents-agents-t-fp-package"]], "csle_agents.agents.t_fp.t_fp_agent module": [[21, "module-csle_agents.agents.t_fp.t_fp_agent"]], "csle_agents.agents.t_spsa package": [[22, "csle-agents-agents-t-spsa-package"]], "csle_agents.agents.t_spsa.t_spsa_agent module": [[22, "module-csle_agents.agents.t_spsa.t_spsa_agent"]], "csle_agents.agents.vi package": [[23, "csle-agents-agents-vi-package"]], "csle_agents.agents.vi.vi_agent module": [[23, "module-csle_agents.agents.vi.vi_agent"]], "csle_agents.common package": [[24, "csle-agents-common-package"]], "csle_agents.common.actor_critic_net module": [[24, "csle-agents-common-actor-critic-net-module"]], "csle_agents.common.fnn_w_gaussian module": [[24, "module-csle_agents.common.fnn_w_gaussian"]], "csle_agents.common.fnn_w_linear module": [[24, "module-csle_agents.common.fnn_w_linear"]], "csle_agents.common.pruning module": [[24, "module-csle_agents.common.pruning"]], "csle_agents.constants package": [[25, "csle-agents-constants-package"]], "csle_agents.constants.constants module": [[25, "module-csle_agents.constants.constants"]], "csle_agents.job_controllers package": [[26, "csle-agents-job-controllers-package"]], "csle_agents.job_controllers.training_job_manager module": [[26, "module-csle_agents.job_controllers.training_job_manager"]], "csle_agents": [[28, "csle-agents"]]}, "indexentries": {"csle_agents": [[0, "module-csle_agents"], [27, "module-csle_agents"]], "module": [[0, "module-csle_agents"], [1, "module-csle_agents.agents"], [2, "module-csle_agents.agents.base"], [2, "module-csle_agents.agents.base.base_agent"], [3, "module-csle_agents.agents.bayes_opt"], [3, "module-csle_agents.agents.bayes_opt.bayes_opt_agent"], [4, "module-csle_agents.agents.cross_entropy"], [4, "module-csle_agents.agents.cross_entropy.cross_entropy_agent"], [5, "module-csle_agents.agents.differential_evolution"], [5, "module-csle_agents.agents.differential_evolution.differential_evolution_agent"], [6, "module-csle_agents.agents.dqn"], [6, "module-csle_agents.agents.dqn.dqn_agent"], [7, "module-csle_agents.agents.dynasec"], [7, "module-csle_agents.agents.dynasec.dynasec_agent"], [8, "module-csle_agents.agents.fp"], [8, "module-csle_agents.agents.fp.fictitious_play_agent"], [9, "module-csle_agents.agents.hsvi"], [9, "module-csle_agents.agents.hsvi.hsvi_agent"], [10, "module-csle_agents.agents.hsvi_os_posg"], [10, "module-csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent"], [11, "module-csle_agents.agents.kiefer_wolfowitz"], [11, "module-csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent"], [12, "module-csle_agents.agents.lp_nf"], [12, "module-csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent"], [13, "module-csle_agents.agents.pi"], [13, "module-csle_agents.agents.pi.pi_agent"], [14, "module-csle_agents.agents.ppo"], [14, "module-csle_agents.agents.ppo.ppo_agent"], [15, "module-csle_agents.agents.q_learning"], [15, "module-csle_agents.agents.q_learning.q_learning_agent"], [16, "module-csle_agents.agents.random_search"], [16, "module-csle_agents.agents.random_search.random_search_agent"], [17, "module-csle_agents.agents.reinforce"], [17, "module-csle_agents.agents.reinforce.reinforce_agent"], [18, "module-csle_agents.agents.sarsa"], [18, "module-csle_agents.agents.sarsa.sarsa_agent"], [19, "module-csle_agents.agents.shapley_iteration"], [19, "module-csle_agents.agents.shapley_iteration.shapley_iteration_agent"], [20, "module-csle_agents.agents.sondik_vi"], [20, "module-csle_agents.agents.sondik_vi.sondik_vi_agent"], [21, "module-csle_agents.agents.t_fp"], [21, "module-csle_agents.agents.t_fp.t_fp_agent"], [22, "module-csle_agents.agents.t_spsa"], [22, "module-csle_agents.agents.t_spsa.t_spsa_agent"], [23, "module-csle_agents.agents.vi"], [23, "module-csle_agents.agents.vi.vi_agent"], [24, "module-csle_agents.common"], [24, "module-csle_agents.common.fnn_w_gaussian"], [24, "module-csle_agents.common.fnn_w_linear"], [24, "module-csle_agents.common.pruning"], [25, "module-csle_agents.constants"], [25, "module-csle_agents.constants.constants"], [26, "module-csle_agents.job_controllers"], [26, "module-csle_agents.job_controllers.training_job_manager"], [27, "module-csle_agents"]], "csle_agents.agents": [[1, "module-csle_agents.agents"]], "baseagent (class in csle_agents.agents.base.base_agent)": [[2, "csle_agents.agents.base.base_agent.BaseAgent"]], "csle_agents.agents.base": [[2, "module-csle_agents.agents.base"]], "csle_agents.agents.base.base_agent": [[2, "module-csle_agents.agents.base.base_agent"]], "hparam_names() (csle_agents.agents.base.base_agent.baseagent method)": [[2, "csle_agents.agents.base.base_agent.BaseAgent.hparam_names"]], "train() (csle_agents.agents.base.base_agent.baseagent method)": [[2, "csle_agents.agents.base.base_agent.BaseAgent.train"]], "bayesoptagent (class in csle_agents.agents.bayes_opt.bayes_opt_agent)": [[3, "csle_agents.agents.bayes_opt.bayes_opt_agent.BayesOptAgent"]], "bayesian_optimization() (csle_agents.agents.bayes_opt.bayes_opt_agent.bayesoptagent method)": [[3, "csle_agents.agents.bayes_opt.bayes_opt_agent.BayesOptAgent.bayesian_optimization"]], "compute_avg_metrics() (csle_agents.agents.bayes_opt.bayes_opt_agent.bayesoptagent static method)": [[3, "csle_agents.agents.bayes_opt.bayes_opt_agent.BayesOptAgent.compute_avg_metrics"]], "csle_agents.agents.bayes_opt": [[3, "module-csle_agents.agents.bayes_opt"]], "csle_agents.agents.bayes_opt.bayes_opt_agent": [[3, "module-csle_agents.agents.bayes_opt.bayes_opt_agent"]], "eval_theta() (csle_agents.agents.bayes_opt.bayes_opt_agent.bayesoptagent method)": [[3, "csle_agents.agents.bayes_opt.bayes_opt_agent.BayesOptAgent.eval_theta"]], "get_theta_vector_from_param_dict() (csle_agents.agents.bayes_opt.bayes_opt_agent.bayesoptagent static method)": [[3, "csle_agents.agents.bayes_opt.bayes_opt_agent.BayesOptAgent.get_theta_vector_from_param_dict"]], "hparam_names() (csle_agents.agents.bayes_opt.bayes_opt_agent.bayesoptagent method)": [[3, "csle_agents.agents.bayes_opt.bayes_opt_agent.BayesOptAgent.hparam_names"]], "initial_theta() (csle_agents.agents.bayes_opt.bayes_opt_agent.bayesoptagent static method)": [[3, "csle_agents.agents.bayes_opt.bayes_opt_agent.BayesOptAgent.initial_theta"]], "round_vec() (csle_agents.agents.bayes_opt.bayes_opt_agent.bayesoptagent static method)": [[3, "csle_agents.agents.bayes_opt.bayes_opt_agent.BayesOptAgent.round_vec"]], "train() (csle_agents.agents.bayes_opt.bayes_opt_agent.bayesoptagent method)": [[3, "csle_agents.agents.bayes_opt.bayes_opt_agent.BayesOptAgent.train"]], "update_metrics() (csle_agents.agents.bayes_opt.bayes_opt_agent.bayesoptagent static method)": [[3, "csle_agents.agents.bayes_opt.bayes_opt_agent.BayesOptAgent.update_metrics"]], "crossentropyagent (class in csle_agents.agents.cross_entropy.cross_entropy_agent)": [[4, "csle_agents.agents.cross_entropy.cross_entropy_agent.CrossEntropyAgent"]], "compute_avg_metrics() (csle_agents.agents.cross_entropy.cross_entropy_agent.crossentropyagent static method)": [[4, "csle_agents.agents.cross_entropy.cross_entropy_agent.CrossEntropyAgent.compute_avg_metrics"]], "cross_entropy() (csle_agents.agents.cross_entropy.cross_entropy_agent.crossentropyagent method)": [[4, "csle_agents.agents.cross_entropy.cross_entropy_agent.CrossEntropyAgent.cross_entropy"]], "csle_agents.agents.cross_entropy": [[4, "module-csle_agents.agents.cross_entropy"]], "csle_agents.agents.cross_entropy.cross_entropy_agent": [[4, "module-csle_agents.agents.cross_entropy.cross_entropy_agent"]], "eval_theta() (csle_agents.agents.cross_entropy.cross_entropy_agent.crossentropyagent method)": [[4, "csle_agents.agents.cross_entropy.cross_entropy_agent.CrossEntropyAgent.eval_theta"]], "hparam_names() (csle_agents.agents.cross_entropy.cross_entropy_agent.crossentropyagent method)": [[4, "csle_agents.agents.cross_entropy.cross_entropy_agent.CrossEntropyAgent.hparam_names"]], "initial_theta() (csle_agents.agents.cross_entropy.cross_entropy_agent.crossentropyagent static method)": [[4, "csle_agents.agents.cross_entropy.cross_entropy_agent.CrossEntropyAgent.initial_theta"]], "round_vec() (csle_agents.agents.cross_entropy.cross_entropy_agent.crossentropyagent static method)": [[4, "csle_agents.agents.cross_entropy.cross_entropy_agent.CrossEntropyAgent.round_vec"]], "train() (csle_agents.agents.cross_entropy.cross_entropy_agent.crossentropyagent method)": [[4, "csle_agents.agents.cross_entropy.cross_entropy_agent.CrossEntropyAgent.train"]], "update_metrics() (csle_agents.agents.cross_entropy.cross_entropy_agent.crossentropyagent static method)": [[4, "csle_agents.agents.cross_entropy.cross_entropy_agent.CrossEntropyAgent.update_metrics"]], "differentialevolutionagent (class in csle_agents.agents.differential_evolution.differential_evolution_agent)": [[5, "csle_agents.agents.differential_evolution.differential_evolution_agent.DifferentialEvolutionAgent"]], "compute_avg_metrics() (csle_agents.agents.differential_evolution.differential_evolution_agent.differentialevolutionagent static method)": [[5, "csle_agents.agents.differential_evolution.differential_evolution_agent.DifferentialEvolutionAgent.compute_avg_metrics"]], "csle_agents.agents.differential_evolution": [[5, "module-csle_agents.agents.differential_evolution"]], "csle_agents.agents.differential_evolution.differential_evolution_agent": [[5, "module-csle_agents.agents.differential_evolution.differential_evolution_agent"]], "differential_evolution() (csle_agents.agents.differential_evolution.differential_evolution_agent.differentialevolutionagent method)": [[5, "csle_agents.agents.differential_evolution.differential_evolution_agent.DifferentialEvolutionAgent.differential_evolution"]], "ensure_bounds() (csle_agents.agents.differential_evolution.differential_evolution_agent.differentialevolutionagent method)": [[5, "csle_agents.agents.differential_evolution.differential_evolution_agent.DifferentialEvolutionAgent.ensure_bounds"]], "eval_theta() (csle_agents.agents.differential_evolution.differential_evolution_agent.differentialevolutionagent method)": [[5, "csle_agents.agents.differential_evolution.differential_evolution_agent.DifferentialEvolutionAgent.eval_theta"]], "hparam_names() (csle_agents.agents.differential_evolution.differential_evolution_agent.differentialevolutionagent method)": [[5, "csle_agents.agents.differential_evolution.differential_evolution_agent.DifferentialEvolutionAgent.hparam_names"]], "initial_theta() (csle_agents.agents.differential_evolution.differential_evolution_agent.differentialevolutionagent static method)": [[5, "csle_agents.agents.differential_evolution.differential_evolution_agent.DifferentialEvolutionAgent.initial_theta"]], "round_vec() (csle_agents.agents.differential_evolution.differential_evolution_agent.differentialevolutionagent static method)": [[5, "csle_agents.agents.differential_evolution.differential_evolution_agent.DifferentialEvolutionAgent.round_vec"]], "train() (csle_agents.agents.differential_evolution.differential_evolution_agent.differentialevolutionagent method)": [[5, "csle_agents.agents.differential_evolution.differential_evolution_agent.DifferentialEvolutionAgent.train"]], "update_metrics() (csle_agents.agents.differential_evolution.differential_evolution_agent.differentialevolutionagent static method)": [[5, "csle_agents.agents.differential_evolution.differential_evolution_agent.DifferentialEvolutionAgent.update_metrics"]], "dqnagent (class in csle_agents.agents.dqn.dqn_agent)": [[6, "csle_agents.agents.dqn.dqn_agent.DQNAgent"]], "dqntrainingcallback (class in csle_agents.agents.dqn.dqn_agent)": [[6, "csle_agents.agents.dqn.dqn_agent.DQNTrainingCallback"]], "csle_agents.agents.dqn": [[6, "module-csle_agents.agents.dqn"]], "csle_agents.agents.dqn.dqn_agent": [[6, "module-csle_agents.agents.dqn.dqn_agent"]], "hparam_names() (csle_agents.agents.dqn.dqn_agent.dqnagent method)": [[6, "csle_agents.agents.dqn.dqn_agent.DQNAgent.hparam_names"]], "train() (csle_agents.agents.dqn.dqn_agent.dqnagent method)": [[6, "csle_agents.agents.dqn.dqn_agent.DQNAgent.train"]], "datacollectorprocess (class in csle_agents.agents.dynasec.dynasec_agent)": [[7, "csle_agents.agents.dynasec.dynasec_agent.DataCollectorProcess"]], "dynasecagent (class in csle_agents.agents.dynasec.dynasec_agent)": [[7, "csle_agents.agents.dynasec.dynasec_agent.DynaSecAgent"]], "emulationmonitorthread (class in csle_agents.agents.dynasec.dynasec_agent)": [[7, "csle_agents.agents.dynasec.dynasec_agent.EmulationMonitorThread"]], "emulationstatisticsthread (class in csle_agents.agents.dynasec.dynasec_agent)": [[7, "csle_agents.agents.dynasec.dynasec_agent.EmulationStatisticsThread"]], "policyevaluationthread (class in csle_agents.agents.dynasec.dynasec_agent)": [[7, "csle_agents.agents.dynasec.dynasec_agent.PolicyEvaluationThread"]], "policyoptimizationprocess (class in csle_agents.agents.dynasec.dynasec_agent)": [[7, "csle_agents.agents.dynasec.dynasec_agent.PolicyOptimizationProcess"]], "systemidentificationprocess (class in csle_agents.agents.dynasec.dynasec_agent)": [[7, "csle_agents.agents.dynasec.dynasec_agent.SystemIdentificationProcess"]], "csle_agents.agents.dynasec": [[7, "module-csle_agents.agents.dynasec"]], "csle_agents.agents.dynasec.dynasec_agent": [[7, "module-csle_agents.agents.dynasec.dynasec_agent"]], "eval_traces() (csle_agents.agents.dynasec.dynasec_agent.policyevaluationthread method)": [[7, "csle_agents.agents.dynasec.dynasec_agent.PolicyEvaluationThread.eval_traces"]], "get_z_from_system_model() (csle_agents.agents.dynasec.dynasec_agent.dynasecagent static method)": [[7, "csle_agents.agents.dynasec.dynasec_agent.DynaSecAgent.get_Z_from_system_model"]], "get_spsa_experiment_config() (csle_agents.agents.dynasec.dynasec_agent.dynasecagent method)": [[7, "csle_agents.agents.dynasec.dynasec_agent.DynaSecAgent.get_spsa_experiment_config"]], "hparam_names() (csle_agents.agents.dynasec.dynasec_agent.dynasecagent method)": [[7, "csle_agents.agents.dynasec.dynasec_agent.DynaSecAgent.hparam_names"]], "mean() (csle_agents.agents.dynasec.dynasec_agent.dynasecagent static method)": [[7, "csle_agents.agents.dynasec.dynasec_agent.DynaSecAgent.mean"]], "record_metrics() (csle_agents.agents.dynasec.dynasec_agent.dynasecagent method)": [[7, "csle_agents.agents.dynasec.dynasec_agent.DynaSecAgent.record_metrics"]], "record_metrics() (csle_agents.agents.dynasec.dynasec_agent.policyevaluationthread method)": [[7, "csle_agents.agents.dynasec.dynasec_agent.PolicyEvaluationThread.record_metrics"]], "run() (csle_agents.agents.dynasec.dynasec_agent.datacollectorprocess method)": [[7, "csle_agents.agents.dynasec.dynasec_agent.DataCollectorProcess.run"]], "run() (csle_agents.agents.dynasec.dynasec_agent.emulationmonitorthread method)": [[7, "csle_agents.agents.dynasec.dynasec_agent.EmulationMonitorThread.run"]], "run() (csle_agents.agents.dynasec.dynasec_agent.emulationstatisticsthread method)": [[7, "csle_agents.agents.dynasec.dynasec_agent.EmulationStatisticsThread.run"]], "run() (csle_agents.agents.dynasec.dynasec_agent.policyevaluationthread method)": [[7, "csle_agents.agents.dynasec.dynasec_agent.PolicyEvaluationThread.run"]], "run() (csle_agents.agents.dynasec.dynasec_agent.policyoptimizationprocess method)": [[7, "csle_agents.agents.dynasec.dynasec_agent.PolicyOptimizationProcess.run"]], "run() (csle_agents.agents.dynasec.dynasec_agent.systemidentificationprocess method)": [[7, "csle_agents.agents.dynasec.dynasec_agent.SystemIdentificationProcess.run"]], "train() (csle_agents.agents.dynasec.dynasec_agent.dynasecagent method)": [[7, "csle_agents.agents.dynasec.dynasec_agent.DynaSecAgent.train"]], "fictitiousplayagent (class in csle_agents.agents.fp.fictitious_play_agent)": [[8, "csle_agents.agents.fp.fictitious_play_agent.FictitiousPlayAgent"]], "best_response() (csle_agents.agents.fp.fictitious_play_agent.fictitiousplayagent method)": [[8, "csle_agents.agents.fp.fictitious_play_agent.FictitiousPlayAgent.best_response"]], "compute_avg_metrics() (csle_agents.agents.fp.fictitious_play_agent.fictitiousplayagent static method)": [[8, "csle_agents.agents.fp.fictitious_play_agent.FictitiousPlayAgent.compute_avg_metrics"]], "compute_empirical_strategy() (csle_agents.agents.fp.fictitious_play_agent.fictitiousplayagent method)": [[8, "csle_agents.agents.fp.fictitious_play_agent.FictitiousPlayAgent.compute_empirical_strategy"]], "csle_agents.agents.fp": [[8, "module-csle_agents.agents.fp"]], "csle_agents.agents.fp.fictitious_play_agent": [[8, "module-csle_agents.agents.fp.fictitious_play_agent"]], "fictitious_play() (csle_agents.agents.fp.fictitious_play_agent.fictitiousplayagent method)": [[8, "csle_agents.agents.fp.fictitious_play_agent.FictitiousPlayAgent.fictitious_play"]], "hparam_names() (csle_agents.agents.fp.fictitious_play_agent.fictitiousplayagent method)": [[8, "csle_agents.agents.fp.fictitious_play_agent.FictitiousPlayAgent.hparam_names"]], "round_vec() (csle_agents.agents.fp.fictitious_play_agent.fictitiousplayagent static method)": [[8, "csle_agents.agents.fp.fictitious_play_agent.FictitiousPlayAgent.round_vec"]], "train() (csle_agents.agents.fp.fictitious_play_agent.fictitiousplayagent method)": [[8, "csle_agents.agents.fp.fictitious_play_agent.FictitiousPlayAgent.train"]], "update_metrics() (csle_agents.agents.fp.fictitious_play_agent.fictitiousplayagent static method)": [[8, "csle_agents.agents.fp.fictitious_play_agent.FictitiousPlayAgent.update_metrics"]], "hsviagent (class in csle_agents.agents.hsvi.hsvi_agent)": [[9, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent"]], "approximate_projection_sawtooth() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[9, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.approximate_projection_sawtooth"]], "bayes_filter() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[9, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.bayes_filter"]], "csle_agents.agents.hsvi": [[9, "module-csle_agents.agents.hsvi"]], "csle_agents.agents.hsvi.hsvi_agent": [[9, "module-csle_agents.agents.hsvi.hsvi_agent"]], "excess() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[9, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.excess"]], "explore() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[9, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.explore"]], "generate_corner_belief() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[9, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.generate_corner_belief"]], "hparam_names() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[9, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.hparam_names"]], "hsvi() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[9, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.hsvi"]], "hsvi_algorithm() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[9, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.hsvi_algorithm"]], "initialize_lower_bound() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[9, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.initialize_lower_bound"]], "initialize_upper_bound() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[9, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.initialize_upper_bound"]], "interior_point_belief_val() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[9, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.interior_point_belief_val"]], "local_lower_bound_update() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[9, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.local_lower_bound_update"]], "local_updates() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[9, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.local_updates"]], "local_upper_bound_update() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[9, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.local_upper_bound_update"]], "lower_bound_backup() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[9, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.lower_bound_backup"]], "lower_bound_value() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[9, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.lower_bound_value"]], "lp_convex_hull_projection_lp() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[9, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.lp_convex_hull_projection_lp"]], "next_belief() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[9, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.next_belief"]], "observation_possible() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[9, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.observation_possible"]], "one_step_lookahead() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[9, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.one_step_lookahead"]], "p_o_given_b_a() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[9, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.p_o_given_b_a"]], "prune_upper_bound() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[9, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.prune_upper_bound"]], "q() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[9, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.q"]], "q_hat_interval() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[9, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.q_hat_interval"]], "simulate() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[9, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.simulate"]], "train() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[9, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.train"]], "update_corner_points() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[9, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.update_corner_points"]], "upper_bound_backup() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[9, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.upper_bound_backup"]], "upper_bound_value() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[9, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.upper_bound_value"]], "vi() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[9, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.vi"]], "width() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[9, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.width"]], "hsviosposgagent (class in csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent"]], "auxillary_game() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.auxillary_game"]], "bayes_filter() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.bayes_filter"]], "choose_a_o_for_exploration() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.choose_a_o_for_exploration"]], "combine_weights_and_pure_strategies_into_mixed_strategy() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.combine_weights_and_pure_strategies_into_mixed_strategy"]], "compute_delta() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.compute_delta"]], "compute_equilibrium_strategies_in_matrix_game() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.compute_equilibrium_strategies_in_matrix_game"]], "compute_matrix_game_value() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.compute_matrix_game_value"]], "csle_agents.agents.hsvi_os_posg": [[10, "module-csle_agents.agents.hsvi_os_posg"]], "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent": [[10, "module-csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent"]], "delta_lipschitz_envelope_of_upper_bound_value() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.delta_lipschitz_envelope_of_upper_bound_value"]], "excess() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.excess"]], "explore() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.explore"]], "generate_corner_belief() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.generate_corner_belief"]], "hparam_names() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.hparam_names"]], "hsvi() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.hsvi"]], "hsvi_os_posg() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.hsvi_os_posg"]], "initialize_lower_bound() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.initialize_lower_bound"]], "initialize_upper_bound() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.initialize_upper_bound"]], "local_lower_bound_update() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.local_lower_bound_update"]], "local_updates() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.local_updates"]], "local_upper_bound_update() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.local_upper_bound_update"]], "lower_bound_backup() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.lower_bound_backup"]], "lower_bound_value() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.lower_bound_value"]], "maxcomp_shapley_bellman_operator() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.maxcomp_shapley_bellman_operator"]], "mdp_reward_matrix_p2() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.mdp_reward_matrix_p2"]], "mdp_transition_tensor_p2() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.mdp_transition_tensor_p2"]], "next_belief() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.next_belief"]], "obtain_equilibrium_strategy_profiles_in_stage_game() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.obtain_equilibrium_strategy_profiles_in_stage_game"]], "one_step_lookahead() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.one_step_lookahead"]], "p_o_given_b_a1_a2() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.p_o_given_b_a1_a2"]], "p_o_given_b_pi_1_pi_2() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.p_o_given_b_pi_1_pi_2"]], "prune_upper_bound() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.prune_upper_bound"]], "rho() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.rho"]], "sample_d() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.sample_D"]], "si() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.si"]], "train() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.train"]], "upper_bound_backup() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.upper_bound_backup"]], "upper_bound_value() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.upper_bound_value"]], "valcomp() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.valcomp"]], "value_of_p1_strategy_static() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.value_of_p1_strategy_static"]], "vi() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.vi"]], "weighted_excess_gap() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.weighted_excess_gap"]], "width() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[10, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.width"]], "kieferwolfowitzagent (class in csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent)": [[11, "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.KieferWolfowitzAgent"]], "batch_gradient() (csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.kieferwolfowitzagent method)": [[11, "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.KieferWolfowitzAgent.batch_gradient"]], "compute_avg_metrics() (csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.kieferwolfowitzagent static method)": [[11, "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.KieferWolfowitzAgent.compute_avg_metrics"]], "csle_agents.agents.kiefer_wolfowitz": [[11, "module-csle_agents.agents.kiefer_wolfowitz"]], "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent": [[11, "module-csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent"]], "estimate_gk() (csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.kieferwolfowitzagent method)": [[11, "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.KieferWolfowitzAgent.estimate_gk"]], "eval_theta() (csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.kieferwolfowitzagent method)": [[11, "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.KieferWolfowitzAgent.eval_theta"]], "hparam_names() (csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.kieferwolfowitzagent method)": [[11, "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.KieferWolfowitzAgent.hparam_names"]], "initial_theta() (csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.kieferwolfowitzagent static method)": [[11, "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.KieferWolfowitzAgent.initial_theta"]], "kiefer_wolfowitz() (csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.kieferwolfowitzagent method)": [[11, "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.KieferWolfowitzAgent.kiefer_wolfowitz"]], "round_vec() (csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.kieferwolfowitzagent static method)": [[11, "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.KieferWolfowitzAgent.round_vec"]], "train() (csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.kieferwolfowitzagent method)": [[11, "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.KieferWolfowitzAgent.train"]], "update_metrics() (csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.kieferwolfowitzagent static method)": [[11, "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.KieferWolfowitzAgent.update_metrics"]], "linearprogrammingnormalformgameagent (class in csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent)": [[12, "csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.LinearProgrammingNormalFormGameAgent"]], "compute_avg_metrics() (csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.linearprogrammingnormalformgameagent static method)": [[12, "csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.LinearProgrammingNormalFormGameAgent.compute_avg_metrics"]], "compute_equilibrium_strategies_in_matrix_game() (csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.linearprogrammingnormalformgameagent method)": [[12, "csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.LinearProgrammingNormalFormGameAgent.compute_equilibrium_strategies_in_matrix_game"]], "compute_matrix_game_value() (csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.linearprogrammingnormalformgameagent method)": [[12, "csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.LinearProgrammingNormalFormGameAgent.compute_matrix_game_value"]], "csle_agents.agents.lp_nf": [[12, "module-csle_agents.agents.lp_nf"]], "csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent": [[12, "module-csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent"]], "hparam_names() (csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.linearprogrammingnormalformgameagent method)": [[12, "csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.LinearProgrammingNormalFormGameAgent.hparam_names"]], "linear_programming_normal_form() (csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.linearprogrammingnormalformgameagent method)": [[12, "csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.LinearProgrammingNormalFormGameAgent.linear_programming_normal_form"]], "round_vec() (csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.linearprogrammingnormalformgameagent static method)": [[12, "csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.LinearProgrammingNormalFormGameAgent.round_vec"]], "train() (csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.linearprogrammingnormalformgameagent method)": [[12, "csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.LinearProgrammingNormalFormGameAgent.train"]], "update_metrics() (csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.linearprogrammingnormalformgameagent static method)": [[12, "csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.LinearProgrammingNormalFormGameAgent.update_metrics"]], "piagent (class in csle_agents.agents.pi.pi_agent)": [[13, "csle_agents.agents.pi.pi_agent.PIAgent"]], "csle_agents.agents.pi": [[13, "module-csle_agents.agents.pi"]], "csle_agents.agents.pi.pi_agent": [[13, "module-csle_agents.agents.pi.pi_agent"]], "evaluate_policy() (csle_agents.agents.pi.pi_agent.piagent method)": [[13, "csle_agents.agents.pi.pi_agent.PIAgent.evaluate_policy"]], "expected_reward_under_policy() (csle_agents.agents.pi.pi_agent.piagent method)": [[13, "csle_agents.agents.pi.pi_agent.PIAgent.expected_reward_under_policy"]], "hparam_names() (csle_agents.agents.pi.pi_agent.piagent method)": [[13, "csle_agents.agents.pi.pi_agent.PIAgent.hparam_names"]], "pi() (csle_agents.agents.pi.pi_agent.piagent method)": [[13, "csle_agents.agents.pi.pi_agent.PIAgent.pi"]], "policy_evaluation() (csle_agents.agents.pi.pi_agent.piagent method)": [[13, "csle_agents.agents.pi.pi_agent.PIAgent.policy_evaluation"]], "policy_improvement() (csle_agents.agents.pi.pi_agent.piagent method)": [[13, "csle_agents.agents.pi.pi_agent.PIAgent.policy_improvement"]], "policy_iteration() (csle_agents.agents.pi.pi_agent.piagent method)": [[13, "csle_agents.agents.pi.pi_agent.PIAgent.policy_iteration"]], "train() (csle_agents.agents.pi.pi_agent.piagent method)": [[13, "csle_agents.agents.pi.pi_agent.PIAgent.train"]], "transition_probability_under_policy() (csle_agents.agents.pi.pi_agent.piagent method)": [[13, "csle_agents.agents.pi.pi_agent.PIAgent.transition_probability_under_policy"]], "ppoagent (class in csle_agents.agents.ppo.ppo_agent)": [[14, "csle_agents.agents.ppo.ppo_agent.PPOAgent"]], "ppotrainingcallback (class in csle_agents.agents.ppo.ppo_agent)": [[14, "csle_agents.agents.ppo.ppo_agent.PPOTrainingCallback"]], "csle_agents.agents.ppo": [[14, "module-csle_agents.agents.ppo"]], "csle_agents.agents.ppo.ppo_agent": [[14, "module-csle_agents.agents.ppo.ppo_agent"]], "hparam_names() (csle_agents.agents.ppo.ppo_agent.ppoagent method)": [[14, "csle_agents.agents.ppo.ppo_agent.PPOAgent.hparam_names"]], "train() (csle_agents.agents.ppo.ppo_agent.ppoagent method)": [[14, "csle_agents.agents.ppo.ppo_agent.PPOAgent.train"]], "qlearningagent (class in csle_agents.agents.q_learning.q_learning_agent)": [[15, "csle_agents.agents.q_learning.q_learning_agent.QLearningAgent"]], "create_policy_from_q_table() (csle_agents.agents.q_learning.q_learning_agent.qlearningagent method)": [[15, "csle_agents.agents.q_learning.q_learning_agent.QLearningAgent.create_policy_from_q_table"]], "csle_agents.agents.q_learning": [[15, "module-csle_agents.agents.q_learning"]], "csle_agents.agents.q_learning.q_learning_agent": [[15, "module-csle_agents.agents.q_learning.q_learning_agent"]], "eps_greedy() (csle_agents.agents.q_learning.q_learning_agent.qlearningagent method)": [[15, "csle_agents.agents.q_learning.q_learning_agent.QLearningAgent.eps_greedy"]], "evaluate_policy() (csle_agents.agents.q_learning.q_learning_agent.qlearningagent method)": [[15, "csle_agents.agents.q_learning.q_learning_agent.QLearningAgent.evaluate_policy"]], "hparam_names() (csle_agents.agents.q_learning.q_learning_agent.qlearningagent method)": [[15, "csle_agents.agents.q_learning.q_learning_agent.QLearningAgent.hparam_names"]], "initialize_count_table() (csle_agents.agents.q_learning.q_learning_agent.qlearningagent method)": [[15, "csle_agents.agents.q_learning.q_learning_agent.QLearningAgent.initialize_count_table"]], "initialize_q_table() (csle_agents.agents.q_learning.q_learning_agent.qlearningagent method)": [[15, "csle_agents.agents.q_learning.q_learning_agent.QLearningAgent.initialize_q_table"]], "q_learning() (csle_agents.agents.q_learning.q_learning_agent.qlearningagent method)": [[15, "csle_agents.agents.q_learning.q_learning_agent.QLearningAgent.q_learning"]], "q_learning_update() (csle_agents.agents.q_learning.q_learning_agent.qlearningagent method)": [[15, "csle_agents.agents.q_learning.q_learning_agent.QLearningAgent.q_learning_update"]], "step_size() (csle_agents.agents.q_learning.q_learning_agent.qlearningagent method)": [[15, "csle_agents.agents.q_learning.q_learning_agent.QLearningAgent.step_size"]], "train() (csle_agents.agents.q_learning.q_learning_agent.qlearningagent method)": [[15, "csle_agents.agents.q_learning.q_learning_agent.QLearningAgent.train"]], "train_q_learning() (csle_agents.agents.q_learning.q_learning_agent.qlearningagent method)": [[15, "csle_agents.agents.q_learning.q_learning_agent.QLearningAgent.train_q_learning"]], "randomsearchagent (class in csle_agents.agents.random_search.random_search_agent)": [[16, "csle_agents.agents.random_search.random_search_agent.RandomSearchAgent"]], "compute_avg_metrics() (csle_agents.agents.random_search.random_search_agent.randomsearchagent static method)": [[16, "csle_agents.agents.random_search.random_search_agent.RandomSearchAgent.compute_avg_metrics"]], "csle_agents.agents.random_search": [[16, "module-csle_agents.agents.random_search"]], "csle_agents.agents.random_search.random_search_agent": [[16, "module-csle_agents.agents.random_search.random_search_agent"]], "eval_theta() (csle_agents.agents.random_search.random_search_agent.randomsearchagent method)": [[16, "csle_agents.agents.random_search.random_search_agent.RandomSearchAgent.eval_theta"]], "hparam_names() (csle_agents.agents.random_search.random_search_agent.randomsearchagent method)": [[16, "csle_agents.agents.random_search.random_search_agent.RandomSearchAgent.hparam_names"]], "initial_theta() (csle_agents.agents.random_search.random_search_agent.randomsearchagent static method)": [[16, "csle_agents.agents.random_search.random_search_agent.RandomSearchAgent.initial_theta"]], "random_perturbation() (csle_agents.agents.random_search.random_search_agent.randomsearchagent method)": [[16, "csle_agents.agents.random_search.random_search_agent.RandomSearchAgent.random_perturbation"]], "random_search() (csle_agents.agents.random_search.random_search_agent.randomsearchagent method)": [[16, "csle_agents.agents.random_search.random_search_agent.RandomSearchAgent.random_search"]], "round_vec() (csle_agents.agents.random_search.random_search_agent.randomsearchagent static method)": [[16, "csle_agents.agents.random_search.random_search_agent.RandomSearchAgent.round_vec"]], "train() (csle_agents.agents.random_search.random_search_agent.randomsearchagent method)": [[16, "csle_agents.agents.random_search.random_search_agent.RandomSearchAgent.train"]], "update_metrics() (csle_agents.agents.random_search.random_search_agent.randomsearchagent static method)": [[16, "csle_agents.agents.random_search.random_search_agent.RandomSearchAgent.update_metrics"]], "reinforceagent (class in csle_agents.agents.reinforce.reinforce_agent)": [[17, "csle_agents.agents.reinforce.reinforce_agent.ReinforceAgent"]], "compute_avg_metrics() (csle_agents.agents.reinforce.reinforce_agent.reinforceagent static method)": [[17, "csle_agents.agents.reinforce.reinforce_agent.ReinforceAgent.compute_avg_metrics"]], "csle_agents.agents.reinforce": [[17, "module-csle_agents.agents.reinforce"]], "csle_agents.agents.reinforce.reinforce_agent": [[17, "module-csle_agents.agents.reinforce.reinforce_agent"]], "hparam_names() (csle_agents.agents.reinforce.reinforce_agent.reinforceagent method)": [[17, "csle_agents.agents.reinforce.reinforce_agent.ReinforceAgent.hparam_names"]], "reinforce() (csle_agents.agents.reinforce.reinforce_agent.reinforceagent method)": [[17, "csle_agents.agents.reinforce.reinforce_agent.ReinforceAgent.reinforce"]], "round_vec() (csle_agents.agents.reinforce.reinforce_agent.reinforceagent static method)": [[17, "csle_agents.agents.reinforce.reinforce_agent.ReinforceAgent.round_vec"]], "train() (csle_agents.agents.reinforce.reinforce_agent.reinforceagent method)": [[17, "csle_agents.agents.reinforce.reinforce_agent.ReinforceAgent.train"]], "training_step() (csle_agents.agents.reinforce.reinforce_agent.reinforceagent method)": [[17, "csle_agents.agents.reinforce.reinforce_agent.ReinforceAgent.training_step"]], "update_metrics() (csle_agents.agents.reinforce.reinforce_agent.reinforceagent static method)": [[17, "csle_agents.agents.reinforce.reinforce_agent.ReinforceAgent.update_metrics"]], "sarsaagent (class in csle_agents.agents.sarsa.sarsa_agent)": [[18, "csle_agents.agents.sarsa.sarsa_agent.SARSAAgent"]], "create_policy_from_q_table() (csle_agents.agents.sarsa.sarsa_agent.sarsaagent method)": [[18, "csle_agents.agents.sarsa.sarsa_agent.SARSAAgent.create_policy_from_q_table"]], "csle_agents.agents.sarsa": [[18, "module-csle_agents.agents.sarsa"]], "csle_agents.agents.sarsa.sarsa_agent": [[18, "module-csle_agents.agents.sarsa.sarsa_agent"]], "eps_greedy() (csle_agents.agents.sarsa.sarsa_agent.sarsaagent method)": [[18, "csle_agents.agents.sarsa.sarsa_agent.SARSAAgent.eps_greedy"]], "evaluate_policy() (csle_agents.agents.sarsa.sarsa_agent.sarsaagent method)": [[18, "csle_agents.agents.sarsa.sarsa_agent.SARSAAgent.evaluate_policy"]], "hparam_names() (csle_agents.agents.sarsa.sarsa_agent.sarsaagent method)": [[18, "csle_agents.agents.sarsa.sarsa_agent.SARSAAgent.hparam_names"]], "initialize_count_table() (csle_agents.agents.sarsa.sarsa_agent.sarsaagent method)": [[18, "csle_agents.agents.sarsa.sarsa_agent.SARSAAgent.initialize_count_table"]], "initialize_q_table() (csle_agents.agents.sarsa.sarsa_agent.sarsaagent method)": [[18, "csle_agents.agents.sarsa.sarsa_agent.SARSAAgent.initialize_q_table"]], "q_learning() (csle_agents.agents.sarsa.sarsa_agent.sarsaagent method)": [[18, "csle_agents.agents.sarsa.sarsa_agent.SARSAAgent.q_learning"]], "sarsa_update() (csle_agents.agents.sarsa.sarsa_agent.sarsaagent method)": [[18, "csle_agents.agents.sarsa.sarsa_agent.SARSAAgent.sarsa_update"]], "step_size() (csle_agents.agents.sarsa.sarsa_agent.sarsaagent method)": [[18, "csle_agents.agents.sarsa.sarsa_agent.SARSAAgent.step_size"]], "train() (csle_agents.agents.sarsa.sarsa_agent.sarsaagent method)": [[18, "csle_agents.agents.sarsa.sarsa_agent.SARSAAgent.train"]], "train_sarsa() (csle_agents.agents.sarsa.sarsa_agent.sarsaagent method)": [[18, "csle_agents.agents.sarsa.sarsa_agent.SARSAAgent.train_sarsa"]], "shapleyiterationagent (class in csle_agents.agents.shapley_iteration.shapley_iteration_agent)": [[19, "csle_agents.agents.shapley_iteration.shapley_iteration_agent.ShapleyIterationAgent"]], "auxillary_game() (csle_agents.agents.shapley_iteration.shapley_iteration_agent.shapleyiterationagent method)": [[19, "csle_agents.agents.shapley_iteration.shapley_iteration_agent.ShapleyIterationAgent.auxillary_game"]], "compute_matrix_game_value() (csle_agents.agents.shapley_iteration.shapley_iteration_agent.shapleyiterationagent method)": [[19, "csle_agents.agents.shapley_iteration.shapley_iteration_agent.ShapleyIterationAgent.compute_matrix_game_value"]], "csle_agents.agents.shapley_iteration": [[19, "module-csle_agents.agents.shapley_iteration"]], "csle_agents.agents.shapley_iteration.shapley_iteration_agent": [[19, "module-csle_agents.agents.shapley_iteration.shapley_iteration_agent"]], "hparam_names() (csle_agents.agents.shapley_iteration.shapley_iteration_agent.shapleyiterationagent method)": [[19, "csle_agents.agents.shapley_iteration.shapley_iteration_agent.ShapleyIterationAgent.hparam_names"]], "shapley_iteration() (csle_agents.agents.shapley_iteration.shapley_iteration_agent.shapleyiterationagent method)": [[19, "csle_agents.agents.shapley_iteration.shapley_iteration_agent.ShapleyIterationAgent.shapley_iteration"]], "si() (csle_agents.agents.shapley_iteration.shapley_iteration_agent.shapleyiterationagent method)": [[19, "csle_agents.agents.shapley_iteration.shapley_iteration_agent.ShapleyIterationAgent.si"]], "train() (csle_agents.agents.shapley_iteration.shapley_iteration_agent.shapleyiterationagent method)": [[19, "csle_agents.agents.shapley_iteration.shapley_iteration_agent.ShapleyIterationAgent.train"]], "sondikviagent (class in csle_agents.agents.sondik_vi.sondik_vi_agent)": [[20, "csle_agents.agents.sondik_vi.sondik_vi_agent.SondikVIAgent"]], "check_duplicate() (csle_agents.agents.sondik_vi.sondik_vi_agent.sondikviagent method)": [[20, "csle_agents.agents.sondik_vi.sondik_vi_agent.SondikVIAgent.check_duplicate"]], "compute_all_conditional_plans_conditioned_on_a_t() (csle_agents.agents.sondik_vi.sondik_vi_agent.sondikviagent method)": [[20, "csle_agents.agents.sondik_vi.sondik_vi_agent.SondikVIAgent.compute_all_conditional_plans_conditioned_on_a_t"]], "csle_agents.agents.sondik_vi": [[20, "module-csle_agents.agents.sondik_vi"]], "csle_agents.agents.sondik_vi.sondik_vi_agent": [[20, "module-csle_agents.agents.sondik_vi.sondik_vi_agent"]], "evaluate_policy() (csle_agents.agents.sondik_vi.sondik_vi_agent.sondikviagent method)": [[20, "csle_agents.agents.sondik_vi.sondik_vi_agent.SondikVIAgent.evaluate_policy"]], "hparam_names() (csle_agents.agents.sondik_vi.sondik_vi_agent.sondikviagent method)": [[20, "csle_agents.agents.sondik_vi.sondik_vi_agent.SondikVIAgent.hparam_names"]], "prune() (csle_agents.agents.sondik_vi.sondik_vi_agent.sondikviagent method)": [[20, "csle_agents.agents.sondik_vi.sondik_vi_agent.SondikVIAgent.prune"]], "sondik_vi() (csle_agents.agents.sondik_vi.sondik_vi_agent.sondikviagent method)": [[20, "csle_agents.agents.sondik_vi.sondik_vi_agent.SondikVIAgent.sondik_vi"]], "sondik_vi_algorithm() (csle_agents.agents.sondik_vi.sondik_vi_agent.sondikviagent method)": [[20, "csle_agents.agents.sondik_vi.sondik_vi_agent.SondikVIAgent.sondik_vi_algorithm"]], "train() (csle_agents.agents.sondik_vi.sondik_vi_agent.sondikviagent method)": [[20, "csle_agents.agents.sondik_vi.sondik_vi_agent.SondikVIAgent.train"]], "tfpagent (class in csle_agents.agents.t_fp.t_fp_agent)": [[21, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent"]], "attacker_best_response() (csle_agents.agents.t_fp.t_fp_agent.tfpagent method)": [[21, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.attacker_best_response"]], "compute_avg_metrics() (csle_agents.agents.t_fp.t_fp_agent.tfpagent static method)": [[21, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.compute_avg_metrics"]], "csle_agents.agents.t_fp": [[21, "module-csle_agents.agents.t_fp"]], "csle_agents.agents.t_fp.t_fp_agent": [[21, "module-csle_agents.agents.t_fp.t_fp_agent"]], "defender_best_response() (csle_agents.agents.t_fp.t_fp_agent.tfpagent method)": [[21, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.defender_best_response"]], "evaluate_attacker_policy() (csle_agents.agents.t_fp.t_fp_agent.tfpagent method)": [[21, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.evaluate_attacker_policy"]], "evaluate_defender_policy() (csle_agents.agents.t_fp.t_fp_agent.tfpagent method)": [[21, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.evaluate_defender_policy"]], "evaluate_strategy_profile() (csle_agents.agents.t_fp.t_fp_agent.tfpagent method)": [[21, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.evaluate_strategy_profile"]], "exploitability() (csle_agents.agents.t_fp.t_fp_agent.tfpagent static method)": [[21, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.exploitability"]], "get_attacker_experiment_config() (csle_agents.agents.t_fp.t_fp_agent.tfpagent method)": [[21, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.get_attacker_experiment_config"]], "get_defender_experiment_config() (csle_agents.agents.t_fp.t_fp_agent.tfpagent method)": [[21, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.get_defender_experiment_config"]], "hparam_names() (csle_agents.agents.t_fp.t_fp_agent.tfpagent method)": [[21, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.hparam_names"]], "round_vec() (csle_agents.agents.t_fp.t_fp_agent.tfpagent static method)": [[21, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.round_vec"]], "running_average() (csle_agents.agents.t_fp.t_fp_agent.tfpagent static method)": [[21, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.running_average"]], "t_fp() (csle_agents.agents.t_fp.t_fp_agent.tfpagent method)": [[21, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.t_fp"]], "train() (csle_agents.agents.t_fp.t_fp_agent.tfpagent method)": [[21, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.train"]], "update_metrics() (csle_agents.agents.t_fp.t_fp_agent.tfpagent static method)": [[21, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.update_metrics"]], "tspsaagent (class in csle_agents.agents.t_spsa.t_spsa_agent)": [[22, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent"]], "batch_gradient() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent method)": [[22, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.batch_gradient"]], "compute_avg_metrics() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent static method)": [[22, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.compute_avg_metrics"]], "csle_agents.agents.t_spsa": [[22, "module-csle_agents.agents.t_spsa"]], "csle_agents.agents.t_spsa.t_spsa_agent": [[22, "module-csle_agents.agents.t_spsa.t_spsa_agent"]], "estimate_gk() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent method)": [[22, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.estimate_gk"]], "eval_theta() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent method)": [[22, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.eval_theta"]], "hparam_names() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent method)": [[22, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.hparam_names"]], "initial_theta() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent static method)": [[22, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.initial_theta"]], "round_vec() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent static method)": [[22, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.round_vec"]], "spsa() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent method)": [[22, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.spsa"]], "standard_ak() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent static method)": [[22, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.standard_ak"]], "standard_ck() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent static method)": [[22, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.standard_ck"]], "standard_deltak() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent static method)": [[22, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.standard_deltak"]], "train() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent method)": [[22, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.train"]], "update_metrics() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent static method)": [[22, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.update_metrics"]], "viagent (class in csle_agents.agents.vi.vi_agent)": [[23, "csle_agents.agents.vi.vi_agent.VIAgent"]], "create_policy_from_value_function() (csle_agents.agents.vi.vi_agent.viagent method)": [[23, "csle_agents.agents.vi.vi_agent.VIAgent.create_policy_from_value_function"]], "csle_agents.agents.vi": [[23, "module-csle_agents.agents.vi"]], "csle_agents.agents.vi.vi_agent": [[23, "module-csle_agents.agents.vi.vi_agent"]], "evaluate_policy() (csle_agents.agents.vi.vi_agent.viagent method)": [[23, "csle_agents.agents.vi.vi_agent.VIAgent.evaluate_policy"]], "hparam_names() (csle_agents.agents.vi.vi_agent.viagent method)": [[23, "csle_agents.agents.vi.vi_agent.VIAgent.hparam_names"]], "one_step_lookahead() (csle_agents.agents.vi.vi_agent.viagent method)": [[23, "csle_agents.agents.vi.vi_agent.VIAgent.one_step_lookahead"]], "train() (csle_agents.agents.vi.vi_agent.viagent method)": [[23, "csle_agents.agents.vi.vi_agent.VIAgent.train"]], "value_iteration() (csle_agents.agents.vi.vi_agent.viagent method)": [[23, "csle_agents.agents.vi.vi_agent.VIAgent.value_iteration"]], "vi() (csle_agents.agents.vi.vi_agent.viagent method)": [[23, "csle_agents.agents.vi.vi_agent.VIAgent.vi"]], "fnnwithgaussian (class in csle_agents.common.fnn_w_gaussian)": [[24, "csle_agents.common.fnn_w_gaussian.FNNwithGaussian"]], "fnnwithlinear (class in csle_agents.common.fnn_w_linear)": [[24, "csle_agents.common.fnn_w_linear.FNNwithLinear"]], "check_dominance_lp() (in module csle_agents.common.pruning)": [[24, "csle_agents.common.pruning.check_dominance_lp"]], "check_duplicate() (in module csle_agents.common.pruning)": [[24, "csle_agents.common.pruning.check_duplicate"]], "csle_agents.common": [[24, "module-csle_agents.common"]], "csle_agents.common.fnn_w_gaussian": [[24, "module-csle_agents.common.fnn_w_gaussian"]], "csle_agents.common.fnn_w_linear": [[24, "module-csle_agents.common.fnn_w_linear"]], "csle_agents.common.pruning": [[24, "module-csle_agents.common.pruning"]], "forward() (csle_agents.common.fnn_w_gaussian.fnnwithgaussian method)": [[24, "csle_agents.common.fnn_w_gaussian.FNNwithGaussian.forward"]], "forward() (csle_agents.common.fnn_w_linear.fnnwithlinear method)": [[24, "csle_agents.common.fnn_w_linear.FNNwithLinear.forward"]], "get_hidden_activation() (csle_agents.common.fnn_w_gaussian.fnnwithgaussian method)": [[24, "csle_agents.common.fnn_w_gaussian.FNNwithGaussian.get_hidden_activation"]], "get_hidden_activation() (csle_agents.common.fnn_w_linear.fnnwithlinear method)": [[24, "csle_agents.common.fnn_w_linear.FNNwithLinear.get_hidden_activation"]], "prune_lower_bound() (in module csle_agents.common.pruning)": [[24, "csle_agents.common.pruning.prune_lower_bound"]], "test() (in module csle_agents.common.fnn_w_gaussian)": [[24, "csle_agents.common.fnn_w_gaussian.test"]], "test() (in module csle_agents.common.fnn_w_linear)": [[24, "csle_agents.common.fnn_w_linear.test"]], "training (csle_agents.common.fnn_w_gaussian.fnnwithgaussian attribute)": [[24, "csle_agents.common.fnn_w_gaussian.FNNwithGaussian.training"]], "training (csle_agents.common.fnn_w_linear.fnnwithlinear attribute)": [[24, "csle_agents.common.fnn_w_linear.FNNwithLinear.training"]], "a (csle_agents.constants.constants.q_learning attribute)": [[25, "csle_agents.constants.constants.Q_LEARNING.A"]], "a (csle_agents.constants.constants.sarsa attribute)": [[25, "csle_agents.constants.constants.SARSA.A"]], "action_space (csle_agents.constants.constants.hsvi attribute)": [[25, "csle_agents.constants.constants.HSVI.ACTION_SPACE"]], "action_space (csle_agents.constants.constants.sondik_vi attribute)": [[25, "csle_agents.constants.constants.SONDIK_VI.ACTION_SPACE"]], "action_space_player_1 (csle_agents.constants.constants.hsvi_os_posg attribute)": [[25, "csle_agents.constants.constants.HSVI_OS_POSG.ACTION_SPACE_PLAYER_1"]], "action_space_player_1 (csle_agents.constants.constants.lp_for_nf_games attribute)": [[25, "csle_agents.constants.constants.LP_FOR_NF_GAMES.ACTION_SPACE_PLAYER_1"]], "action_space_player_1 (csle_agents.constants.constants.shapley_iteration attribute)": [[25, "csle_agents.constants.constants.SHAPLEY_ITERATION.ACTION_SPACE_PLAYER_1"]], "action_space_player_2 (csle_agents.constants.constants.hsvi_os_posg attribute)": [[25, "csle_agents.constants.constants.HSVI_OS_POSG.ACTION_SPACE_PLAYER_2"]], "action_space_player_2 (csle_agents.constants.constants.lp_for_nf_games attribute)": [[25, "csle_agents.constants.constants.LP_FOR_NF_GAMES.ACTION_SPACE_PLAYER_2"]], "action_space_player_2 (csle_agents.constants.constants.shapley_iteration attribute)": [[25, "csle_agents.constants.constants.SHAPLEY_ITERATION.ACTION_SPACE_PLAYER_2"]], "adam (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.ADAM"]], "attacker_action (csle_agents.constants.constants.env_metrics attribute)": [[25, "csle_agents.constants.constants.ENV_METRICS.ATTACKER_ACTION"]], "attacker_thresholds (csle_agents.constants.constants.t_fp attribute)": [[25, "csle_agents.constants.constants.T_FP.ATTACKER_THRESHOLDS"]], "average_attacker_return (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.AVERAGE_ATTACKER_RETURN"]], "average_best_response_attacker_return (csle_agents.constants.constants.t_fp attribute)": [[25, "csle_agents.constants.constants.T_FP.AVERAGE_BEST_RESPONSE_ATTACKER_RETURN"]], "average_best_response_defender_return (csle_agents.constants.constants.t_fp attribute)": [[25, "csle_agents.constants.constants.T_FP.AVERAGE_BEST_RESPONSE_DEFENDER_RETURN"]], "average_defender_return (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.AVERAGE_DEFENDER_RETURN"]], "average_random_return (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.AVERAGE_RANDOM_RETURN"]], "average_random_return (csle_agents.constants.constants.env_metrics attribute)": [[25, "csle_agents.constants.constants.ENV_METRICS.AVERAGE_RANDOM_RETURN"]], "average_return (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.AVERAGE_RETURN"]], "average_time_horizon (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.AVERAGE_TIME_HORIZON"]], "average_upper_bound_return (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.AVERAGE_UPPER_BOUND_RETURN"]], "average_upper_bound_return (csle_agents.constants.constants.env_metrics attribute)": [[25, "csle_agents.constants.constants.ENV_METRICS.AVERAGE_UPPER_BOUND_RETURN"]], "baseline_prefix (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.BASELINE_PREFIX"]], "batch_size (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.BATCH_SIZE"]], "bayesian_optimization (class in csle_agents.constants.constants)": [[25, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION"]], "best_response_evaluation_iterations (csle_agents.constants.constants.t_fp attribute)": [[25, "csle_agents.constants.constants.T_FP.BEST_RESPONSE_EVALUATION_ITERATIONS"]], "bounds (csle_agents.constants.constants.differential_evolution attribute)": [[25, "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION.BOUNDS"]], "buffer_size (csle_agents.constants.constants.dqn attribute)": [[25, "csle_agents.constants.constants.DQN.BUFFER_SIZE"]], "clients_arrival_rate (csle_agents.constants.constants.dynasec attribute)": [[25, "csle_agents.constants.constants.DYNASEC.CLIENTS_ARRIVAL_RATE"]], "clip_gradient (csle_agents.constants.constants.reinforce attribute)": [[25, "csle_agents.constants.constants.REINFORCE.CLIP_GRADIENT"]], "clip_range (csle_agents.constants.constants.ppo attribute)": [[25, "csle_agents.constants.constants.PPO.CLIP_RANGE"]], "clip_range_vf (csle_agents.constants.constants.ppo attribute)": [[25, "csle_agents.constants.constants.PPO.CLIP_RANGE_VF"]], "common (class in csle_agents.constants.constants)": [[25, "csle_agents.constants.constants.COMMON"]], "confidence_interval (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.CONFIDENCE_INTERVAL"]], "cross_entropy (class in csle_agents.constants.constants)": [[25, "csle_agents.constants.constants.CROSS_ENTROPY"]], "defender_action (csle_agents.constants.constants.env_metrics attribute)": [[25, "csle_agents.constants.constants.ENV_METRICS.DEFENDER_ACTION"]], "defender_thresholds (csle_agents.constants.constants.t_fp attribute)": [[25, "csle_agents.constants.constants.T_FP.DEFENDER_THRESHOLDS"]], "delta (csle_agents.constants.constants.kiefer_wolfowitz attribute)": [[25, "csle_agents.constants.constants.KIEFER_WOLFOWITZ.DELTA"]], "delta (csle_agents.constants.constants.random_search attribute)": [[25, "csle_agents.constants.constants.RANDOM_SEARCH.DELTA"]], "delta (csle_agents.constants.constants.shapley_iteration attribute)": [[25, "csle_agents.constants.constants.SHAPLEY_ITERATION.DELTA"]], "delta (csle_agents.constants.constants.vi attribute)": [[25, "csle_agents.constants.constants.VI.DELTA"]], "differential_evolution (class in csle_agents.constants.constants)": [[25, "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION"]], "dqn (class in csle_agents.constants.constants)": [[25, "csle_agents.constants.constants.DQN"]], "dqn_batch_size (csle_agents.constants.constants.dqn attribute)": [[25, "csle_agents.constants.constants.DQN.DQN_BATCH_SIZE"]], "dynasec (class in csle_agents.constants.constants)": [[25, "csle_agents.constants.constants.DYNASEC"]], "emulation_monitor_sleep_time (csle_agents.constants.constants.dynasec attribute)": [[25, "csle_agents.constants.constants.DYNASEC.EMULATION_MONITOR_SLEEP_TIME"]], "emulation_traces_to_save_w_data_collection_job (csle_agents.constants.constants.dynasec attribute)": [[25, "csle_agents.constants.constants.DYNASEC.EMULATION_TRACES_TO_SAVE_W_DATA_COLLECTION_JOB"]], "ent_coef (csle_agents.constants.constants.ppo attribute)": [[25, "csle_agents.constants.constants.PPO.ENT_COEF"]], "env_metrics (class in csle_agents.constants.constants)": [[25, "csle_agents.constants.constants.ENV_METRICS"]], "epsilon (csle_agents.constants.constants.hsvi attribute)": [[25, "csle_agents.constants.constants.HSVI.EPSILON"]], "epsilon (csle_agents.constants.constants.hsvi_os_posg attribute)": [[25, "csle_agents.constants.constants.HSVI_OS_POSG.EPSILON"]], "epsilon (csle_agents.constants.constants.q_learning attribute)": [[25, "csle_agents.constants.constants.Q_LEARNING.EPSILON"]], "epsilon (csle_agents.constants.constants.sarsa attribute)": [[25, "csle_agents.constants.constants.SARSA.EPSILON"]], "equilibrium_strategies_evaluation_iterations (csle_agents.constants.constants.t_fp attribute)": [[25, "csle_agents.constants.constants.T_FP.EQUILIBRIUM_STRATEGIES_EVALUATION_ITERATIONS"]], "eval_batch_size (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.EVAL_BATCH_SIZE"]], "eval_every (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.EVAL_EVERY"]], "eval_prefix (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.EVAL_PREFIX"]], "excesses (csle_agents.constants.constants.hsvi_os_posg attribute)": [[25, "csle_agents.constants.constants.HSVI_OS_POSG.EXCESSES"]], "exploitability (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.EXPLOITABILITY"]], "exploration_final_eps (csle_agents.constants.constants.dqn attribute)": [[25, "csle_agents.constants.constants.DQN.EXPLORATION_FINAL_EPS"]], "exploration_fraction (csle_agents.constants.constants.dqn attribute)": [[25, "csle_agents.constants.constants.DQN.EXPLORATION_FRACTION"]], "exploration_initial_eps (csle_agents.constants.constants.dqn attribute)": [[25, "csle_agents.constants.constants.DQN.EXPLORATION_INITIAL_EPS"]], "fictitious_play (class in csle_agents.constants.constants)": [[25, "csle_agents.constants.constants.FICTITIOUS_PLAY"]], "gae_lambda (csle_agents.constants.constants.ppo attribute)": [[25, "csle_agents.constants.constants.PPO.GAE_LAMBDA"]], "gamma (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.GAMMA"]], "gradient_batch_size (csle_agents.constants.constants.kiefer_wolfowitz attribute)": [[25, "csle_agents.constants.constants.KIEFER_WOLFOWITZ.GRADIENT_BATCH_SIZE"]], "gradient_batch_size (csle_agents.constants.constants.reinforce attribute)": [[25, "csle_agents.constants.constants.REINFORCE.GRADIENT_BATCH_SIZE"]], "gradient_steps (csle_agents.constants.constants.dqn attribute)": [[25, "csle_agents.constants.constants.DQN.GRADIENT_STEPS"]], "hsvi (class in csle_agents.constants.constants)": [[25, "csle_agents.constants.constants.HSVI"]], "hsvi_os_posg (class in csle_agents.constants.constants)": [[25, "csle_agents.constants.constants.HSVI_OS_POSG"]], "initial_alpha (csle_agents.constants.constants.kiefer_wolfowitz attribute)": [[25, "csle_agents.constants.constants.KIEFER_WOLFOWITZ.INITIAL_ALPHA"]], "initial_belief (csle_agents.constants.constants.hsvi attribute)": [[25, "csle_agents.constants.constants.HSVI.INITIAL_BELIEF"]], "initial_belief (csle_agents.constants.constants.hsvi_os_posg attribute)": [[25, "csle_agents.constants.constants.HSVI_OS_POSG.INITIAL_BELIEF"]], "initial_belief (csle_agents.constants.constants.sondik_vi attribute)": [[25, "csle_agents.constants.constants.SONDIK_VI.INITIAL_BELIEF"]], "initial_belief_values (csle_agents.constants.constants.hsvi attribute)": [[25, "csle_agents.constants.constants.HSVI.INITIAL_BELIEF_VALUES"]], "initial_belief_values (csle_agents.constants.constants.sondik_vi attribute)": [[25, "csle_agents.constants.constants.SONDIK_VI.INITIAL_BELIEF_VALUES"]], "initial_policy (csle_agents.constants.constants.pi attribute)": [[25, "csle_agents.constants.constants.PI.INITIAL_POLICY"]], "initial_state_values (csle_agents.constants.constants.q_learning attribute)": [[25, "csle_agents.constants.constants.Q_LEARNING.INITIAL_STATE_VALUES"]], "initial_state_values (csle_agents.constants.constants.sarsa attribute)": [[25, "csle_agents.constants.constants.SARSA.INITIAL_STATE_VALUES"]], "intrusion_alerts_mean (csle_agents.constants.constants.dynasec attribute)": [[25, "csle_agents.constants.constants.DYNASEC.INTRUSION_ALERTS_MEAN"]], "intrusion_alerts_mean_baseline (csle_agents.constants.constants.dynasec attribute)": [[25, "csle_agents.constants.constants.DYNASEC.INTRUSION_ALERTS_MEAN_BASELINE"]], "intrusion_start_p (csle_agents.constants.constants.dynasec attribute)": [[25, "csle_agents.constants.constants.DYNASEC.INTRUSION_START_P"]], "k (csle_agents.constants.constants.cross_entropy attribute)": [[25, "csle_agents.constants.constants.CROSS_ENTROPY.K"]], "kiefer_wolfowitz (class in csle_agents.constants.constants)": [[25, "csle_agents.constants.constants.KIEFER_WOLFOWITZ"]], "l (csle_agents.constants.constants.bayesian_optimization attribute)": [[25, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.L"]], "l (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.L"]], "l (csle_agents.constants.constants.cross_entropy attribute)": [[25, "csle_agents.constants.constants.CROSS_ENTROPY.L"]], "l (csle_agents.constants.constants.differential_evolution attribute)": [[25, "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION.L"]], "l (csle_agents.constants.constants.kiefer_wolfowitz attribute)": [[25, "csle_agents.constants.constants.KIEFER_WOLFOWITZ.L"]], "l (csle_agents.constants.constants.random_search attribute)": [[25, "csle_agents.constants.constants.RANDOM_SEARCH.L"]], "lamb (csle_agents.constants.constants.cross_entropy attribute)": [[25, "csle_agents.constants.constants.CROSS_ENTROPY.LAMB"]], "lb_size (csle_agents.constants.constants.hsvi attribute)": [[25, "csle_agents.constants.constants.HSVI.LB_SIZE"]], "lb_sizes (csle_agents.constants.constants.hsvi attribute)": [[25, "csle_agents.constants.constants.HSVI.LB_SIZES"]], "learning_rate (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.LEARNING_RATE"]], "learning_rate_decay_rate (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.LEARNING_RATE_DECAY_RATE"]], "learning_rate_exp_decay (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.LEARNING_RATE_EXP_DECAY"]], "learning_starts (csle_agents.constants.constants.dqn attribute)": [[25, "csle_agents.constants.constants.DQN.LEARNING_STARTS"]], "lp_for_nf_games (class in csle_agents.constants.constants)": [[25, "csle_agents.constants.constants.LP_FOR_NF_GAMES"]], "max_env_steps (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.MAX_ENV_STEPS"]], "max_grad_norm (csle_agents.constants.constants.dqn attribute)": [[25, "csle_agents.constants.constants.DQN.MAX_GRAD_NORM"]], "max_grad_norm (csle_agents.constants.constants.ppo attribute)": [[25, "csle_agents.constants.constants.PPO.MAX_GRAD_NORM"]], "mlp_policy (csle_agents.constants.constants.dqn attribute)": [[25, "csle_agents.constants.constants.DQN.MLP_POLICY"]], "mlp_policy (csle_agents.constants.constants.ppo attribute)": [[25, "csle_agents.constants.constants.PPO.MLP_POLICY"]], "mutate (csle_agents.constants.constants.differential_evolution attribute)": [[25, "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION.MUTATE"]], "n (csle_agents.constants.constants.bayesian_optimization attribute)": [[25, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.N"]], "n (csle_agents.constants.constants.cross_entropy attribute)": [[25, "csle_agents.constants.constants.CROSS_ENTROPY.N"]], "n (csle_agents.constants.constants.differential_evolution attribute)": [[25, "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION.N"]], "n (csle_agents.constants.constants.fictitious_play attribute)": [[25, "csle_agents.constants.constants.FICTITIOUS_PLAY.N"]], "n (csle_agents.constants.constants.hsvi_os_posg attribute)": [[25, "csle_agents.constants.constants.HSVI_OS_POSG.N"]], "n (csle_agents.constants.constants.kiefer_wolfowitz attribute)": [[25, "csle_agents.constants.constants.KIEFER_WOLFOWITZ.N"]], "n (csle_agents.constants.constants.lp_for_nf_games attribute)": [[25, "csle_agents.constants.constants.LP_FOR_NF_GAMES.N"]], "n (csle_agents.constants.constants.pi attribute)": [[25, "csle_agents.constants.constants.PI.N"]], "n (csle_agents.constants.constants.q_learning attribute)": [[25, "csle_agents.constants.constants.Q_LEARNING.N"]], "n (csle_agents.constants.constants.random_search attribute)": [[25, "csle_agents.constants.constants.RANDOM_SEARCH.N"]], "n (csle_agents.constants.constants.reinforce attribute)": [[25, "csle_agents.constants.constants.REINFORCE.N"]], "n (csle_agents.constants.constants.sarsa attribute)": [[25, "csle_agents.constants.constants.SARSA.N"]], "n (csle_agents.constants.constants.shapley_iteration attribute)": [[25, "csle_agents.constants.constants.SHAPLEY_ITERATION.N"]], "no_intrusion_alerts_mean (csle_agents.constants.constants.dynasec attribute)": [[25, "csle_agents.constants.constants.DYNASEC.NO_INTRUSION_ALERTS_MEAN"]], "no_intrusion_alerts_mean_baseline (csle_agents.constants.constants.dynasec attribute)": [[25, "csle_agents.constants.constants.DYNASEC.NO_INTRUSION_ALERTS_MEAN_BASELINE"]], "number_of_simulations (csle_agents.constants.constants.hsvi attribute)": [[25, "csle_agents.constants.constants.HSVI.NUMBER_OF_SIMULATIONS"]], "num_actions (csle_agents.constants.constants.pi attribute)": [[25, "csle_agents.constants.constants.PI.NUM_ACTIONS"]], "num_actions (csle_agents.constants.constants.vi attribute)": [[25, "csle_agents.constants.constants.VI.NUM_ACTIONS"]], "num_alpha_vectors (csle_agents.constants.constants.sondik_vi attribute)": [[25, "csle_agents.constants.constants.SONDIK_VI.NUM_ALPHA_VECTORS"]], "num_cached_simulation_traces (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.NUM_CACHED_SIMULATION_TRACES"]], "num_clients (csle_agents.constants.constants.dynasec attribute)": [[25, "csle_agents.constants.constants.DYNASEC.NUM_CLIENTS"]], "num_nodes (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.NUM_NODES"]], "num_parallel_envs (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.NUM_PARALLEL_ENVS"]], "num_states (csle_agents.constants.constants.pi attribute)": [[25, "csle_agents.constants.constants.PI.NUM_STATES"]], "num_states (csle_agents.constants.constants.vi attribute)": [[25, "csle_agents.constants.constants.VI.NUM_STATES"]], "num_training_timesteps (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.NUM_TRAINING_TIMESTEPS"]], "n_2 (csle_agents.constants.constants.t_fp attribute)": [[25, "csle_agents.constants.constants.T_FP.N_2"]], "n_episodes_rollout (csle_agents.constants.constants.dqn attribute)": [[25, "csle_agents.constants.constants.DQN.N_EPISODES_ROLLOUT"]], "observation (csle_agents.constants.constants.env_metrics attribute)": [[25, "csle_agents.constants.constants.ENV_METRICS.OBSERVATION"]], "observation_function (csle_agents.constants.constants.hsvi_os_posg attribute)": [[25, "csle_agents.constants.constants.HSVI_OS_POSG.OBSERVATION_FUNCTION"]], "observation_space (csle_agents.constants.constants.hsvi attribute)": [[25, "csle_agents.constants.constants.HSVI.OBSERVATION_SPACE"]], "observation_space (csle_agents.constants.constants.hsvi_os_posg attribute)": [[25, "csle_agents.constants.constants.HSVI_OS_POSG.OBSERVATION_SPACE"]], "observation_space (csle_agents.constants.constants.sondik_vi attribute)": [[25, "csle_agents.constants.constants.SONDIK_VI.OBSERVATION_SPACE"]], "observation_tensor (csle_agents.constants.constants.hsvi attribute)": [[25, "csle_agents.constants.constants.HSVI.OBSERVATION_TENSOR"]], "observation_tensor (csle_agents.constants.constants.sondik_vi attribute)": [[25, "csle_agents.constants.constants.SONDIK_VI.OBSERVATION_TENSOR"]], "optimizer (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.OPTIMIZER"]], "parameter_bounds (csle_agents.constants.constants.bayesian_optimization attribute)": [[25, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.PARAMETER_BOUNDS"]], "params (csle_agents.constants.constants.bayesian_optimization attribute)": [[25, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.PARAMS"]], "payoff_matrix (csle_agents.constants.constants.fictitious_play attribute)": [[25, "csle_agents.constants.constants.FICTITIOUS_PLAY.PAYOFF_MATRIX"]], "payoff_matrix (csle_agents.constants.constants.lp_for_nf_games attribute)": [[25, "csle_agents.constants.constants.LP_FOR_NF_GAMES.PAYOFF_MATRIX"]], "pi (class in csle_agents.constants.constants)": [[25, "csle_agents.constants.constants.PI"]], "planning_horizon (csle_agents.constants.constants.sondik_vi attribute)": [[25, "csle_agents.constants.constants.SONDIK_VI.PLANNING_HORIZON"]], "player_1_prior (csle_agents.constants.constants.fictitious_play attribute)": [[25, "csle_agents.constants.constants.FICTITIOUS_PLAY.PLAYER_1_PRIOR"]], "player_2_prior (csle_agents.constants.constants.fictitious_play attribute)": [[25, "csle_agents.constants.constants.FICTITIOUS_PLAY.PLAYER_2_PRIOR"]], "policy_losses (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.POLICY_LOSSES"]], "population_size (csle_agents.constants.constants.differential_evolution attribute)": [[25, "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION.POPULATION_SIZE"]], "ppo (class in csle_agents.constants.constants)": [[25, "csle_agents.constants.constants.PPO"]], "prune_frequency (csle_agents.constants.constants.hsvi attribute)": [[25, "csle_agents.constants.constants.HSVI.PRUNE_FREQUENCY"]], "prune_frequency (csle_agents.constants.constants.hsvi_os_posg attribute)": [[25, "csle_agents.constants.constants.HSVI_OS_POSG.PRUNE_FREQUENCY"]], "q_learning (class in csle_agents.constants.constants)": [[25, "csle_agents.constants.constants.Q_LEARNING"]], "random_search (class in csle_agents.constants.constants)": [[25, "csle_agents.constants.constants.RANDOM_SEARCH"]], "recombination (csle_agents.constants.constants.differential_evolution attribute)": [[25, "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION.RECOMBINATION"]], "reinforce (class in csle_agents.constants.constants)": [[25, "csle_agents.constants.constants.REINFORCE"]], "replay_window_size (csle_agents.constants.constants.dynasec attribute)": [[25, "csle_agents.constants.constants.DYNASEC.REPLAY_WINDOW_SIZE"]], "return (csle_agents.constants.constants.env_metrics attribute)": [[25, "csle_agents.constants.constants.ENV_METRICS.RETURN"]], "reward_tensor (csle_agents.constants.constants.hsvi attribute)": [[25, "csle_agents.constants.constants.HSVI.REWARD_TENSOR"]], "reward_tensor (csle_agents.constants.constants.hsvi_os_posg attribute)": [[25, "csle_agents.constants.constants.HSVI_OS_POSG.REWARD_TENSOR"]], "reward_tensor (csle_agents.constants.constants.pi attribute)": [[25, "csle_agents.constants.constants.PI.REWARD_TENSOR"]], "reward_tensor (csle_agents.constants.constants.shapley_iteration attribute)": [[25, "csle_agents.constants.constants.SHAPLEY_ITERATION.REWARD_TENSOR"]], "reward_tensor (csle_agents.constants.constants.sondik_vi attribute)": [[25, "csle_agents.constants.constants.SONDIK_VI.REWARD_TENSOR"]], "reward_tensor (csle_agents.constants.constants.vi attribute)": [[25, "csle_agents.constants.constants.VI.REWARD_TENSOR"]], "running_average (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.RUNNING_AVERAGE"]], "running_average_attacker_return (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.RUNNING_AVERAGE_ATTACKER_RETURN"]], "running_average_best_response_attacker_return (csle_agents.constants.constants.t_fp attribute)": [[25, "csle_agents.constants.constants.T_FP.RUNNING_AVERAGE_BEST_RESPONSE_ATTACKER_RETURN"]], "running_average_best_response_defender_return (csle_agents.constants.constants.t_fp attribute)": [[25, "csle_agents.constants.constants.T_FP.RUNNING_AVERAGE_BEST_RESPONSE_DEFENDER_RETURN"]], "running_average_defender_return (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.RUNNING_AVERAGE_DEFENDER_RETURN"]], "running_average_exploitability (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.RUNNING_AVERAGE_EXPLOITABILITY"]], "running_average_intrusion_length (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.RUNNING_AVERAGE_INTRUSION_LENGTH"]], "running_average_intrusion_start (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.RUNNING_AVERAGE_INTRUSION_START"]], "running_average_return (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.RUNNING_AVERAGE_RETURN"]], "running_average_start_point_correct (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.RUNNING_AVERAGE_START_POINT_CORRECT"]], "running_average_time_horizon (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.RUNNING_AVERAGE_TIME_HORIZON"]], "running_average_weighted_intrusion_prediction_distance (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.RUNNING_AVERAGE_WEIGHTED_INTRUSION_PREDICTION_DISTANCE"]], "runtime (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.RUNTIME"]], "s (csle_agents.constants.constants.q_learning attribute)": [[25, "csle_agents.constants.constants.Q_LEARNING.S"]], "s (csle_agents.constants.constants.sarsa attribute)": [[25, "csle_agents.constants.constants.SARSA.S"]], "sarsa (class in csle_agents.constants.constants)": [[25, "csle_agents.constants.constants.SARSA"]], "save_every (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.SAVE_EVERY"]], "sgd (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.SGD"]], "shapley_iteration (class in csle_agents.constants.constants)": [[25, "csle_agents.constants.constants.SHAPLEY_ITERATION"]], "simulate_horizon (csle_agents.constants.constants.hsvi attribute)": [[25, "csle_agents.constants.constants.HSVI.SIMULATE_HORIZON"]], "simulation_frequency (csle_agents.constants.constants.hsvi attribute)": [[25, "csle_agents.constants.constants.HSVI.SIMULATION_FREQUENCY"]], "sleep_time (csle_agents.constants.constants.dynasec attribute)": [[25, "csle_agents.constants.constants.DYNASEC.SLEEP_TIME"]], "sondik_vi (class in csle_agents.constants.constants)": [[25, "csle_agents.constants.constants.SONDIK_VI"]], "start_point_correct (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.START_POINT_CORRECT"]], "state (csle_agents.constants.constants.env_metrics attribute)": [[25, "csle_agents.constants.constants.ENV_METRICS.STATE"]], "state_space (csle_agents.constants.constants.hsvi attribute)": [[25, "csle_agents.constants.constants.HSVI.STATE_SPACE"]], "state_space (csle_agents.constants.constants.hsvi_os_posg attribute)": [[25, "csle_agents.constants.constants.HSVI_OS_POSG.STATE_SPACE"]], "state_space (csle_agents.constants.constants.shapley_iteration attribute)": [[25, "csle_agents.constants.constants.SHAPLEY_ITERATION.STATE_SPACE"]], "state_space (csle_agents.constants.constants.sondik_vi attribute)": [[25, "csle_agents.constants.constants.SONDIK_VI.STATE_SPACE"]], "static_attacker_type (csle_agents.constants.constants.dynasec attribute)": [[25, "csle_agents.constants.constants.DYNASEC.STATIC_ATTACKER_TYPE"]], "steps_between_updates (csle_agents.constants.constants.ppo attribute)": [[25, "csle_agents.constants.constants.PPO.STEPS_BETWEEN_UPDATES"]], "stopping_envs (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.STOPPING_ENVS"]], "stop_distribution_attacker (csle_agents.constants.constants.bayesian_optimization attribute)": [[25, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.STOP_DISTRIBUTION_ATTACKER"]], "stop_distribution_attacker (csle_agents.constants.constants.cross_entropy attribute)": [[25, "csle_agents.constants.constants.CROSS_ENTROPY.STOP_DISTRIBUTION_ATTACKER"]], "stop_distribution_attacker (csle_agents.constants.constants.differential_evolution attribute)": [[25, "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION.STOP_DISTRIBUTION_ATTACKER"]], "stop_distribution_attacker (csle_agents.constants.constants.kiefer_wolfowitz attribute)": [[25, "csle_agents.constants.constants.KIEFER_WOLFOWITZ.STOP_DISTRIBUTION_ATTACKER"]], "stop_distribution_attacker (csle_agents.constants.constants.random_search attribute)": [[25, "csle_agents.constants.constants.RANDOM_SEARCH.STOP_DISTRIBUTION_ATTACKER"]], "stop_distribution_defender (csle_agents.constants.constants.bayesian_optimization attribute)": [[25, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.STOP_DISTRIBUTION_DEFENDER"]], "stop_distribution_defender (csle_agents.constants.constants.cross_entropy attribute)": [[25, "csle_agents.constants.constants.CROSS_ENTROPY.STOP_DISTRIBUTION_DEFENDER"]], "stop_distribution_defender (csle_agents.constants.constants.differential_evolution attribute)": [[25, "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION.STOP_DISTRIBUTION_DEFENDER"]], "stop_distribution_defender (csle_agents.constants.constants.kiefer_wolfowitz attribute)": [[25, "csle_agents.constants.constants.KIEFER_WOLFOWITZ.STOP_DISTRIBUTION_DEFENDER"]], "stop_distribution_defender (csle_agents.constants.constants.random_search attribute)": [[25, "csle_agents.constants.constants.RANDOM_SEARCH.STOP_DISTRIBUTION_DEFENDER"]], "target (csle_agents.constants.constants.bayesian_optimization attribute)": [[25, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.TARGET"]], "target_kl (csle_agents.constants.constants.ppo attribute)": [[25, "csle_agents.constants.constants.PPO.TARGET_KL"]], "target_update_interval (csle_agents.constants.constants.dqn attribute)": [[25, "csle_agents.constants.constants.DQN.TARGET_UPDATE_INTERVAL"]], "theta (csle_agents.constants.constants.vi attribute)": [[25, "csle_agents.constants.constants.VI.THETA"]], "theta1 (csle_agents.constants.constants.bayesian_optimization attribute)": [[25, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.THETA1"]], "theta1 (csle_agents.constants.constants.cross_entropy attribute)": [[25, "csle_agents.constants.constants.CROSS_ENTROPY.THETA1"]], "theta1 (csle_agents.constants.constants.differential_evolution attribute)": [[25, "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION.THETA1"]], "theta1 (csle_agents.constants.constants.kiefer_wolfowitz attribute)": [[25, "csle_agents.constants.constants.KIEFER_WOLFOWITZ.THETA1"]], "theta1 (csle_agents.constants.constants.random_search attribute)": [[25, "csle_agents.constants.constants.RANDOM_SEARCH.THETA1"]], "theta1_attacker (csle_agents.constants.constants.t_fp attribute)": [[25, "csle_agents.constants.constants.T_FP.THETA1_ATTACKER"]], "theta1_defender (csle_agents.constants.constants.t_fp attribute)": [[25, "csle_agents.constants.constants.T_FP.THETA1_DEFENDER"]], "thetas (csle_agents.constants.constants.bayesian_optimization attribute)": [[25, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.THETAS"]], "thetas (csle_agents.constants.constants.cross_entropy attribute)": [[25, "csle_agents.constants.constants.CROSS_ENTROPY.THETAS"]], "thetas (csle_agents.constants.constants.differential_evolution attribute)": [[25, "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION.THETAS"]], "thetas (csle_agents.constants.constants.kiefer_wolfowitz attribute)": [[25, "csle_agents.constants.constants.KIEFER_WOLFOWITZ.THETAS"]], "thetas (csle_agents.constants.constants.random_search attribute)": [[25, "csle_agents.constants.constants.RANDOM_SEARCH.THETAS"]], "thresholds (csle_agents.constants.constants.bayesian_optimization attribute)": [[25, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.THRESHOLDS"]], "thresholds (csle_agents.constants.constants.cross_entropy attribute)": [[25, "csle_agents.constants.constants.CROSS_ENTROPY.THRESHOLDS"]], "thresholds (csle_agents.constants.constants.differential_evolution attribute)": [[25, "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION.THRESHOLDS"]], "thresholds (csle_agents.constants.constants.kiefer_wolfowitz attribute)": [[25, "csle_agents.constants.constants.KIEFER_WOLFOWITZ.THRESHOLDS"]], "thresholds (csle_agents.constants.constants.random_search attribute)": [[25, "csle_agents.constants.constants.RANDOM_SEARCH.THRESHOLDS"]], "time_horizon (csle_agents.constants.constants.env_metrics attribute)": [[25, "csle_agents.constants.constants.ENV_METRICS.TIME_HORIZON"]], "time_step (csle_agents.constants.constants.env_metrics attribute)": [[25, "csle_agents.constants.constants.ENV_METRICS.TIME_STEP"]], "training_epochs (csle_agents.constants.constants.dynasec attribute)": [[25, "csle_agents.constants.constants.DYNASEC.TRAINING_EPOCHS"]], "train_freq (csle_agents.constants.constants.dqn attribute)": [[25, "csle_agents.constants.constants.DQN.TRAIN_FREQ"]], "transition_tensor (csle_agents.constants.constants.hsvi attribute)": [[25, "csle_agents.constants.constants.HSVI.TRANSITION_TENSOR"]], "transition_tensor (csle_agents.constants.constants.hsvi_os_posg attribute)": [[25, "csle_agents.constants.constants.HSVI_OS_POSG.TRANSITION_TENSOR"]], "transition_tensor (csle_agents.constants.constants.pi attribute)": [[25, "csle_agents.constants.constants.PI.TRANSITION_TENSOR"]], "transition_tensor (csle_agents.constants.constants.shapley_iteration attribute)": [[25, "csle_agents.constants.constants.SHAPLEY_ITERATION.TRANSITION_TENSOR"]], "transition_tensor (csle_agents.constants.constants.sondik_vi attribute)": [[25, "csle_agents.constants.constants.SONDIK_VI.TRANSITION_TENSOR"]], "transition_tensor (csle_agents.constants.constants.vi attribute)": [[25, "csle_agents.constants.constants.VI.TRANSITION_TENSOR"]], "t_fp (class in csle_agents.constants.constants)": [[25, "csle_agents.constants.constants.T_FP"]], "ub_size (csle_agents.constants.constants.hsvi attribute)": [[25, "csle_agents.constants.constants.HSVI.UB_SIZE"]], "ub_sizes (csle_agents.constants.constants.hsvi attribute)": [[25, "csle_agents.constants.constants.HSVI.UB_SIZES"]], "ucb (csle_agents.constants.constants.bayesian_optimization attribute)": [[25, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.UCB"]], "ucb_kappa (csle_agents.constants.constants.bayesian_optimization attribute)": [[25, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.UCB_KAPPA"]], "ucb_xi (csle_agents.constants.constants.bayesian_optimization attribute)": [[25, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.UCB_XI"]], "use_lp (csle_agents.constants.constants.hsvi attribute)": [[25, "csle_agents.constants.constants.HSVI.USE_LP"]], "use_pruning (csle_agents.constants.constants.sondik_vi attribute)": [[25, "csle_agents.constants.constants.SONDIK_VI.USE_PRUNING"]], "utility_function (csle_agents.constants.constants.bayesian_optimization attribute)": [[25, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.UTILITY_FUNCTION"]], "vf_coef (csle_agents.constants.constants.ppo attribute)": [[25, "csle_agents.constants.constants.PPO.VF_COEF"]], "vi (class in csle_agents.constants.constants)": [[25, "csle_agents.constants.constants.VI"]], "warmup_episodes (csle_agents.constants.constants.dynasec attribute)": [[25, "csle_agents.constants.constants.DYNASEC.WARMUP_EPISODES"]], "weighted_intrusion_prediction_distance (csle_agents.constants.constants.common attribute)": [[25, "csle_agents.constants.constants.COMMON.WEIGHTED_INTRUSION_PREDICTION_DISTANCE"]], "width (csle_agents.constants.constants.hsvi attribute)": [[25, "csle_agents.constants.constants.HSVI.WIDTH"]], "widths (csle_agents.constants.constants.hsvi attribute)": [[25, "csle_agents.constants.constants.HSVI.WIDTHS"]], "widths (csle_agents.constants.constants.hsvi_os_posg attribute)": [[25, "csle_agents.constants.constants.HSVI_OS_POSG.WIDTHS"]], "csle_agents.constants": [[25, "module-csle_agents.constants"]], "csle_agents.constants.constants": [[25, "module-csle_agents.constants.constants"]], "trainingjobmanager (class in csle_agents.job_controllers.training_job_manager)": [[26, "csle_agents.job_controllers.training_job_manager.TrainingJobManager"]], "csle_agents.job_controllers": [[26, "module-csle_agents.job_controllers"]], "csle_agents.job_controllers.training_job_manager": [[26, "module-csle_agents.job_controllers.training_job_manager"]], "run_training_job() (csle_agents.job_controllers.training_job_manager.trainingjobmanager static method)": [[26, "csle_agents.job_controllers.training_job_manager.TrainingJobManager.run_training_job"]], "start_training_job_in_background() (csle_agents.job_controllers.training_job_manager.trainingjobmanager static method)": [[26, "csle_agents.job_controllers.training_job_manager.TrainingJobManager.start_training_job_in_background"]]}})