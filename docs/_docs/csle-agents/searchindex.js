Search.setIndex({"docnames": ["csle_agents", "csle_agents.agents", "csle_agents.agents.base", "csle_agents.agents.bayes_opt", "csle_agents.agents.bayesian_optimization", "csle_agents.agents.cross_entropy", "csle_agents.agents.differential_evolution", "csle_agents.agents.dqn", "csle_agents.agents.dynasec", "csle_agents.agents.fp", "csle_agents.agents.hsvi", "csle_agents.agents.hsvi_os_posg", "csle_agents.agents.kiefer_wolfowitz", "csle_agents.agents.lp_nf", "csle_agents.agents.pi", "csle_agents.agents.ppo", "csle_agents.agents.q_learning", "csle_agents.agents.random_search", "csle_agents.agents.reinforce", "csle_agents.agents.sarsa", "csle_agents.agents.shapley_iteration", "csle_agents.agents.sondik_vi", "csle_agents.agents.t_fp", "csle_agents.agents.t_spsa", "csle_agents.agents.vi", "csle_agents.common", "csle_agents.constants", "csle_agents.job_controllers", "index", "modules"], "filenames": ["csle_agents.rst", "csle_agents.agents.rst", "csle_agents.agents.base.rst", "csle_agents.agents.bayes_opt.rst", "csle_agents.agents.bayesian_optimization.rst", "csle_agents.agents.cross_entropy.rst", "csle_agents.agents.differential_evolution.rst", "csle_agents.agents.dqn.rst", "csle_agents.agents.dynasec.rst", "csle_agents.agents.fp.rst", "csle_agents.agents.hsvi.rst", "csle_agents.agents.hsvi_os_posg.rst", "csle_agents.agents.kiefer_wolfowitz.rst", "csle_agents.agents.lp_nf.rst", "csle_agents.agents.pi.rst", "csle_agents.agents.ppo.rst", "csle_agents.agents.q_learning.rst", "csle_agents.agents.random_search.rst", "csle_agents.agents.reinforce.rst", "csle_agents.agents.sarsa.rst", "csle_agents.agents.shapley_iteration.rst", "csle_agents.agents.sondik_vi.rst", "csle_agents.agents.t_fp.rst", "csle_agents.agents.t_spsa.rst", "csle_agents.agents.vi.rst", "csle_agents.common.rst", "csle_agents.constants.rst", "csle_agents.job_controllers.rst", "index.rst", "modules.rst"], "titles": ["csle_agents package", "csle_agents.agents package", "csle_agents.agents.base package", "csle_agents.agents.bayes_opt package", "csle_agents.agents.bayesian_optimization package", "csle_agents.agents.cross_entropy package", "csle_agents.agents.differential_evolution package", "csle_agents.agents.dqn package", "csle_agents.agents.dynasec package", "csle_agents.agents.fp package", "csle_agents.agents.hsvi package", "csle_agents.agents.hsvi_os_posg package", "csle_agents.agents.kiefer_wolfowitz package", "csle_agents.agents.lp_nf package", "csle_agents.agents.pi package", "csle_agents.agents.ppo package", "csle_agents.agents.q_learning package", "csle_agents.agents.random_search package", "csle_agents.agents.reinforce package", "csle_agents.agents.sarsa package", "csle_agents.agents.shapley_iteration package", "csle_agents.agents.sondik_vi package", "csle_agents.agents.t_fp package", "csle_agents.agents.t_spsa package", "csle_agents.agents.vi package", "csle_agents.common package", "csle_agents.constants package", "csle_agents.job_controllers package", "csle_agents package", "csle_agents"], "terms": {"agent": [0, 26, 28, 29], "base": [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], "submodul": [0, 1, 28, 29], "base_ag": [0, 1, 28], "bayes_opt": [], "bayes_opt_ag": [0, 1, 28], "cross_entropi": [0, 1, 26, 28], "cross_entropy_ag": [0, 1, 28], "differential_evolut": [0, 1, 26, 28], "differential_evolution_ag": [0, 1, 28], "dqn": [0, 1, 26, 28], "dqn_agent": [0, 1, 28], "dynasec": [0, 1, 26, 28], "dynasec_ag": [0, 1, 28], "fp": [0, 1, 22, 26, 28], "fictitious_play_ag": [0, 1, 28], "hsvi": [0, 1, 11, 26, 28], "hsvi_ag": [0, 1, 28], "hsvi_os_posg": [0, 1, 26, 28], "hsvi_os_posg_ag": [0, 1, 28], "kiefer_wolfowitz": [0, 1, 26, 28], "kiefer_wolfowitz_ag": [0, 1, 28], "lp_nf": [0, 1, 11, 28], "linear_programming_normal_form_game_ag": [0, 1, 28], "pi": [0, 1, 11, 26, 28], "pi_ag": [0, 1, 28], "ppo": [0, 1, 26, 28], "ppo_ag": [0, 1, 28], "q_learn": [0, 1, 19, 26, 28], "q_learning_ag": [0, 1, 28], "random_search": [0, 1, 26, 28], "random_search_ag": [0, 1, 28], "reinforc": [0, 1, 8, 26, 28], "reinforce_ag": [0, 1, 28], "sarsa": [0, 1, 26, 28], "sarsa_ag": [0, 1, 28], "shapley_iter": [0, 1, 26, 28], "shapley_iteration_ag": [0, 1, 28], "sondik_vi": [0, 1, 26, 28], "sondik_vi_ag": [0, 1, 28], "t_fp": [0, 1, 26, 28], "t_fp_agent": [0, 1, 28], "t_spsa": [0, 1, 28], "t_spsa_ag": [0, 1, 28], "vi": [0, 1, 10, 11, 26, 28], "vi_ag": [0, 1, 28], "common": [0, 26, 28, 29], "actor_critic_net": [0, 28, 29], "fnn_w_gaussian": [0, 28, 29], "fnnwithgaussian": [0, 25, 28], "forward": [0, 25, 28], "get_hidden_activ": [0, 25, 28], "train": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28], "test": [0, 25, 28], "fnn_w_linear": [0, 28, 29], "fnnwithlinear": [0, 25, 28], "prune": [0, 1, 10, 11, 21, 28, 29], "check_dominance_lp": [0, 25, 28], "check_dupl": [0, 1, 21, 25, 28], "prune_lower_bound": [0, 25, 28], "constant": [0, 28, 29], "bayesian_optim": [0, 1, 26, 28], "l": [0, 4, 5, 6, 7, 11, 12, 15, 17, 20, 23, 26, 28], "n": [0, 14, 16, 19, 22, 26, 28], "parameter_bound": [0, 26, 28], "param": [0, 10, 11, 14, 21, 24, 26, 28], "stop_distribution_attack": [0, 26, 28], "stop_distribution_defend": [0, 26, 28], "target": [0, 26, 28], "theta1": [0, 26, 28], "theta": [0, 4, 5, 6, 10, 11, 12, 17, 23, 24, 26, 28], "threshold": [0, 4, 5, 6, 10, 11, 12, 17, 20, 22, 23, 24, 26, 28], "ucb": [0, 26, 28], "ucb_kappa": [0, 26, 28], "ucb_xi": [0, 26, 28], "utility_funct": [0, 26, 28], "adam": [0, 26, 28], "average_attacker_return": [0, 26, 28], "average_defender_return": [0, 26, 28], "average_random_return": [0, 26, 28], "average_return": [0, 24, 26, 28], "average_time_horizon": [0, 26, 28], "average_upper_bound_return": [0, 26, 28], "baseline_prefix": [0, 26, 28], "batch_siz": [0, 26, 28], "confidence_interv": [0, 26, 28], "eval_batch_s": [0, 7, 14, 15, 16, 19, 21, 24, 26, 28], "eval_everi": [0, 7, 15, 26, 28], "eval_prefix": [0, 26, 28], "exploit": [0, 1, 22, 26, 28], "gamma": [0, 10, 11, 14, 16, 18, 19, 20, 21, 26, 28], "learning_r": [0, 26, 28], "learning_rate_decay_r": [0, 26, 28], "learning_rate_exp_decai": [0, 26, 28], "max_env_step": [0, 26, 28], "num_cached_simulation_trac": [0, 26, 28], "num_nod": [0, 26, 28], "num_parallel_env": [0, 26, 28], "num_training_timestep": [0, 26, 28], "optim": [0, 4, 8, 11, 14, 18, 23, 26, 28], "policy_loss": [0, 26, 28], "running_averag": [0, 1, 22, 26, 28], "running_average_attacker_return": [0, 26, 28], "running_average_defender_return": [0, 26, 28], "running_average_exploit": [0, 26, 28], "running_average_intrusion_length": [0, 26, 28], "running_average_intrusion_start": [0, 26, 28], "running_average_return": [0, 26, 28], "running_average_start_point_correct": [0, 26, 28], "running_average_time_horizon": [0, 26, 28], "running_average_weighted_intrusion_prediction_dist": [0, 26, 28], "runtim": [0, 26, 28], "save_everi": [0, 7, 15, 26, 28], "sgd": [0, 26, 28], "start_point_correct": [0, 26, 28], "stopping_env": [0, 26, 28], "weighted_intrusion_prediction_dist": [0, 26, 28], "k": [0, 12, 23, 26, 28], "lamb": [0, 23, 26, 28], "bound": [0, 6, 10, 11, 25, 26, 28], "mutat": [0, 26, 28], "population_s": [0, 26, 28], "recombin": [0, 26, 28], "buffer_s": [0, 26, 28], "dqn_batch_siz": [0, 26, 28], "exploration_final_ep": [0, 26, 28], "exploration_fract": [0, 26, 28], "exploration_initial_ep": [0, 26, 28], "gradient_step": [0, 26, 28], "learning_start": [0, 26, 28], "max_grad_norm": [0, 26, 28], "mlp_polici": [0, 26, 28], "n_episodes_rollout": [0, 26, 28], "target_update_interv": [0, 26, 28], "train_freq": [0, 26, 28], "clients_arrival_r": [0, 26, 28], "emulation_monitor_sleep_tim": [0, 26, 28], "emulation_traces_to_save_w_data_collection_job": [0, 26, 28], "intrusion_alerts_mean": [0, 26, 28], "intrusion_alerts_mean_baselin": [0, 26, 28], "intrusion_start_p": [0, 8, 26, 28], "no_intrusion_alerts_mean": [0, 26, 28], "no_intrusion_alerts_mean_baselin": [0, 26, 28], "num_client": [0, 26, 28], "replay_window_s": [0, 26, 28], "sleep_tim": [0, 8, 26, 28], "static_attacker_typ": [0, 26, 28], "training_epoch": [0, 26, 28], "warmup_episod": [0, 26, 28], "env_metr": [0, 26, 28], "attacker_act": [0, 26, 28], "defender_act": [0, 26, 28], "observ": [0, 10, 11, 21, 26, 28], "return": [0, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], "state": [0, 7, 10, 11, 14, 15, 16, 19, 20, 21, 24, 25, 26, 28], "time_horizon": [0, 26, 28], "time_step": [0, 26, 28], "fictitious_plai": [0, 1, 9, 26, 28], "payoff_matrix": [0, 26, 28], "player_1_prior": [0, 26, 28], "player_2_prior": [0, 26, 28], "action_spac": [0, 26, 28], "epsilon": [0, 10, 11, 16, 19, 23, 26, 28], "initial_belief": [0, 26, 28], "initial_belief_valu": [0, 26, 28], "lb_size": [0, 26, 28], "number_of_simul": [0, 10, 26, 28], "observation_spac": [0, 26, 28], "observation_tensor": [0, 26, 28], "prune_frequ": [0, 10, 11, 26, 28], "reward_tensor": [0, 26, 28], "simulate_horizon": [0, 10, 26, 28], "simulation_frequ": [0, 10, 26, 28], "state_spac": [0, 26, 28], "transition_tensor": [0, 26, 28], "ub_siz": [0, 26, 28], "use_lp": [0, 26, 28], "width": [0, 1, 10, 11, 26, 28], "action_space_player_1": [0, 26, 28], "action_space_player_2": [0, 26, 28], "excess": [0, 1, 10, 11, 26, 28], "observation_funct": [0, 26, 28], "delta": [0, 11, 12, 17, 24, 26, 28], "gradient_batch_s": [0, 12, 23, 26, 28], "initial_alpha": [0, 26, 28], "lp_for_nf_gam": [0, 26, 28], "initial_polici": [0, 26, 28], "num_act": [0, 10, 11, 14, 16, 19, 24, 26, 28], "num_stat": [0, 10, 11, 14, 16, 19, 24, 26, 28], "clip_rang": [0, 26, 28], "clip_range_vf": [0, 26, 28], "ent_coef": [0, 26, 28], "gae_lambda": [0, 26, 28], "steps_between_upd": [0, 26, 28], "target_kl": [0, 26, 28], "vf_coef": [0, 26, 28], "A": [0, 7, 9, 10, 11, 13, 15, 16, 19, 20, 23, 25, 26, 28], "initial_state_valu": [0, 26, 28], "": [0, 10, 11, 16, 18, 19, 20, 21, 25, 26, 28], "clip_gradi": [0, 26, 28], "num_alpha_vector": [0, 26, 28], "planning_horizon": [0, 26, 28], "use_prun": [0, 21, 26, 28], "attacker_threshold": [0, 22, 26, 28], "average_best_response_attacker_return": [0, 26, 28], "average_best_response_defender_return": [0, 26, 28], "best_response_evaluation_iter": [0, 26, 28], "defender_threshold": [0, 22, 26, 28], "equilibrium_strategies_evaluation_iter": [0, 26, 28], "n_2": [0, 26, 28], "running_average_best_response_attacker_return": [0, 26, 28], "running_average_best_response_defender_return": [0, 26, 28], "theta1_attack": [0, 26, 28], "theta1_defend": [0, 26, 28], "job_control": [0, 28, 29], "training_job_manag": [0, 28, 29], "baseag": [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28], "hparam_nam": [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28], "class": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27], "simulation_env_config": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24], "simulationenvconfig": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "emulation_env_config": [2, 4, 5, 6, 7, 8, 9, 12, 13, 15, 17, 18, 22, 23], "none": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27], "emulationenvconfig": [2, 4, 5, 6, 7, 8, 9, 12, 13, 15, 17, 18, 22, 23], "experiment_config": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "experimentconfig": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "sourc": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27], "abc": 2, "abstract": 2, "repres": [2, 10, 11, 26], "an": [2, 8, 10, 11, 14, 16, 19, 20, 21, 24], "rl": [2, 12, 22, 23], "list": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], "str": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], "experimentexecut": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "input_dim": 25, "int": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], "output_dim": 25, "hidden_dim": 25, "num_hidden_lay": 25, "2": [11, 13, 16, 19, 20, 21, 25], "hidden_activ": 25, "relu": 25, "implement": [7, 10, 11, 12, 14, 15, 22, 23, 24, 25], "fnn": 25, "gaussian": 25, "output": 25, "parameteriz": 25, "number": [4, 5, 6, 10, 11, 12, 14, 16, 17, 19, 20, 21, 22, 23, 24, 25], "layer": 25, "dimens": [4, 5, 6, 12, 14, 17, 23, 25], "hidden": 25, "activ": 25, "sub": 25, "torch": 25, "nn": 25, "abl": [11, 25], "us": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25], "high": 25, "level": 25, "api": 25, "creat": [11, 16, 19, 20, 24, 25], "custom": 25, "network": [18, 25], "x": [11, 14, 22, 25], "propag": 25, "paramet": [4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27], "input": 25, "tensor": [10, 11, 14, 18, 20, 25], "predict": 25, "interpret": [14, 25], "function": [6, 8, 10, 11, 14, 20, 24, 25], "bool": [4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25], "basic": 25, "case": 25, "verifi": 25, "model": [1, 7, 8, 15, 25, 28], "can": [10, 11, 25], "fit": 25, "some": [10, 11, 25], "randomli": [4, 5, 6, 12, 17, 23, 25], "gener": [8, 10, 11, 25], "data": [8, 25], "alpha_vec": 25, "ndarrai": [4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 16, 17, 19, 20, 23, 24, 25], "q": [1, 10, 16, 19, 25, 26, 28], "lp": [10, 11, 13, 25], "check": [10, 21, 25], "whether": [9, 10, 11, 13, 20, 21, 25], "given": [4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 17, 18, 22, 23, 25, 27], "alpha": [10, 11, 21, 25], "vector": [4, 5, 6, 9, 10, 11, 12, 13, 14, 17, 18, 21, 22, 23, 25], "i": [9, 10, 11, 14, 21, 25], "domin": [21, 25], "cassandra": 25, "littman": 25, "zhang": 25, "1997": 25, "set": [10, 11, 13, 20, 21, 25], "against": [9, 11, 22, 25], "otherwis": [10, 25], "alpha_set": 25, "av": [21, 25], "alreadi": [21, 25], "true": [4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25], "fals": [8, 10, 11, 15, 25], "lower_bound": [10, 11, 25], "lark": [21, 25], "filter": [10, 11, 21, 25], "algorithm": [4, 5, 6, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26], "lower": [10, 11, 25], "current": [10, 11, 12, 14, 17, 22, 23, 24, 25], "csle": [26, 27], "object": [4, 5, 6, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 26, 27], "string": 26, "relat": 26, "bayesian": [4, 10, 11, 26], "among": 26, "all": [11, 14, 20, 21, 26], "baseline_": 26, "eval_": 26, "3": [4, 5, 6, 7, 9, 12, 13, 15, 17, 18, 22, 23, 26], "stop": [11, 12, 20, 23, 26], "game": [9, 11, 13, 20, 22, 26], "v1": 26, "mdp": [11, 14, 16, 19, 26], "attack": [22, 26], "pomdp": [10, 11, 21, 26], "defend": [12, 22, 23, 26], "cross": [5, 26], "entropi": [5, 26], "differenti": [6, 26], "evolut": [6, 26], "exploration_fracion": 26, "mlppolici": 26, "emulation_traces_to_save_with_data_collection_job": [8, 26], "environ": [4, 5, 6, 9, 12, 13, 17, 18, 22, 23, 26], "metric": [4, 5, 6, 8, 9, 12, 13, 17, 18, 22, 23, 26], "a2": [11, 13, 20, 26], "a1": [11, 13, 19, 20, 26], "o": [10, 11, 21, 26], "r": [10, 11, 14, 16, 19, 20, 21, 24, 26], "t": [8, 10, 11, 20, 21, 22, 23, 24, 26], "fictiti": [9, 26], "plai": [9, 11, 26], "lower_bound_s": 26, "upper_bound_s": 26, "posg": [11, 26], "kiefer": [12, 26], "wolfowitz": [12, 26], "linear": [11, 13, 14, 26], "program": [11, 13, 14, 26], "normal": [9, 13, 26], "form": [9, 13, 21, 26], "learn": [8, 16, 19, 22, 26], "random": [4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26], "search": [10, 11, 17, 18, 26], "shaplei": [11, 20, 26], "iter": [10, 11, 12, 14, 16, 19, 20, 21, 23, 24, 26], "sondik": [21, 26], "packag": 29, "subpackag": 29, "modul": 29, "content": 29, "trainingjobmanag": [0, 27, 28], "run_training_job": [0, 27, 28], "start_training_job_in_background": [0, 27, 28], "bayesoptag": [1, 4, 28], "compute_avg_metr": [1, 4, 5, 6, 9, 12, 13, 17, 18, 22, 23, 28], "eval_theta": [1, 4, 5, 6, 12, 17, 23, 28], "get_theta_vector_from_param_dict": [1, 4, 28], "initial_theta": [1, 4, 5, 6, 12, 17, 23, 28], "round_vec": [1, 4, 5, 6, 9, 12, 13, 17, 18, 22, 23, 28], "update_metr": [1, 4, 5, 6, 9, 12, 13, 17, 18, 22, 23, 28], "crossentropyag": [1, 5, 28], "differentialevolutionag": [1, 6, 28], "ensure_bound": [1, 6, 28], "dqnagent": [1, 7, 28], "dqntrainingcallback": [1, 7, 28], "datacollectorprocess": [1, 8, 28], "run": [1, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28], "dynasecag": [1, 8, 28], "get_z_from_system_model": [1, 8, 28], "get_spsa_experiment_config": [1, 8, 28], "mean": [1, 8, 21, 28], "record_metr": [1, 8, 28], "emulationmonitorthread": [1, 8, 28], "emulationstatisticsthread": [1, 8, 28], "policyevaluationthread": [1, 8, 28], "eval_trac": [1, 8, 28], "policyoptimizationprocess": [1, 8, 28], "systemidentificationprocess": [1, 8, 28], "fictitiousplayag": [1, 9, 28], "best_respons": [1, 9, 28], "compute_empirical_strategi": [1, 9, 28], "hsviagent": [1, 10, 28], "approximate_projection_sawtooth": [1, 10, 28], "bayes_filt": [1, 10, 11, 28], "explor": [1, 10, 11, 16, 19, 28], "generate_corner_belief": [1, 10, 11, 28], "hsvi_algorithm": [1, 10, 28], "initialize_lower_bound": [1, 10, 11, 28], "initialize_upper_bound": [1, 10, 11, 28], "interior_point_belief_v": [1, 10, 28], "local_lower_bound_upd": [1, 10, 11, 28], "local_upd": [1, 10, 11, 28], "local_upper_bound_upd": [1, 10, 11, 28], "lower_bound_backup": [1, 10, 11, 28], "lower_bound_valu": [1, 10, 11, 28], "lp_convex_hull_projection_lp": [1, 10, 28], "next_belief": [1, 10, 11, 28], "observation_poss": [1, 10, 28], "one_step_lookahead": [1, 10, 11, 24, 28], "p_o_given_b_a": [1, 10, 28], "prune_upper_bound": [1, 10, 11, 28], "q_hat_interv": [1, 10, 28], "simul": [1, 4, 5, 6, 10, 12, 17, 21, 23, 28], "update_corner_point": [1, 10, 28], "upper_bound_backup": [1, 10, 11, 28], "upper_bound_valu": [1, 10, 11, 28], "hsviosposgag": [1, 11, 28], "auxillary_gam": [1, 11, 20, 28], "choose_a_o_for_explor": [1, 11, 28], "combine_weights_and_pure_strategies_into_mixed_strategi": [1, 11, 28], "compute_delta": [1, 11, 28], "compute_equilibrium_strategies_in_matrix_gam": [1, 11, 13, 28], "compute_matrix_game_valu": [1, 11, 13, 20, 28], "delta_lipschitz_envelope_of_upper_bound_valu": [1, 11, 28], "maxcomp_shapley_bellman_oper": [1, 11, 28], "mdp_reward_matrix_p2": [1, 11, 28], "mdp_transition_tensor_p2": [1, 11, 28], "obtain_equilibrium_strategy_profiles_in_stage_gam": [1, 11, 28], "p_o_given_b_a1_a2": [1, 11, 28], "p_o_given_b_pi_1_pi_2": [1, 11, 28], "rho": [1, 11, 28], "sample_d": [1, 11, 28], "si": [1, 11, 20, 28], "valcomp": [1, 11, 28], "value_of_p1_strategy_stat": [1, 11, 28], "weighted_excess_gap": [1, 11, 28], "kieferwolfowitzag": [1, 12, 28], "batch_gradi": [1, 12, 23, 28], "estimate_gk": [1, 12, 23, 28], "linearprogrammingnormalformgameag": [1, 13, 28], "linear_programming_normal_form": [1, 13, 28], "piagent": [1, 14, 28], "evaluate_polici": [1, 14, 16, 19, 21, 24, 28], "expected_reward_under_polici": [1, 14, 28], "policy_evalu": [1, 14, 28], "policy_improv": [1, 14, 28], "policy_iter": [1, 14, 28], "transition_probability_under_polici": [1, 14, 28], "ppoagent": [1, 15, 28], "ppotrainingcallback": [1, 15, 28], "qlearningag": [1, 16, 28], "create_policy_from_q_t": [1, 16, 19, 28], "eps_greedi": [1, 16, 19, 28], "initialize_count_t": [1, 16, 19, 28], "initialize_q_t": [1, 16, 19, 28], "q_learning_upd": [1, 16, 28], "step_siz": [1, 16, 19, 28], "train_q_learn": [1, 16, 28], "randomsearchag": [1, 17, 28], "random_perturb": [1, 17, 28], "reinforceag": [1, 18, 28], "training_step": [1, 18, 28], "sarsaag": [1, 19, 28], "sarsa_upd": [1, 19, 28], "train_sarsa": [1, 19, 28], "shapleyiterationag": [1, 20, 28], "sondikviag": [1, 21, 28], "compute_all_conditional_plans_conditioned_on_a_t": [1, 21, 28], "sondik_vi_algorithm": [1, 21, 28], "tfpagent": [1, 22, 28], "attacker_best_respons": [1, 22, 28], "defender_best_respons": [1, 22, 28], "evaluate_attacker_polici": [1, 22, 28], "evaluate_defender_polici": [1, 22, 28], "evaluate_strategy_profil": [1, 22, 28], "get_attacker_experiment_config": [1, 22, 28], "get_defender_experiment_config": [1, 22, 28], "tspsaagent": [1, 23, 28], "spsa": [1, 8, 23, 28], "standard_ak": [1, 23, 28], "standard_ck": [1, 23, 28], "standard_deltak": [1, 23, 28], "viagent": [1, 24, 28], "create_policy_from_value_funct": [1, 24, 28], "value_iter": [1, 24, 28], "union": [2, 4, 5, 6, 7, 9, 12, 13, 15, 17, 18, 22, 23], "env": [4, 5, 6, 7, 8, 9, 12, 13, 15, 17, 18, 22, 23], "option": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "training_job": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27], "trainingjobconfig": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27], "save_to_metastor": [4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24], "exp_result": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "experimentresult": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "seed": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "random_se": [4, 5, 6, 7, 9, 12, 13, 15, 17, 18, 22, 23], "experi": [4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24], "result": [4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24], "store": [4, 5, 6, 9, 12, 13, 17, 18, 23], "job": [4, 5, 6, 9, 12, 13, 17, 18, 23, 27], "config": [4, 5, 6, 9, 12, 13, 17, 18, 23], "updat": [4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24], "polici": [4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 21, 22, 23, 24], "static": [4, 5, 6, 8, 9, 11, 12, 13, 17, 18, 22, 23, 27], "dict": [4, 5, 6, 8, 9, 12, 13, 17, 18, 22, 23], "float": [4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "comput": [4, 5, 6, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24], "averag": [4, 5, 6, 9, 12, 13, 16, 17, 18, 19, 22, 23], "aggreg": [4, 5, 6, 9, 12, 13, 17, 18, 22, 23], "multithresholdstoppingpolici": [4, 5, 6, 12, 17, 23], "max_step": [4, 5, 6, 7, 8, 12, 15, 17, 23], "200": [4, 5, 6, 12, 17, 23], "evalu": [4, 5, 6, 8, 11, 12, 14, 16, 17, 19, 21, 22, 23, 24], "mont": [4, 5, 6, 12, 17, 22, 23], "carlo": [4, 5, 6, 12, 17, 22, 23], "param_dict": 4, "extract": 4, "from": [4, 5, 6, 7, 8, 9, 11, 12, 13, 15, 16, 17, 18, 19, 22, 23, 24], "hyperparamet": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "name": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "initi": [4, 5, 6, 10, 11, 12, 16, 17, 19, 21, 23], "vec": [4, 5, 6, 9, 12, 13, 17, 18, 22, 23], "round": [4, 5, 6, 9, 12, 13, 17, 18, 22, 23], "decim": [4, 5, 6, 9, 12, 13, 17, 18, 22, 23], "perform": [4, 5, 6, 8, 9, 10, 11, 12, 13, 17, 18, 22, 23, 24], "info": [4, 5, 6, 9, 12, 13, 17, 18, 22, 23], "new": [4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 17, 18, 22, 23], "inform": [4, 5, 6, 9, 12, 13, 17, 18, 22, 23], "method": [4, 5, 6, 12], "util": [4, 5, 6, 8, 11, 12, 14], "ensur": [6, 11], "openai": [7, 15], "baselin": [7, 8, 15], "exp_execut": [7, 15], "simulation_nam": [7, 15], "action": [7, 9, 10, 11, 13, 14, 15, 16, 18, 19, 20, 21, 24], "player_typ": [7, 15], "playertyp": [7, 15], "verbos": [7, 11, 15], "0": [7, 8, 10, 11, 15, 16, 19, 20, 21, 24], "100": [7, 15], "10": [7, 10, 11, 15], "save_dir": [7, 15], "gym_env_nam": [7, 15], "basecallback": [7, 15], "callback": [7, 15], "monitor": [7, 15], "emulation_execut": 8, "emulationexecut": 8, "attacker_sequ": 8, "emulationattackeract": 8, "defender_sequ": 8, "emulationdefenderact": 8, "worker_id": 8, "emulation_statistics_window": 8, "emulationstatisticswindow": 8, "30": 8, "1": [8, 10, 11, 12, 13, 14, 20, 21, 23, 24], "thread": 8, "process": [8, 15], "interact": 8, "emul": 8, "execut": 8, "system_identification_config": 8, "systemidentificationconfig": 8, "system_model": 8, "gaussianmixturesystemmodel": 8, "sample_spac": 8, "tupl": [8, 9, 10, 11, 13, 14, 16, 19, 20, 21, 22, 24], "configur": [8, 22, 27], "prob_vector": 8, "metrics_dict": 8, "record": 8, "import": 8, "them": 8, "sleep_time_minut": 8, "collect": 8, "data_collector_process": 8, "track": 8, "statist": 8, "baseline_polici": 8, "emulation_statistics_thread": 8, "baseline_system_model": 8, "period": 8, "trace": 8, "emulationtrac": 8, "defender_polici": 8, "eval": 8, "through": [8, 11, 23], "system": [8, 14], "emulation_statist": 8, "emulationstatist": 8, "collector": 8, "estim": [8, 10, 12, 22, 23], "brown": 9, "1951": 9, "p": [9, 10, 11, 14, 18, 21], "maxim": [9, 11, 13, 20], "best": [9, 11, 22], "respons": [9, 11, 22], "oppon": [9, 11], "strategi": [9, 11, 13, 16, 19, 20, 22], "payoff": 9, "matrix": [9, 11, 13, 14, 20, 21], "player": [9, 11, 13, 20], "minim": [9, 11, 13], "its": [9, 22], "valu": [9, 10, 11, 13, 14, 16, 19, 20, 21, 22, 24], "count": [9, 16, 19], "empir": 9, "heurist": [10, 11], "trei": [10, 11], "smith": [10, 11], "reid": [10, 11], "simmon": [10, 11], "2004": [10, 11], "upper_bound": [10, 11], "b": [10, 11], "refer": 10, "hauskreht": 10, "2000": 10, "approxim": 10, "project": 10, "belief": [10, 11, 21], "onto": 10, "convex": [10, 11], "hull": [10, 11], "upepr": 10, "upper": [10, 11], "point": [10, 11], "s_prime": [10, 11, 16, 19], "z": [10, 11, 21], "being": [10, 11], "when": [10, 11, 22], "after": [10, 11, 14], "take": [10, 11], "transit": [10, 11, 14, 20, 21, 24], "b_prime": [10, 11], "uncertainti": 10, "accuraci": [10, 11], "discount": [10, 11, 14, 16, 18, 19, 20, 21, 24], "factor": [10, 11, 14, 16, 18, 19, 20, 21, 24], "depth": [10, 11], "tree": [10, 11], "reward": [10, 11, 14, 16, 18, 19, 20, 21, 22, 24], "corner": [10, 11], "simplex": [10, 11], "correspond": [10, 11], "probabl": [10, 11, 14, 18, 21, 24], "b0": [10, 11, 21], "sawtooth": 10, "how": [10, 11], "often": [10, 11], "frequent": 10, "compur": 10, "length": 10, "interior_point": 10, "alpha_corn": 10, "induc": [10, 11, 21], "interior": 10, "local": [10, 11], "v": [10, 11, 14, 20, 21, 24], "boolean": [10, 11, 13, 20], "flag": [10, 11, 13, 20], "The": [10, 11, 14, 21], "dure": [10, 11], "solv": [10, 11, 14], "next": [10, 11, 16, 19, 24], "latest": [10, 11, 18], "space": [10, 11, 16, 19], "aciton": [10, 11, 20], "tocheck": 10, "possibl": [10, 11, 21], "fasl": 10, "discount_factor": [10, 11, 24], "one": [10, 11, 24], "step": [10, 11, 12, 14, 16, 17, 18, 19, 23, 24], "lookahead": [10, 11, 24], "kernel": [10, 11, 24], "tabl": [10, 11, 16, 19, 24], "next_state_lookahead": [10, 11, 24], "arrai": [10, 11, 24], "decid": [10, 11], "appli": 10, "bellman": [10, 11], "equat": [10, 11], "interv": [10, 11], "horizon": [10, 21], "greedi": [10, 11, 16, 19, 24], "respect": [10, 11], "which": [10, 11], "oper": [10, 11, 24], "cumul": 10, "corner_point": 10, "new_point": 10, "mayb": 10, "add": [10, 11], "0001": [10, 11, 24], "state_to_id": [10, 11, 24], "id": [10, 11, 24], "lookup": [10, 11, 24], "hp": [10, 11, 24], "hack": [10, 11, 24], "converg": [10, 11, 14, 24], "auxillari": [11, 20], "pi_2": 11, "follow": [11, 21, 22], "pi_1_upper_bound": 11, "pi_2_lower_bound": 11, "d": 11, "select": [11, 14, 16, 19], "accord": [11, 16, 19], "argmax_": 11, "b_1": 11, "a_1": 11, "hor\u00e1k": 11, "bosanski": 11, "kova\u0159\u00edk": 11, "kiekintveld": 11, "2020": 11, "time": 11, "equilibrium": [11, 13], "stage": [11, 20], "construct": 11, "lipschitz": 11, "continu": 11, "neighboorhood": 11, "weighted_excess": 11, "weight": [11, 18], "mixtur": 11, "mix": 11, "To": 11, "prove": 11, "we": 11, "requir": 11, "v_ub": 11, "v_lb": 11, "ar": 11, "well": 11, "thi": 11, "specif": 11, "u": 11, "where": [11, 14, 21], "teh": 11, "profil": [11, 13, 22], "ani": [11, 13], "also": [11, 13], "maximin": [11, 13, 20], "minimax": [11, 13, 20], "val": [11, 13, 20], "envelop": 11, "gap": 11, "horak": 11, "pechoucek": 11, "2017": 11, "neighborhood": 11, "p1": 11, "p2": 11, "zero": 11, "sum": 11, "achiev": 11, "each": [11, 14, 21], "uniform": 11, "singleton": 11, "fulli": 11, "version": 11, "preserv": 11, "properti": 11, "dear": 11, "child": 11, "mani": 11, "maxcomp": 11, "hv": 11, "pointwis": 11, "maximum": [11, 20], "over": 11, "By": 11, "solut": 11, "found": 11, "e": 11, "whole": 11, "purpos": 11, "karel": 11, "phd": 11, "thesi": 11, "2019": 11, "That": 11, "backup": 11, "exact": 11, "behavior": 11, "combin": [11, 21], "p1_strategi": 11, "fix": 11, "pi_1": 11, "tri": 11, "keep": 11, "between": 11, "most": 11, "monoton": 11, "increas": 11, "unbound": 11, "lipshitz": 11, "sampl": [11, 16, 19], "legal": 11, "rang": 11, "sequenc": 11, "need": 11, "2delta": 11, "max_iter": [11, 20], "500": [11, 20], "delta_threshold": [11, 20], "log": [11, 18], "1953": [11, 20], "sg": [11, 20], "themselv": [11, 20], "alpha_bar": 11, "substituted_alpha": 11, "composit": 11, "consist": 11, "distribut": 11, "expect": [11, 14], "c": [11, 23], "sigma_1": 11, "It": [11, 21], "assum": [11, 14], "further": 11, "sinc": 11, "subsequ": 11, "subgam": 11, "treat": 11, "independ": 11, "For": 11, "exampl": 11, "sa": [12, 16, 19], "50": 12, "batch": [12, 14, 16, 19, 21, 23, 24], "gradient": [12, 23], "ck": [12, 23], "perturb": [12, 17, 23], "size": [12, 14, 16, 17, 19, 21, 23, 24], "total": [12, 23], "includ": [12, 23], "evalut": [14, 16, 19, 21, 24], "tabular": [14, 16, 19, 21, 24], "immedi": [14, 21], "interleav": 14, "improv": 14, "guarante": 14, "scalar": [14, 23], "dynam": 14, "algebra": 14, "old": 14, "pi_prim": 14, "under": 14, "determinist": 14, "p_pi": 14, "start": [15, 27], "q_tabl": [16, 19], "n_state": [16, 19, 21], "256": [16, 19], "n_action": [16, 19, 21], "5": [16, 19], "count_tabl": [16, 19], "watkin": 16, "determin": [16, 19], "calcul": [16, 19, 22], "8": [16, 19], "10000": [16, 19], "saved_reward": 18, "saved_log_prob": 18, "policy_network": 18, "fnnwithsoftmax": 18, "encount": 18, "episod": 18, "trajectori": 18, "loss": 18, "eaction": 19, "indic": 20, "should": [20, 21], "1971": 21, "n_alpha_vectors_t_plus_on": 21, "n_ob": 21, "condit": 21, "plan": 21, "produc": 21, "conditional_plan": 21, "contain": 21, "element": [21, 22], "n_alpha_vector": 21, "_i": 21, "_j": 21, "_k": 21, "o_i": 21, "o_j": 21, "o_k": 21, "alphavectorspolici": 21, "aleph": 21, "remov": 21, "defender_simulation_env_config": 22, "attacker_simulation_env_config": 22, "todo": 22, "defender_strategi": 22, "mixedmultithresholdstoppingpolici": 22, "attacker_strategi": 22, "attacker_v": 22, "defender_v": 22, "last": 22, "hammar": 23, "stadler": 23, "2021": 23, "intrus": 23, "prevent": 23, "deltak": 23, "direct": 23, "get": [4, 5, 6, 12, 17, 23], "ascent": 23, "index": 23, "a_k": 23, "lambda": 23, "pertrub": 23, "delta_k": 23, "manag": 27, "job_config": 27, "background": 27, "policy_typ": [0, 26, 28], "average_heuristic_return": [0, 26, 28], "get_polici": [1, 4, 5, 6, 12, 17, 23, 28], "logger": [1, 7, 15, 28], "linearthresholdstoppingpolici": [4, 5, 6, 12, 17, 23], "base_class": [7, 15], "basealgorithm": [7, 15]}, "objects": {"": [[28, 0, 0, "-", "csle_agents"]], "csle_agents": [[1, 0, 0, "-", "agents"], [25, 0, 0, "-", "common"], [26, 0, 0, "-", "constants"], [27, 0, 0, "-", "job_controllers"]], "csle_agents.agents": [[2, 0, 0, "-", "base"], [3, 0, 0, "-", "bayes_opt"], [4, 0, 0, "-", "bayesian_optimization"], [5, 0, 0, "-", "cross_entropy"], [6, 0, 0, "-", "differential_evolution"], [7, 0, 0, "-", "dqn"], [8, 0, 0, "-", "dynasec"], [9, 0, 0, "-", "fp"], [10, 0, 0, "-", "hsvi"], [11, 0, 0, "-", "hsvi_os_posg"], [12, 0, 0, "-", "kiefer_wolfowitz"], [13, 0, 0, "-", "lp_nf"], [14, 0, 0, "-", "pi"], [15, 0, 0, "-", "ppo"], [16, 0, 0, "-", "q_learning"], [17, 0, 0, "-", "random_search"], [18, 0, 0, "-", "reinforce"], [19, 0, 0, "-", "sarsa"], [20, 0, 0, "-", "shapley_iteration"], [21, 0, 0, "-", "sondik_vi"], [22, 0, 0, "-", "t_fp"], [23, 0, 0, "-", "t_spsa"], [24, 0, 0, "-", "vi"]], "csle_agents.agents.base": [[2, 0, 0, "-", "base_agent"]], "csle_agents.agents.base.base_agent": [[2, 1, 1, "", "BaseAgent"]], "csle_agents.agents.base.base_agent.BaseAgent": [[2, 2, 1, "", "hparam_names"], [2, 2, 1, "", "train"]], "csle_agents.agents.bayesian_optimization": [[4, 0, 0, "-", "bayes_opt_agent"]], "csle_agents.agents.bayesian_optimization.bayes_opt_agent": [[4, 1, 1, "", "BayesOptAgent"]], "csle_agents.agents.bayesian_optimization.bayes_opt_agent.BayesOptAgent": [[4, 2, 1, "", "bayesian_optimization"], [4, 2, 1, "", "compute_avg_metrics"], [4, 2, 1, "", "eval_theta"], [4, 2, 1, "", "get_policy"], [4, 2, 1, "", "get_theta_vector_from_param_dict"], [4, 2, 1, "", "hparam_names"], [4, 2, 1, "", "initial_theta"], [4, 2, 1, "", "round_vec"], [4, 2, 1, "", "train"], [4, 2, 1, "", "update_metrics"]], "csle_agents.agents.cross_entropy": [[5, 0, 0, "-", "cross_entropy_agent"]], "csle_agents.agents.cross_entropy.cross_entropy_agent": [[5, 1, 1, "", "CrossEntropyAgent"]], "csle_agents.agents.cross_entropy.cross_entropy_agent.CrossEntropyAgent": [[5, 2, 1, "", "compute_avg_metrics"], [5, 2, 1, "", "cross_entropy"], [5, 2, 1, "", "eval_theta"], [5, 2, 1, "", "get_policy"], [5, 2, 1, "", "hparam_names"], [5, 2, 1, "", "initial_theta"], [5, 2, 1, "", "round_vec"], [5, 2, 1, "", "train"], [5, 2, 1, "", "update_metrics"]], "csle_agents.agents.differential_evolution": [[6, 0, 0, "-", "differential_evolution_agent"]], "csle_agents.agents.differential_evolution.differential_evolution_agent": [[6, 1, 1, "", "DifferentialEvolutionAgent"]], "csle_agents.agents.differential_evolution.differential_evolution_agent.DifferentialEvolutionAgent": [[6, 2, 1, "", "compute_avg_metrics"], [6, 2, 1, "", "differential_evolution"], [6, 2, 1, "", "ensure_bounds"], [6, 2, 1, "", "eval_theta"], [6, 2, 1, "", "get_policy"], [6, 2, 1, "", "hparam_names"], [6, 2, 1, "", "initial_theta"], [6, 2, 1, "", "round_vec"], [6, 2, 1, "", "train"], [6, 2, 1, "", "update_metrics"]], "csle_agents.agents.dqn": [[7, 0, 0, "-", "dqn_agent"]], "csle_agents.agents.dqn.dqn_agent": [[7, 1, 1, "", "DQNAgent"], [7, 1, 1, "", "DQNTrainingCallback"]], "csle_agents.agents.dqn.dqn_agent.DQNAgent": [[7, 2, 1, "", "hparam_names"], [7, 2, 1, "", "train"]], "csle_agents.agents.dqn.dqn_agent.DQNTrainingCallback": [[7, 3, 1, "", "logger"], [7, 3, 1, "", "model"]], "csle_agents.agents.dynasec": [[8, 0, 0, "-", "dynasec_agent"]], "csle_agents.agents.dynasec.dynasec_agent": [[8, 1, 1, "", "DataCollectorProcess"], [8, 1, 1, "", "DynaSecAgent"], [8, 1, 1, "", "EmulationMonitorThread"], [8, 1, 1, "", "EmulationStatisticsThread"], [8, 1, 1, "", "PolicyEvaluationThread"], [8, 1, 1, "", "PolicyOptimizationProcess"], [8, 1, 1, "", "SystemIdentificationProcess"]], "csle_agents.agents.dynasec.dynasec_agent.DataCollectorProcess": [[8, 2, 1, "", "run"]], "csle_agents.agents.dynasec.dynasec_agent.DynaSecAgent": [[8, 2, 1, "", "get_Z_from_system_model"], [8, 2, 1, "", "get_spsa_experiment_config"], [8, 2, 1, "", "hparam_names"], [8, 2, 1, "", "mean"], [8, 2, 1, "", "record_metrics"], [8, 2, 1, "", "train"]], "csle_agents.agents.dynasec.dynasec_agent.EmulationMonitorThread": [[8, 2, 1, "", "run"]], "csle_agents.agents.dynasec.dynasec_agent.EmulationStatisticsThread": [[8, 2, 1, "", "run"]], "csle_agents.agents.dynasec.dynasec_agent.PolicyEvaluationThread": [[8, 2, 1, "", "eval_traces"], [8, 2, 1, "", "record_metrics"], [8, 2, 1, "", "run"]], "csle_agents.agents.dynasec.dynasec_agent.PolicyOptimizationProcess": [[8, 2, 1, "", "run"]], "csle_agents.agents.dynasec.dynasec_agent.SystemIdentificationProcess": [[8, 2, 1, "", "run"]], "csle_agents.agents.fp": [[9, 0, 0, "-", "fictitious_play_agent"]], "csle_agents.agents.fp.fictitious_play_agent": [[9, 1, 1, "", "FictitiousPlayAgent"]], "csle_agents.agents.fp.fictitious_play_agent.FictitiousPlayAgent": [[9, 2, 1, "", "best_response"], [9, 2, 1, "", "compute_avg_metrics"], [9, 2, 1, "", "compute_empirical_strategy"], [9, 2, 1, "", "fictitious_play"], [9, 2, 1, "", "hparam_names"], [9, 2, 1, "", "round_vec"], [9, 2, 1, "", "train"], [9, 2, 1, "", "update_metrics"]], "csle_agents.agents.hsvi": [[10, 0, 0, "-", "hsvi_agent"]], "csle_agents.agents.hsvi.hsvi_agent": [[10, 1, 1, "", "HSVIAgent"]], "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent": [[10, 2, 1, "", "approximate_projection_sawtooth"], [10, 2, 1, "", "bayes_filter"], [10, 2, 1, "", "excess"], [10, 2, 1, "", "explore"], [10, 2, 1, "", "generate_corner_belief"], [10, 2, 1, "", "hparam_names"], [10, 2, 1, "", "hsvi"], [10, 2, 1, "", "hsvi_algorithm"], [10, 2, 1, "", "initialize_lower_bound"], [10, 2, 1, "", "initialize_upper_bound"], [10, 2, 1, "", "interior_point_belief_val"], [10, 2, 1, "", "local_lower_bound_update"], [10, 2, 1, "", "local_updates"], [10, 2, 1, "", "local_upper_bound_update"], [10, 2, 1, "", "lower_bound_backup"], [10, 2, 1, "", "lower_bound_value"], [10, 2, 1, "", "lp_convex_hull_projection_lp"], [10, 2, 1, "", "next_belief"], [10, 2, 1, "", "observation_possible"], [10, 2, 1, "", "one_step_lookahead"], [10, 2, 1, "", "p_o_given_b_a"], [10, 2, 1, "", "prune_upper_bound"], [10, 2, 1, "", "q"], [10, 2, 1, "", "q_hat_interval"], [10, 2, 1, "", "simulate"], [10, 2, 1, "", "train"], [10, 2, 1, "", "update_corner_points"], [10, 2, 1, "", "upper_bound_backup"], [10, 2, 1, "", "upper_bound_value"], [10, 2, 1, "", "vi"], [10, 2, 1, "", "width"]], "csle_agents.agents.hsvi_os_posg": [[11, 0, 0, "-", "hsvi_os_posg_agent"]], "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent": [[11, 1, 1, "", "HSVIOSPOSGAgent"]], "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent": [[11, 2, 1, "", "auxillary_game"], [11, 2, 1, "", "bayes_filter"], [11, 2, 1, "", "choose_a_o_for_exploration"], [11, 2, 1, "", "combine_weights_and_pure_strategies_into_mixed_strategy"], [11, 2, 1, "", "compute_delta"], [11, 2, 1, "", "compute_equilibrium_strategies_in_matrix_game"], [11, 2, 1, "", "compute_matrix_game_value"], [11, 2, 1, "", "delta_lipschitz_envelope_of_upper_bound_value"], [11, 2, 1, "", "excess"], [11, 2, 1, "", "explore"], [11, 2, 1, "", "generate_corner_belief"], [11, 2, 1, "", "hparam_names"], [11, 2, 1, "", "hsvi"], [11, 2, 1, "", "hsvi_os_posg"], [11, 2, 1, "", "initialize_lower_bound"], [11, 2, 1, "", "initialize_upper_bound"], [11, 2, 1, "", "local_lower_bound_update"], [11, 2, 1, "", "local_updates"], [11, 2, 1, "", "local_upper_bound_update"], [11, 2, 1, "", "lower_bound_backup"], [11, 2, 1, "", "lower_bound_value"], [11, 2, 1, "", "maxcomp_shapley_bellman_operator"], [11, 2, 1, "", "mdp_reward_matrix_p2"], [11, 2, 1, "", "mdp_transition_tensor_p2"], [11, 2, 1, "", "next_belief"], [11, 2, 1, "", "obtain_equilibrium_strategy_profiles_in_stage_game"], [11, 2, 1, "", "one_step_lookahead"], [11, 2, 1, "", "p_o_given_b_a1_a2"], [11, 2, 1, "", "p_o_given_b_pi_1_pi_2"], [11, 2, 1, "", "prune_upper_bound"], [11, 2, 1, "", "rho"], [11, 2, 1, "", "sample_D"], [11, 2, 1, "", "si"], [11, 2, 1, "", "train"], [11, 2, 1, "", "upper_bound_backup"], [11, 2, 1, "", "upper_bound_value"], [11, 2, 1, "", "valcomp"], [11, 2, 1, "", "value_of_p1_strategy_static"], [11, 2, 1, "", "vi"], [11, 2, 1, "", "weighted_excess_gap"], [11, 2, 1, "", "width"]], "csle_agents.agents.kiefer_wolfowitz": [[12, 0, 0, "-", "kiefer_wolfowitz_agent"]], "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent": [[12, 1, 1, "", "KieferWolfowitzAgent"]], "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.KieferWolfowitzAgent": [[12, 2, 1, "", "batch_gradient"], [12, 2, 1, "", "compute_avg_metrics"], [12, 2, 1, "", "estimate_gk"], [12, 2, 1, "", "eval_theta"], [12, 2, 1, "", "get_policy"], [12, 2, 1, "", "hparam_names"], [12, 2, 1, "", "initial_theta"], [12, 2, 1, "", "kiefer_wolfowitz"], [12, 2, 1, "", "round_vec"], [12, 2, 1, "", "train"], [12, 2, 1, "", "update_metrics"]], "csle_agents.agents.lp_nf": [[13, 0, 0, "-", "linear_programming_normal_form_game_agent"]], "csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent": [[13, 1, 1, "", "LinearProgrammingNormalFormGameAgent"]], "csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.LinearProgrammingNormalFormGameAgent": [[13, 2, 1, "", "compute_avg_metrics"], [13, 2, 1, "", "compute_equilibrium_strategies_in_matrix_game"], [13, 2, 1, "", "compute_matrix_game_value"], [13, 2, 1, "", "hparam_names"], [13, 2, 1, "", "linear_programming_normal_form"], [13, 2, 1, "", "round_vec"], [13, 2, 1, "", "train"], [13, 2, 1, "", "update_metrics"]], "csle_agents.agents.pi": [[14, 0, 0, "-", "pi_agent"]], "csle_agents.agents.pi.pi_agent": [[14, 1, 1, "", "PIAgent"]], "csle_agents.agents.pi.pi_agent.PIAgent": [[14, 2, 1, "", "evaluate_policy"], [14, 2, 1, "", "expected_reward_under_policy"], [14, 2, 1, "", "hparam_names"], [14, 2, 1, "", "pi"], [14, 2, 1, "", "policy_evaluation"], [14, 2, 1, "", "policy_improvement"], [14, 2, 1, "", "policy_iteration"], [14, 2, 1, "", "train"], [14, 2, 1, "", "transition_probability_under_policy"]], "csle_agents.agents.ppo": [[15, 0, 0, "-", "ppo_agent"]], "csle_agents.agents.ppo.ppo_agent": [[15, 1, 1, "", "PPOAgent"], [15, 1, 1, "", "PPOTrainingCallback"]], "csle_agents.agents.ppo.ppo_agent.PPOAgent": [[15, 2, 1, "", "hparam_names"], [15, 2, 1, "", "train"]], "csle_agents.agents.ppo.ppo_agent.PPOTrainingCallback": [[15, 3, 1, "", "logger"], [15, 3, 1, "", "model"]], "csle_agents.agents.q_learning": [[16, 0, 0, "-", "q_learning_agent"]], "csle_agents.agents.q_learning.q_learning_agent": [[16, 1, 1, "", "QLearningAgent"]], "csle_agents.agents.q_learning.q_learning_agent.QLearningAgent": [[16, 2, 1, "", "create_policy_from_q_table"], [16, 2, 1, "", "eps_greedy"], [16, 2, 1, "", "evaluate_policy"], [16, 2, 1, "", "hparam_names"], [16, 2, 1, "", "initialize_count_table"], [16, 2, 1, "", "initialize_q_table"], [16, 2, 1, "", "q_learning"], [16, 2, 1, "", "q_learning_update"], [16, 2, 1, "", "step_size"], [16, 2, 1, "", "train"], [16, 2, 1, "", "train_q_learning"]], "csle_agents.agents.random_search": [[17, 0, 0, "-", "random_search_agent"]], "csle_agents.agents.random_search.random_search_agent": [[17, 1, 1, "", "RandomSearchAgent"]], "csle_agents.agents.random_search.random_search_agent.RandomSearchAgent": [[17, 2, 1, "", "compute_avg_metrics"], [17, 2, 1, "", "eval_theta"], [17, 2, 1, "", "get_policy"], [17, 2, 1, "", "hparam_names"], [17, 2, 1, "", "initial_theta"], [17, 2, 1, "", "random_perturbation"], [17, 2, 1, "", "random_search"], [17, 2, 1, "", "round_vec"], [17, 2, 1, "", "train"], [17, 2, 1, "", "update_metrics"]], "csle_agents.agents.reinforce": [[18, 0, 0, "-", "reinforce_agent"]], "csle_agents.agents.reinforce.reinforce_agent": [[18, 1, 1, "", "ReinforceAgent"]], "csle_agents.agents.reinforce.reinforce_agent.ReinforceAgent": [[18, 2, 1, "", "compute_avg_metrics"], [18, 2, 1, "", "hparam_names"], [18, 2, 1, "", "reinforce"], [18, 2, 1, "", "round_vec"], [18, 2, 1, "", "train"], [18, 2, 1, "", "training_step"], [18, 2, 1, "", "update_metrics"]], "csle_agents.agents.sarsa": [[19, 0, 0, "-", "sarsa_agent"]], "csle_agents.agents.sarsa.sarsa_agent": [[19, 1, 1, "", "SARSAAgent"]], "csle_agents.agents.sarsa.sarsa_agent.SARSAAgent": [[19, 2, 1, "", "create_policy_from_q_table"], [19, 2, 1, "", "eps_greedy"], [19, 2, 1, "", "evaluate_policy"], [19, 2, 1, "", "hparam_names"], [19, 2, 1, "", "initialize_count_table"], [19, 2, 1, "", "initialize_q_table"], [19, 2, 1, "", "q_learning"], [19, 2, 1, "", "sarsa_update"], [19, 2, 1, "", "step_size"], [19, 2, 1, "", "train"], [19, 2, 1, "", "train_sarsa"]], "csle_agents.agents.shapley_iteration": [[20, 0, 0, "-", "shapley_iteration_agent"]], "csle_agents.agents.shapley_iteration.shapley_iteration_agent": [[20, 1, 1, "", "ShapleyIterationAgent"]], "csle_agents.agents.shapley_iteration.shapley_iteration_agent.ShapleyIterationAgent": [[20, 2, 1, "", "auxillary_game"], [20, 2, 1, "", "compute_matrix_game_value"], [20, 2, 1, "", "hparam_names"], [20, 2, 1, "", "shapley_iteration"], [20, 2, 1, "", "si"], [20, 2, 1, "", "train"]], "csle_agents.agents.sondik_vi": [[21, 0, 0, "-", "sondik_vi_agent"]], "csle_agents.agents.sondik_vi.sondik_vi_agent": [[21, 1, 1, "", "SondikVIAgent"]], "csle_agents.agents.sondik_vi.sondik_vi_agent.SondikVIAgent": [[21, 2, 1, "", "check_duplicate"], [21, 2, 1, "", "compute_all_conditional_plans_conditioned_on_a_t"], [21, 2, 1, "", "evaluate_policy"], [21, 2, 1, "", "hparam_names"], [21, 2, 1, "", "prune"], [21, 2, 1, "", "sondik_vi"], [21, 2, 1, "", "sondik_vi_algorithm"], [21, 2, 1, "", "train"]], "csle_agents.agents.t_fp": [[22, 0, 0, "-", "t_fp_agent"]], "csle_agents.agents.t_fp.t_fp_agent": [[22, 1, 1, "", "TFPAgent"]], "csle_agents.agents.t_fp.t_fp_agent.TFPAgent": [[22, 2, 1, "", "attacker_best_response"], [22, 2, 1, "", "compute_avg_metrics"], [22, 2, 1, "", "defender_best_response"], [22, 2, 1, "", "evaluate_attacker_policy"], [22, 2, 1, "", "evaluate_defender_policy"], [22, 2, 1, "", "evaluate_strategy_profile"], [22, 2, 1, "", "exploitability"], [22, 2, 1, "", "get_attacker_experiment_config"], [22, 2, 1, "", "get_defender_experiment_config"], [22, 2, 1, "", "hparam_names"], [22, 2, 1, "", "round_vec"], [22, 2, 1, "", "running_average"], [22, 2, 1, "", "t_fp"], [22, 2, 1, "", "train"], [22, 2, 1, "", "update_metrics"]], "csle_agents.agents.t_spsa": [[23, 0, 0, "-", "t_spsa_agent"]], "csle_agents.agents.t_spsa.t_spsa_agent": [[23, 1, 1, "", "TSPSAAgent"]], "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent": [[23, 2, 1, "", "batch_gradient"], [23, 2, 1, "", "compute_avg_metrics"], [23, 2, 1, "", "estimate_gk"], [23, 2, 1, "", "eval_theta"], [23, 2, 1, "", "get_policy"], [23, 2, 1, "", "hparam_names"], [23, 2, 1, "", "initial_theta"], [23, 2, 1, "", "round_vec"], [23, 2, 1, "", "spsa"], [23, 2, 1, "", "standard_ak"], [23, 2, 1, "", "standard_ck"], [23, 2, 1, "", "standard_deltak"], [23, 2, 1, "", "train"], [23, 2, 1, "", "update_metrics"]], "csle_agents.agents.vi": [[24, 0, 0, "-", "vi_agent"]], "csle_agents.agents.vi.vi_agent": [[24, 1, 1, "", "VIAgent"]], "csle_agents.agents.vi.vi_agent.VIAgent": [[24, 2, 1, "", "create_policy_from_value_function"], [24, 2, 1, "", "evaluate_policy"], [24, 2, 1, "", "hparam_names"], [24, 2, 1, "", "one_step_lookahead"], [24, 2, 1, "", "train"], [24, 2, 1, "", "value_iteration"], [24, 2, 1, "", "vi"]], "csle_agents.common": [[25, 0, 0, "-", "fnn_w_gaussian"], [25, 0, 0, "-", "fnn_w_linear"], [25, 0, 0, "-", "pruning"]], "csle_agents.common.fnn_w_gaussian": [[25, 1, 1, "", "FNNwithGaussian"], [25, 4, 1, "", "test"]], "csle_agents.common.fnn_w_gaussian.FNNwithGaussian": [[25, 2, 1, "", "forward"], [25, 2, 1, "", "get_hidden_activation"], [25, 3, 1, "", "training"]], "csle_agents.common.fnn_w_linear": [[25, 1, 1, "", "FNNwithLinear"], [25, 4, 1, "", "test"]], "csle_agents.common.fnn_w_linear.FNNwithLinear": [[25, 2, 1, "", "forward"], [25, 2, 1, "", "get_hidden_activation"], [25, 3, 1, "", "training"]], "csle_agents.common.pruning": [[25, 4, 1, "", "check_dominance_lp"], [25, 4, 1, "", "check_duplicate"], [25, 4, 1, "", "prune_lower_bound"]], "csle_agents.constants": [[26, 0, 0, "-", "constants"]], "csle_agents.constants.constants": [[26, 1, 1, "", "BAYESIAN_OPTIMIZATION"], [26, 1, 1, "", "COMMON"], [26, 1, 1, "", "CROSS_ENTROPY"], [26, 1, 1, "", "DIFFERENTIAL_EVOLUTION"], [26, 1, 1, "", "DQN"], [26, 1, 1, "", "DYNASEC"], [26, 1, 1, "", "ENV_METRICS"], [26, 1, 1, "", "FICTITIOUS_PLAY"], [26, 1, 1, "", "HSVI"], [26, 1, 1, "", "HSVI_OS_POSG"], [26, 1, 1, "", "KIEFER_WOLFOWITZ"], [26, 1, 1, "", "LP_FOR_NF_GAMES"], [26, 1, 1, "", "PI"], [26, 1, 1, "", "PPO"], [26, 1, 1, "", "Q_LEARNING"], [26, 1, 1, "", "RANDOM_SEARCH"], [26, 1, 1, "", "REINFORCE"], [26, 1, 1, "", "SARSA"], [26, 1, 1, "", "SHAPLEY_ITERATION"], [26, 1, 1, "", "SONDIK_VI"], [26, 1, 1, "", "T_FP"], [26, 1, 1, "", "VI"]], "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION": [[26, 3, 1, "", "L"], [26, 3, 1, "", "N"], [26, 3, 1, "", "PARAMETER_BOUNDS"], [26, 3, 1, "", "PARAMS"], [26, 3, 1, "", "POLICY_TYPE"], [26, 3, 1, "", "STOP_DISTRIBUTION_ATTACKER"], [26, 3, 1, "", "STOP_DISTRIBUTION_DEFENDER"], [26, 3, 1, "", "TARGET"], [26, 3, 1, "", "THETA1"], [26, 3, 1, "", "THETAS"], [26, 3, 1, "", "THRESHOLDS"], [26, 3, 1, "", "UCB"], [26, 3, 1, "", "UCB_KAPPA"], [26, 3, 1, "", "UCB_XI"], [26, 3, 1, "", "UTILITY_FUNCTION"]], "csle_agents.constants.constants.COMMON": [[26, 3, 1, "", "ADAM"], [26, 3, 1, "", "AVERAGE_ATTACKER_RETURN"], [26, 3, 1, "", "AVERAGE_DEFENDER_RETURN"], [26, 3, 1, "", "AVERAGE_HEURISTIC_RETURN"], [26, 3, 1, "", "AVERAGE_RANDOM_RETURN"], [26, 3, 1, "", "AVERAGE_RETURN"], [26, 3, 1, "", "AVERAGE_TIME_HORIZON"], [26, 3, 1, "", "AVERAGE_UPPER_BOUND_RETURN"], [26, 3, 1, "", "BASELINE_PREFIX"], [26, 3, 1, "", "BATCH_SIZE"], [26, 3, 1, "", "CONFIDENCE_INTERVAL"], [26, 3, 1, "", "EVAL_BATCH_SIZE"], [26, 3, 1, "", "EVAL_EVERY"], [26, 3, 1, "", "EVAL_PREFIX"], [26, 3, 1, "", "EXPLOITABILITY"], [26, 3, 1, "", "GAMMA"], [26, 3, 1, "", "L"], [26, 3, 1, "", "LEARNING_RATE"], [26, 3, 1, "", "LEARNING_RATE_DECAY_RATE"], [26, 3, 1, "", "LEARNING_RATE_EXP_DECAY"], [26, 3, 1, "", "MAX_ENV_STEPS"], [26, 3, 1, "", "NUM_CACHED_SIMULATION_TRACES"], [26, 3, 1, "", "NUM_NODES"], [26, 3, 1, "", "NUM_PARALLEL_ENVS"], [26, 3, 1, "", "NUM_TRAINING_TIMESTEPS"], [26, 3, 1, "", "OPTIMIZER"], [26, 3, 1, "", "POLICY_LOSSES"], [26, 3, 1, "", "RUNNING_AVERAGE"], [26, 3, 1, "", "RUNNING_AVERAGE_ATTACKER_RETURN"], [26, 3, 1, "", "RUNNING_AVERAGE_DEFENDER_RETURN"], [26, 3, 1, "", "RUNNING_AVERAGE_EXPLOITABILITY"], [26, 3, 1, "", "RUNNING_AVERAGE_INTRUSION_LENGTH"], [26, 3, 1, "", "RUNNING_AVERAGE_INTRUSION_START"], [26, 3, 1, "", "RUNNING_AVERAGE_RETURN"], [26, 3, 1, "", "RUNNING_AVERAGE_START_POINT_CORRECT"], [26, 3, 1, "", "RUNNING_AVERAGE_TIME_HORIZON"], [26, 3, 1, "", "RUNNING_AVERAGE_WEIGHTED_INTRUSION_PREDICTION_DISTANCE"], [26, 3, 1, "", "RUNTIME"], [26, 3, 1, "", "SAVE_EVERY"], [26, 3, 1, "", "SGD"], [26, 3, 1, "", "START_POINT_CORRECT"], [26, 3, 1, "", "STOPPING_ENVS"], [26, 3, 1, "", "WEIGHTED_INTRUSION_PREDICTION_DISTANCE"]], "csle_agents.constants.constants.CROSS_ENTROPY": [[26, 3, 1, "", "K"], [26, 3, 1, "", "L"], [26, 3, 1, "", "LAMB"], [26, 3, 1, "", "N"], [26, 3, 1, "", "POLICY_TYPE"], [26, 3, 1, "", "STOP_DISTRIBUTION_ATTACKER"], [26, 3, 1, "", "STOP_DISTRIBUTION_DEFENDER"], [26, 3, 1, "", "THETA1"], [26, 3, 1, "", "THETAS"], [26, 3, 1, "", "THRESHOLDS"]], "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION": [[26, 3, 1, "", "BOUNDS"], [26, 3, 1, "", "L"], [26, 3, 1, "", "MUTATE"], [26, 3, 1, "", "N"], [26, 3, 1, "", "POLICY_TYPE"], [26, 3, 1, "", "POPULATION_SIZE"], [26, 3, 1, "", "RECOMBINATION"], [26, 3, 1, "", "STOP_DISTRIBUTION_ATTACKER"], [26, 3, 1, "", "STOP_DISTRIBUTION_DEFENDER"], [26, 3, 1, "", "THETA1"], [26, 3, 1, "", "THETAS"], [26, 3, 1, "", "THRESHOLDS"]], "csle_agents.constants.constants.DQN": [[26, 3, 1, "", "BUFFER_SIZE"], [26, 3, 1, "", "DQN_BATCH_SIZE"], [26, 3, 1, "", "EXPLORATION_FINAL_EPS"], [26, 3, 1, "", "EXPLORATION_FRACTION"], [26, 3, 1, "", "EXPLORATION_INITIAL_EPS"], [26, 3, 1, "", "GRADIENT_STEPS"], [26, 3, 1, "", "LEARNING_STARTS"], [26, 3, 1, "", "MAX_GRAD_NORM"], [26, 3, 1, "", "MLP_POLICY"], [26, 3, 1, "", "N_EPISODES_ROLLOUT"], [26, 3, 1, "", "TARGET_UPDATE_INTERVAL"], [26, 3, 1, "", "TRAIN_FREQ"]], "csle_agents.constants.constants.DYNASEC": [[26, 3, 1, "", "CLIENTS_ARRIVAL_RATE"], [26, 3, 1, "", "EMULATION_MONITOR_SLEEP_TIME"], [26, 3, 1, "", "EMULATION_TRACES_TO_SAVE_W_DATA_COLLECTION_JOB"], [26, 3, 1, "", "INTRUSION_ALERTS_MEAN"], [26, 3, 1, "", "INTRUSION_ALERTS_MEAN_BASELINE"], [26, 3, 1, "", "INTRUSION_START_P"], [26, 3, 1, "", "NO_INTRUSION_ALERTS_MEAN"], [26, 3, 1, "", "NO_INTRUSION_ALERTS_MEAN_BASELINE"], [26, 3, 1, "", "NUM_CLIENTS"], [26, 3, 1, "", "REPLAY_WINDOW_SIZE"], [26, 3, 1, "", "SLEEP_TIME"], [26, 3, 1, "", "STATIC_ATTACKER_TYPE"], [26, 3, 1, "", "TRAINING_EPOCHS"], [26, 3, 1, "", "WARMUP_EPISODES"]], "csle_agents.constants.constants.ENV_METRICS": [[26, 3, 1, "", "ATTACKER_ACTION"], [26, 3, 1, "", "AVERAGE_HEURISTIC_RETURN"], [26, 3, 1, "", "AVERAGE_RANDOM_RETURN"], [26, 3, 1, "", "AVERAGE_UPPER_BOUND_RETURN"], [26, 3, 1, "", "DEFENDER_ACTION"], [26, 3, 1, "", "OBSERVATION"], [26, 3, 1, "", "RETURN"], [26, 3, 1, "", "STATE"], [26, 3, 1, "", "TIME_HORIZON"], [26, 3, 1, "", "TIME_STEP"]], "csle_agents.constants.constants.FICTITIOUS_PLAY": [[26, 3, 1, "", "N"], [26, 3, 1, "", "PAYOFF_MATRIX"], [26, 3, 1, "", "PLAYER_1_PRIOR"], [26, 3, 1, "", "PLAYER_2_PRIOR"]], "csle_agents.constants.constants.HSVI": [[26, 3, 1, "", "ACTION_SPACE"], [26, 3, 1, "", "EPSILON"], [26, 3, 1, "", "INITIAL_BELIEF"], [26, 3, 1, "", "INITIAL_BELIEF_VALUES"], [26, 3, 1, "", "LB_SIZE"], [26, 3, 1, "", "LB_SIZES"], [26, 3, 1, "", "NUMBER_OF_SIMULATIONS"], [26, 3, 1, "", "OBSERVATION_SPACE"], [26, 3, 1, "", "OBSERVATION_TENSOR"], [26, 3, 1, "", "PRUNE_FREQUENCY"], [26, 3, 1, "", "REWARD_TENSOR"], [26, 3, 1, "", "SIMULATE_HORIZON"], [26, 3, 1, "", "SIMULATION_FREQUENCY"], [26, 3, 1, "", "STATE_SPACE"], [26, 3, 1, "", "TRANSITION_TENSOR"], [26, 3, 1, "", "UB_SIZE"], [26, 3, 1, "", "UB_SIZES"], [26, 3, 1, "", "USE_LP"], [26, 3, 1, "", "WIDTH"], [26, 3, 1, "", "WIDTHS"]], "csle_agents.constants.constants.HSVI_OS_POSG": [[26, 3, 1, "", "ACTION_SPACE_PLAYER_1"], [26, 3, 1, "", "ACTION_SPACE_PLAYER_2"], [26, 3, 1, "", "EPSILON"], [26, 3, 1, "", "EXCESSES"], [26, 3, 1, "", "INITIAL_BELIEF"], [26, 3, 1, "", "N"], [26, 3, 1, "", "OBSERVATION_FUNCTION"], [26, 3, 1, "", "OBSERVATION_SPACE"], [26, 3, 1, "", "PRUNE_FREQUENCY"], [26, 3, 1, "", "REWARD_TENSOR"], [26, 3, 1, "", "STATE_SPACE"], [26, 3, 1, "", "TRANSITION_TENSOR"], [26, 3, 1, "", "WIDTHS"]], "csle_agents.constants.constants.KIEFER_WOLFOWITZ": [[26, 3, 1, "", "DELTA"], [26, 3, 1, "", "GRADIENT_BATCH_SIZE"], [26, 3, 1, "", "INITIAL_ALPHA"], [26, 3, 1, "", "L"], [26, 3, 1, "", "N"], [26, 3, 1, "", "POLICY_TYPE"], [26, 3, 1, "", "STOP_DISTRIBUTION_ATTACKER"], [26, 3, 1, "", "STOP_DISTRIBUTION_DEFENDER"], [26, 3, 1, "", "THETA1"], [26, 3, 1, "", "THETAS"], [26, 3, 1, "", "THRESHOLDS"]], "csle_agents.constants.constants.LP_FOR_NF_GAMES": [[26, 3, 1, "", "ACTION_SPACE_PLAYER_1"], [26, 3, 1, "", "ACTION_SPACE_PLAYER_2"], [26, 3, 1, "", "N"], [26, 3, 1, "", "PAYOFF_MATRIX"]], "csle_agents.constants.constants.PI": [[26, 3, 1, "", "INITIAL_POLICY"], [26, 3, 1, "", "N"], [26, 3, 1, "", "NUM_ACTIONS"], [26, 3, 1, "", "NUM_STATES"], [26, 3, 1, "", "REWARD_TENSOR"], [26, 3, 1, "", "TRANSITION_TENSOR"]], "csle_agents.constants.constants.PPO": [[26, 3, 1, "", "CLIP_RANGE"], [26, 3, 1, "", "CLIP_RANGE_VF"], [26, 3, 1, "", "ENT_COEF"], [26, 3, 1, "", "GAE_LAMBDA"], [26, 3, 1, "", "MAX_GRAD_NORM"], [26, 3, 1, "", "MLP_POLICY"], [26, 3, 1, "", "STEPS_BETWEEN_UPDATES"], [26, 3, 1, "", "TARGET_KL"], [26, 3, 1, "", "VF_COEF"]], "csle_agents.constants.constants.Q_LEARNING": [[26, 3, 1, "", "A"], [26, 3, 1, "", "EPSILON"], [26, 3, 1, "", "INITIAL_STATE_VALUES"], [26, 3, 1, "", "N"], [26, 3, 1, "", "S"]], "csle_agents.constants.constants.RANDOM_SEARCH": [[26, 3, 1, "", "DELTA"], [26, 3, 1, "", "L"], [26, 3, 1, "", "N"], [26, 3, 1, "", "POLICY_TYPE"], [26, 3, 1, "", "STOP_DISTRIBUTION_ATTACKER"], [26, 3, 1, "", "STOP_DISTRIBUTION_DEFENDER"], [26, 3, 1, "", "THETA1"], [26, 3, 1, "", "THETAS"], [26, 3, 1, "", "THRESHOLDS"]], "csle_agents.constants.constants.REINFORCE": [[26, 3, 1, "", "CLIP_GRADIENT"], [26, 3, 1, "", "GRADIENT_BATCH_SIZE"], [26, 3, 1, "", "N"]], "csle_agents.constants.constants.SARSA": [[26, 3, 1, "", "A"], [26, 3, 1, "", "EPSILON"], [26, 3, 1, "", "INITIAL_STATE_VALUES"], [26, 3, 1, "", "N"], [26, 3, 1, "", "S"]], "csle_agents.constants.constants.SHAPLEY_ITERATION": [[26, 3, 1, "", "ACTION_SPACE_PLAYER_1"], [26, 3, 1, "", "ACTION_SPACE_PLAYER_2"], [26, 3, 1, "", "DELTA"], [26, 3, 1, "", "N"], [26, 3, 1, "", "REWARD_TENSOR"], [26, 3, 1, "", "STATE_SPACE"], [26, 3, 1, "", "TRANSITION_TENSOR"]], "csle_agents.constants.constants.SONDIK_VI": [[26, 3, 1, "", "ACTION_SPACE"], [26, 3, 1, "", "INITIAL_BELIEF"], [26, 3, 1, "", "INITIAL_BELIEF_VALUES"], [26, 3, 1, "", "NUM_ALPHA_VECTORS"], [26, 3, 1, "", "OBSERVATION_SPACE"], [26, 3, 1, "", "OBSERVATION_TENSOR"], [26, 3, 1, "", "PLANNING_HORIZON"], [26, 3, 1, "", "REWARD_TENSOR"], [26, 3, 1, "", "STATE_SPACE"], [26, 3, 1, "", "TRANSITION_TENSOR"], [26, 3, 1, "", "USE_PRUNING"]], "csle_agents.constants.constants.T_FP": [[26, 3, 1, "", "ATTACKER_THRESHOLDS"], [26, 3, 1, "", "AVERAGE_BEST_RESPONSE_ATTACKER_RETURN"], [26, 3, 1, "", "AVERAGE_BEST_RESPONSE_DEFENDER_RETURN"], [26, 3, 1, "", "BEST_RESPONSE_EVALUATION_ITERATIONS"], [26, 3, 1, "", "DEFENDER_THRESHOLDS"], [26, 3, 1, "", "EQUILIBRIUM_STRATEGIES_EVALUATION_ITERATIONS"], [26, 3, 1, "", "N_2"], [26, 3, 1, "", "RUNNING_AVERAGE_BEST_RESPONSE_ATTACKER_RETURN"], [26, 3, 1, "", "RUNNING_AVERAGE_BEST_RESPONSE_DEFENDER_RETURN"], [26, 3, 1, "", "THETA1_ATTACKER"], [26, 3, 1, "", "THETA1_DEFENDER"]], "csle_agents.constants.constants.VI": [[26, 3, 1, "", "DELTA"], [26, 3, 1, "", "NUM_ACTIONS"], [26, 3, 1, "", "NUM_STATES"], [26, 3, 1, "", "REWARD_TENSOR"], [26, 3, 1, "", "THETA"], [26, 3, 1, "", "TRANSITION_TENSOR"]], "csle_agents.job_controllers": [[27, 0, 0, "-", "training_job_manager"]], "csle_agents.job_controllers.training_job_manager": [[27, 1, 1, "", "TrainingJobManager"]], "csle_agents.job_controllers.training_job_manager.TrainingJobManager": [[27, 2, 1, "", "run_training_job"], [27, 2, 1, "", "start_training_job_in_background"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:attribute", "4": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "attribute", "Python attribute"], "4": ["py", "function", "Python function"]}, "titleterms": {"csle_ag": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], "packag": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], "subpackag": [0, 1, 28], "modul": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], "content": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], "agent": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "base": 2, "submodul": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27], "base_ag": 2, "bayes_opt": 3, "bayes_opt_ag": [3, 4], "cross_entropi": 5, "cross_entropy_ag": 5, "differential_evolut": 6, "differential_evolution_ag": 6, "dqn": 7, "dqn_agent": 7, "dynasec": 8, "dynasec_ag": 8, "fp": 9, "fictitious_play_ag": 9, "hsvi": 10, "hsvi_ag": 10, "hsvi_os_posg": 11, "hsvi_os_posg_ag": 11, "kiefer_wolfowitz": 12, "kiefer_wolfowitz_ag": 12, "lp_nf": 13, "linear_programming_normal_form_game_ag": 13, "pi": 14, "pi_ag": 14, "ppo": 15, "ppo_ag": 15, "q_learn": 16, "q_learning_ag": 16, "random_search": 17, "random_search_ag": 17, "reinforc": 18, "reinforce_ag": 18, "sarsa": 19, "sarsa_ag": 19, "shapley_iter": 20, "shapley_iteration_ag": 20, "sondik_vi": 21, "sondik_vi_ag": 21, "t_fp": 22, "t_fp_agent": 22, "t_spsa": 23, "t_spsa_ag": 23, "vi": 24, "vi_ag": 24, "common": 25, "actor_critic_net": 25, "fnn_w_gaussian": 25, "fnn_w_linear": 25, "prune": 25, "constant": 26, "job_control": 27, "training_job_manag": 27, "bayesian_optim": 4}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"csle_agents package": [[0, "csle-agents-package"], [28, "csle-agents-package"]], "Subpackages": [[0, "subpackages"], [28, "subpackages"], [1, "subpackages"]], "Module contents": [[0, "module-csle_agents"], [28, "module-csle_agents"], [1, "module-csle_agents.agents"], [2, "module-csle_agents.agents.base"], [3, "module-csle_agents.agents.bayes_opt"], [4, "module-csle_agents.agents.bayesian_optimization"], [5, "module-csle_agents.agents.cross_entropy"], [6, "module-csle_agents.agents.differential_evolution"], [7, "module-csle_agents.agents.dqn"], [8, "module-csle_agents.agents.dynasec"], [9, "module-csle_agents.agents.fp"], [10, "module-csle_agents.agents.hsvi"], [11, "module-csle_agents.agents.hsvi_os_posg"], [12, "module-csle_agents.agents.kiefer_wolfowitz"], [13, "module-csle_agents.agents.lp_nf"], [14, "module-csle_agents.agents.pi"], [15, "module-csle_agents.agents.ppo"], [16, "module-csle_agents.agents.q_learning"], [17, "module-csle_agents.agents.random_search"], [18, "module-csle_agents.agents.reinforce"], [19, "module-csle_agents.agents.sarsa"], [20, "module-csle_agents.agents.shapley_iteration"], [21, "module-csle_agents.agents.sondik_vi"], [22, "module-csle_agents.agents.t_fp"], [23, "module-csle_agents.agents.t_spsa"], [24, "module-csle_agents.agents.vi"], [25, "module-csle_agents.common"], [26, "module-csle_agents.constants"], [27, "module-csle_agents.job_controllers"]], "csle_agents": [[29, "csle-agents"]], "csle_agents.agents package": [[1, "csle-agents-agents-package"]], "csle_agents.agents.base package": [[2, "csle-agents-agents-base-package"]], "Submodules": [[2, "submodules"], [3, "submodules"], [4, "submodules"], [5, "submodules"], [6, "submodules"], [7, "submodules"], [8, "submodules"], [9, "submodules"], [10, "submodules"], [11, "submodules"], [12, "submodules"], [13, "submodules"], [14, "submodules"], [15, "submodules"], [16, "submodules"], [17, "submodules"], [18, "submodules"], [19, "submodules"], [20, "submodules"], [21, "submodules"], [22, "submodules"], [23, "submodules"], [24, "submodules"], [25, "submodules"], [26, "submodules"], [27, "submodules"]], "csle_agents.agents.base.base_agent module": [[2, "module-csle_agents.agents.base.base_agent"]], "csle_agents.agents.bayes_opt package": [[3, "csle-agents-agents-bayes-opt-package"]], "csle_agents.agents.bayes_opt.bayes_opt_agent module": [[3, "csle-agents-agents-bayes-opt-bayes-opt-agent-module"]], "csle_agents.agents.bayesian_optimization package": [[4, "csle-agents-agents-bayesian-optimization-package"]], "csle_agents.agents.bayesian_optimization.bayes_opt_agent module": [[4, "module-csle_agents.agents.bayesian_optimization.bayes_opt_agent"]], "csle_agents.agents.cross_entropy package": [[5, "csle-agents-agents-cross-entropy-package"]], "csle_agents.agents.cross_entropy.cross_entropy_agent module": [[5, "module-csle_agents.agents.cross_entropy.cross_entropy_agent"]], "csle_agents.agents.differential_evolution package": [[6, "csle-agents-agents-differential-evolution-package"]], "csle_agents.agents.differential_evolution.differential_evolution_agent module": [[6, "module-csle_agents.agents.differential_evolution.differential_evolution_agent"]], "csle_agents.agents.dqn package": [[7, "csle-agents-agents-dqn-package"]], "csle_agents.agents.dqn.dqn_agent module": [[7, "module-csle_agents.agents.dqn.dqn_agent"]], "csle_agents.agents.dynasec package": [[8, "csle-agents-agents-dynasec-package"]], "csle_agents.agents.dynasec.dynasec_agent module": [[8, "module-csle_agents.agents.dynasec.dynasec_agent"]], "csle_agents.agents.fp package": [[9, "csle-agents-agents-fp-package"]], "csle_agents.agents.fp.fictitious_play_agent module": [[9, "module-csle_agents.agents.fp.fictitious_play_agent"]], "csle_agents.agents.hsvi package": [[10, "csle-agents-agents-hsvi-package"]], "csle_agents.agents.hsvi.hsvi_agent module": [[10, "module-csle_agents.agents.hsvi.hsvi_agent"]], "csle_agents.agents.hsvi_os_posg package": [[11, "csle-agents-agents-hsvi-os-posg-package"]], "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent module": [[11, "module-csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent"]], "csle_agents.agents.kiefer_wolfowitz package": [[12, "csle-agents-agents-kiefer-wolfowitz-package"]], "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent module": [[12, "module-csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent"]], "csle_agents.agents.lp_nf package": [[13, "csle-agents-agents-lp-nf-package"]], "csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent module": [[13, "module-csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent"]], "csle_agents.agents.pi package": [[14, "csle-agents-agents-pi-package"]], "csle_agents.agents.pi.pi_agent module": [[14, "module-csle_agents.agents.pi.pi_agent"]], "csle_agents.agents.ppo package": [[15, "csle-agents-agents-ppo-package"]], "csle_agents.agents.ppo.ppo_agent module": [[15, "module-csle_agents.agents.ppo.ppo_agent"]], "csle_agents.agents.q_learning package": [[16, "csle-agents-agents-q-learning-package"]], "csle_agents.agents.q_learning.q_learning_agent module": [[16, "module-csle_agents.agents.q_learning.q_learning_agent"]], "csle_agents.agents.random_search package": [[17, "csle-agents-agents-random-search-package"]], "csle_agents.agents.random_search.random_search_agent module": [[17, "module-csle_agents.agents.random_search.random_search_agent"]], "csle_agents.agents.reinforce package": [[18, "csle-agents-agents-reinforce-package"]], "csle_agents.agents.reinforce.reinforce_agent module": [[18, "module-csle_agents.agents.reinforce.reinforce_agent"]], "csle_agents.agents.sarsa package": [[19, "csle-agents-agents-sarsa-package"]], "csle_agents.agents.sarsa.sarsa_agent module": [[19, "module-csle_agents.agents.sarsa.sarsa_agent"]], "csle_agents.agents.shapley_iteration package": [[20, "csle-agents-agents-shapley-iteration-package"]], "csle_agents.agents.shapley_iteration.shapley_iteration_agent module": [[20, "module-csle_agents.agents.shapley_iteration.shapley_iteration_agent"]], "csle_agents.agents.sondik_vi package": [[21, "csle-agents-agents-sondik-vi-package"]], "csle_agents.agents.sondik_vi.sondik_vi_agent module": [[21, "module-csle_agents.agents.sondik_vi.sondik_vi_agent"]], "csle_agents.agents.t_fp package": [[22, "csle-agents-agents-t-fp-package"]], "csle_agents.agents.t_fp.t_fp_agent module": [[22, "module-csle_agents.agents.t_fp.t_fp_agent"]], "csle_agents.agents.t_spsa package": [[23, "csle-agents-agents-t-spsa-package"]], "csle_agents.agents.t_spsa.t_spsa_agent module": [[23, "module-csle_agents.agents.t_spsa.t_spsa_agent"]], "csle_agents.agents.vi package": [[24, "csle-agents-agents-vi-package"]], "csle_agents.agents.vi.vi_agent module": [[24, "module-csle_agents.agents.vi.vi_agent"]], "csle_agents.common package": [[25, "csle-agents-common-package"]], "csle_agents.common.actor_critic_net module": [[25, "csle-agents-common-actor-critic-net-module"]], "csle_agents.common.fnn_w_gaussian module": [[25, "module-csle_agents.common.fnn_w_gaussian"]], "csle_agents.common.fnn_w_linear module": [[25, "module-csle_agents.common.fnn_w_linear"]], "csle_agents.common.pruning module": [[25, "module-csle_agents.common.pruning"]], "csle_agents.constants package": [[26, "csle-agents-constants-package"]], "csle_agents.constants.constants module": [[26, "module-csle_agents.constants.constants"]], "csle_agents.job_controllers package": [[27, "csle-agents-job-controllers-package"]], "csle_agents.job_controllers.training_job_manager module": [[27, "module-csle_agents.job_controllers.training_job_manager"]]}, "indexentries": {"csle_agents": [[0, "module-csle_agents"], [28, "module-csle_agents"]], "module": [[0, "module-csle_agents"], [1, "module-csle_agents.agents"], [2, "module-csle_agents.agents.base"], [2, "module-csle_agents.agents.base.base_agent"], [3, "module-csle_agents.agents.bayes_opt"], [4, "module-csle_agents.agents.bayesian_optimization"], [4, "module-csle_agents.agents.bayesian_optimization.bayes_opt_agent"], [5, "module-csle_agents.agents.cross_entropy"], [5, "module-csle_agents.agents.cross_entropy.cross_entropy_agent"], [6, "module-csle_agents.agents.differential_evolution"], [6, "module-csle_agents.agents.differential_evolution.differential_evolution_agent"], [7, "module-csle_agents.agents.dqn"], [7, "module-csle_agents.agents.dqn.dqn_agent"], [8, "module-csle_agents.agents.dynasec"], [8, "module-csle_agents.agents.dynasec.dynasec_agent"], [9, "module-csle_agents.agents.fp"], [9, "module-csle_agents.agents.fp.fictitious_play_agent"], [10, "module-csle_agents.agents.hsvi"], [10, "module-csle_agents.agents.hsvi.hsvi_agent"], [11, "module-csle_agents.agents.hsvi_os_posg"], [11, "module-csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent"], [12, "module-csle_agents.agents.kiefer_wolfowitz"], [12, "module-csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent"], [13, "module-csle_agents.agents.lp_nf"], [13, "module-csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent"], [14, "module-csle_agents.agents.pi"], [14, "module-csle_agents.agents.pi.pi_agent"], [15, "module-csle_agents.agents.ppo"], [15, "module-csle_agents.agents.ppo.ppo_agent"], [16, "module-csle_agents.agents.q_learning"], [16, "module-csle_agents.agents.q_learning.q_learning_agent"], [17, "module-csle_agents.agents.random_search"], [17, "module-csle_agents.agents.random_search.random_search_agent"], [18, "module-csle_agents.agents.reinforce"], [18, "module-csle_agents.agents.reinforce.reinforce_agent"], [19, "module-csle_agents.agents.sarsa"], [19, "module-csle_agents.agents.sarsa.sarsa_agent"], [20, "module-csle_agents.agents.shapley_iteration"], [20, "module-csle_agents.agents.shapley_iteration.shapley_iteration_agent"], [21, "module-csle_agents.agents.sondik_vi"], [21, "module-csle_agents.agents.sondik_vi.sondik_vi_agent"], [22, "module-csle_agents.agents.t_fp"], [22, "module-csle_agents.agents.t_fp.t_fp_agent"], [23, "module-csle_agents.agents.t_spsa"], [23, "module-csle_agents.agents.t_spsa.t_spsa_agent"], [24, "module-csle_agents.agents.vi"], [24, "module-csle_agents.agents.vi.vi_agent"], [25, "module-csle_agents.common"], [25, "module-csle_agents.common.fnn_w_gaussian"], [25, "module-csle_agents.common.fnn_w_linear"], [25, "module-csle_agents.common.pruning"], [26, "module-csle_agents.constants"], [26, "module-csle_agents.constants.constants"], [27, "module-csle_agents.job_controllers"], [27, "module-csle_agents.job_controllers.training_job_manager"], [28, "module-csle_agents"]], "csle_agents.agents": [[1, "module-csle_agents.agents"]], "baseagent (class in csle_agents.agents.base.base_agent)": [[2, "csle_agents.agents.base.base_agent.BaseAgent"]], "csle_agents.agents.base": [[2, "module-csle_agents.agents.base"]], "csle_agents.agents.base.base_agent": [[2, "module-csle_agents.agents.base.base_agent"]], "hparam_names() (csle_agents.agents.base.base_agent.baseagent method)": [[2, "csle_agents.agents.base.base_agent.BaseAgent.hparam_names"]], "train() (csle_agents.agents.base.base_agent.baseagent method)": [[2, "csle_agents.agents.base.base_agent.BaseAgent.train"]], "csle_agents.agents.bayes_opt": [[3, "module-csle_agents.agents.bayes_opt"]], "bayesoptagent (class in csle_agents.agents.bayesian_optimization.bayes_opt_agent)": [[4, "csle_agents.agents.bayesian_optimization.bayes_opt_agent.BayesOptAgent"]], "bayesian_optimization() (csle_agents.agents.bayesian_optimization.bayes_opt_agent.bayesoptagent method)": [[4, "csle_agents.agents.bayesian_optimization.bayes_opt_agent.BayesOptAgent.bayesian_optimization"]], "compute_avg_metrics() (csle_agents.agents.bayesian_optimization.bayes_opt_agent.bayesoptagent static method)": [[4, "csle_agents.agents.bayesian_optimization.bayes_opt_agent.BayesOptAgent.compute_avg_metrics"]], "csle_agents.agents.bayesian_optimization": [[4, "module-csle_agents.agents.bayesian_optimization"]], "csle_agents.agents.bayesian_optimization.bayes_opt_agent": [[4, "module-csle_agents.agents.bayesian_optimization.bayes_opt_agent"]], "eval_theta() (csle_agents.agents.bayesian_optimization.bayes_opt_agent.bayesoptagent method)": [[4, "csle_agents.agents.bayesian_optimization.bayes_opt_agent.BayesOptAgent.eval_theta"]], "get_policy() (csle_agents.agents.bayesian_optimization.bayes_opt_agent.bayesoptagent method)": [[4, "csle_agents.agents.bayesian_optimization.bayes_opt_agent.BayesOptAgent.get_policy"]], "get_theta_vector_from_param_dict() (csle_agents.agents.bayesian_optimization.bayes_opt_agent.bayesoptagent static method)": [[4, "csle_agents.agents.bayesian_optimization.bayes_opt_agent.BayesOptAgent.get_theta_vector_from_param_dict"]], "hparam_names() (csle_agents.agents.bayesian_optimization.bayes_opt_agent.bayesoptagent method)": [[4, "csle_agents.agents.bayesian_optimization.bayes_opt_agent.BayesOptAgent.hparam_names"]], "initial_theta() (csle_agents.agents.bayesian_optimization.bayes_opt_agent.bayesoptagent static method)": [[4, "csle_agents.agents.bayesian_optimization.bayes_opt_agent.BayesOptAgent.initial_theta"]], "round_vec() (csle_agents.agents.bayesian_optimization.bayes_opt_agent.bayesoptagent static method)": [[4, "csle_agents.agents.bayesian_optimization.bayes_opt_agent.BayesOptAgent.round_vec"]], "train() (csle_agents.agents.bayesian_optimization.bayes_opt_agent.bayesoptagent method)": [[4, "csle_agents.agents.bayesian_optimization.bayes_opt_agent.BayesOptAgent.train"]], "update_metrics() (csle_agents.agents.bayesian_optimization.bayes_opt_agent.bayesoptagent static method)": [[4, "csle_agents.agents.bayesian_optimization.bayes_opt_agent.BayesOptAgent.update_metrics"]], "crossentropyagent (class in csle_agents.agents.cross_entropy.cross_entropy_agent)": [[5, "csle_agents.agents.cross_entropy.cross_entropy_agent.CrossEntropyAgent"]], "compute_avg_metrics() (csle_agents.agents.cross_entropy.cross_entropy_agent.crossentropyagent static method)": [[5, "csle_agents.agents.cross_entropy.cross_entropy_agent.CrossEntropyAgent.compute_avg_metrics"]], "cross_entropy() (csle_agents.agents.cross_entropy.cross_entropy_agent.crossentropyagent method)": [[5, "csle_agents.agents.cross_entropy.cross_entropy_agent.CrossEntropyAgent.cross_entropy"]], "csle_agents.agents.cross_entropy": [[5, "module-csle_agents.agents.cross_entropy"]], "csle_agents.agents.cross_entropy.cross_entropy_agent": [[5, "module-csle_agents.agents.cross_entropy.cross_entropy_agent"]], "eval_theta() (csle_agents.agents.cross_entropy.cross_entropy_agent.crossentropyagent method)": [[5, "csle_agents.agents.cross_entropy.cross_entropy_agent.CrossEntropyAgent.eval_theta"]], "get_policy() (csle_agents.agents.cross_entropy.cross_entropy_agent.crossentropyagent method)": [[5, "csle_agents.agents.cross_entropy.cross_entropy_agent.CrossEntropyAgent.get_policy"]], "hparam_names() (csle_agents.agents.cross_entropy.cross_entropy_agent.crossentropyagent method)": [[5, "csle_agents.agents.cross_entropy.cross_entropy_agent.CrossEntropyAgent.hparam_names"]], "initial_theta() (csle_agents.agents.cross_entropy.cross_entropy_agent.crossentropyagent static method)": [[5, "csle_agents.agents.cross_entropy.cross_entropy_agent.CrossEntropyAgent.initial_theta"]], "round_vec() (csle_agents.agents.cross_entropy.cross_entropy_agent.crossentropyagent static method)": [[5, "csle_agents.agents.cross_entropy.cross_entropy_agent.CrossEntropyAgent.round_vec"]], "train() (csle_agents.agents.cross_entropy.cross_entropy_agent.crossentropyagent method)": [[5, "csle_agents.agents.cross_entropy.cross_entropy_agent.CrossEntropyAgent.train"]], "update_metrics() (csle_agents.agents.cross_entropy.cross_entropy_agent.crossentropyagent static method)": [[5, "csle_agents.agents.cross_entropy.cross_entropy_agent.CrossEntropyAgent.update_metrics"]], "differentialevolutionagent (class in csle_agents.agents.differential_evolution.differential_evolution_agent)": [[6, "csle_agents.agents.differential_evolution.differential_evolution_agent.DifferentialEvolutionAgent"]], "compute_avg_metrics() (csle_agents.agents.differential_evolution.differential_evolution_agent.differentialevolutionagent static method)": [[6, "csle_agents.agents.differential_evolution.differential_evolution_agent.DifferentialEvolutionAgent.compute_avg_metrics"]], "csle_agents.agents.differential_evolution": [[6, "module-csle_agents.agents.differential_evolution"]], "csle_agents.agents.differential_evolution.differential_evolution_agent": [[6, "module-csle_agents.agents.differential_evolution.differential_evolution_agent"]], "differential_evolution() (csle_agents.agents.differential_evolution.differential_evolution_agent.differentialevolutionagent method)": [[6, "csle_agents.agents.differential_evolution.differential_evolution_agent.DifferentialEvolutionAgent.differential_evolution"]], "ensure_bounds() (csle_agents.agents.differential_evolution.differential_evolution_agent.differentialevolutionagent method)": [[6, "csle_agents.agents.differential_evolution.differential_evolution_agent.DifferentialEvolutionAgent.ensure_bounds"]], "eval_theta() (csle_agents.agents.differential_evolution.differential_evolution_agent.differentialevolutionagent method)": [[6, "csle_agents.agents.differential_evolution.differential_evolution_agent.DifferentialEvolutionAgent.eval_theta"]], "get_policy() (csle_agents.agents.differential_evolution.differential_evolution_agent.differentialevolutionagent method)": [[6, "csle_agents.agents.differential_evolution.differential_evolution_agent.DifferentialEvolutionAgent.get_policy"]], "hparam_names() (csle_agents.agents.differential_evolution.differential_evolution_agent.differentialevolutionagent method)": [[6, "csle_agents.agents.differential_evolution.differential_evolution_agent.DifferentialEvolutionAgent.hparam_names"]], "initial_theta() (csle_agents.agents.differential_evolution.differential_evolution_agent.differentialevolutionagent static method)": [[6, "csle_agents.agents.differential_evolution.differential_evolution_agent.DifferentialEvolutionAgent.initial_theta"]], "round_vec() (csle_agents.agents.differential_evolution.differential_evolution_agent.differentialevolutionagent static method)": [[6, "csle_agents.agents.differential_evolution.differential_evolution_agent.DifferentialEvolutionAgent.round_vec"]], "train() (csle_agents.agents.differential_evolution.differential_evolution_agent.differentialevolutionagent method)": [[6, "csle_agents.agents.differential_evolution.differential_evolution_agent.DifferentialEvolutionAgent.train"]], "update_metrics() (csle_agents.agents.differential_evolution.differential_evolution_agent.differentialevolutionagent static method)": [[6, "csle_agents.agents.differential_evolution.differential_evolution_agent.DifferentialEvolutionAgent.update_metrics"]], "dqnagent (class in csle_agents.agents.dqn.dqn_agent)": [[7, "csle_agents.agents.dqn.dqn_agent.DQNAgent"]], "dqntrainingcallback (class in csle_agents.agents.dqn.dqn_agent)": [[7, "csle_agents.agents.dqn.dqn_agent.DQNTrainingCallback"]], "csle_agents.agents.dqn": [[7, "module-csle_agents.agents.dqn"]], "csle_agents.agents.dqn.dqn_agent": [[7, "module-csle_agents.agents.dqn.dqn_agent"]], "hparam_names() (csle_agents.agents.dqn.dqn_agent.dqnagent method)": [[7, "csle_agents.agents.dqn.dqn_agent.DQNAgent.hparam_names"]], "logger (csle_agents.agents.dqn.dqn_agent.dqntrainingcallback attribute)": [[7, "csle_agents.agents.dqn.dqn_agent.DQNTrainingCallback.logger"]], "model (csle_agents.agents.dqn.dqn_agent.dqntrainingcallback attribute)": [[7, "csle_agents.agents.dqn.dqn_agent.DQNTrainingCallback.model"]], "train() (csle_agents.agents.dqn.dqn_agent.dqnagent method)": [[7, "csle_agents.agents.dqn.dqn_agent.DQNAgent.train"]], "datacollectorprocess (class in csle_agents.agents.dynasec.dynasec_agent)": [[8, "csle_agents.agents.dynasec.dynasec_agent.DataCollectorProcess"]], "dynasecagent (class in csle_agents.agents.dynasec.dynasec_agent)": [[8, "csle_agents.agents.dynasec.dynasec_agent.DynaSecAgent"]], "emulationmonitorthread (class in csle_agents.agents.dynasec.dynasec_agent)": [[8, "csle_agents.agents.dynasec.dynasec_agent.EmulationMonitorThread"]], "emulationstatisticsthread (class in csle_agents.agents.dynasec.dynasec_agent)": [[8, "csle_agents.agents.dynasec.dynasec_agent.EmulationStatisticsThread"]], "policyevaluationthread (class in csle_agents.agents.dynasec.dynasec_agent)": [[8, "csle_agents.agents.dynasec.dynasec_agent.PolicyEvaluationThread"]], "policyoptimizationprocess (class in csle_agents.agents.dynasec.dynasec_agent)": [[8, "csle_agents.agents.dynasec.dynasec_agent.PolicyOptimizationProcess"]], "systemidentificationprocess (class in csle_agents.agents.dynasec.dynasec_agent)": [[8, "csle_agents.agents.dynasec.dynasec_agent.SystemIdentificationProcess"]], "csle_agents.agents.dynasec": [[8, "module-csle_agents.agents.dynasec"]], "csle_agents.agents.dynasec.dynasec_agent": [[8, "module-csle_agents.agents.dynasec.dynasec_agent"]], "eval_traces() (csle_agents.agents.dynasec.dynasec_agent.policyevaluationthread method)": [[8, "csle_agents.agents.dynasec.dynasec_agent.PolicyEvaluationThread.eval_traces"]], "get_z_from_system_model() (csle_agents.agents.dynasec.dynasec_agent.dynasecagent static method)": [[8, "csle_agents.agents.dynasec.dynasec_agent.DynaSecAgent.get_Z_from_system_model"]], "get_spsa_experiment_config() (csle_agents.agents.dynasec.dynasec_agent.dynasecagent method)": [[8, "csle_agents.agents.dynasec.dynasec_agent.DynaSecAgent.get_spsa_experiment_config"]], "hparam_names() (csle_agents.agents.dynasec.dynasec_agent.dynasecagent method)": [[8, "csle_agents.agents.dynasec.dynasec_agent.DynaSecAgent.hparam_names"]], "mean() (csle_agents.agents.dynasec.dynasec_agent.dynasecagent static method)": [[8, "csle_agents.agents.dynasec.dynasec_agent.DynaSecAgent.mean"]], "record_metrics() (csle_agents.agents.dynasec.dynasec_agent.dynasecagent method)": [[8, "csle_agents.agents.dynasec.dynasec_agent.DynaSecAgent.record_metrics"]], "record_metrics() (csle_agents.agents.dynasec.dynasec_agent.policyevaluationthread method)": [[8, "csle_agents.agents.dynasec.dynasec_agent.PolicyEvaluationThread.record_metrics"]], "run() (csle_agents.agents.dynasec.dynasec_agent.datacollectorprocess method)": [[8, "csle_agents.agents.dynasec.dynasec_agent.DataCollectorProcess.run"]], "run() (csle_agents.agents.dynasec.dynasec_agent.emulationmonitorthread method)": [[8, "csle_agents.agents.dynasec.dynasec_agent.EmulationMonitorThread.run"]], "run() (csle_agents.agents.dynasec.dynasec_agent.emulationstatisticsthread method)": [[8, "csle_agents.agents.dynasec.dynasec_agent.EmulationStatisticsThread.run"]], "run() (csle_agents.agents.dynasec.dynasec_agent.policyevaluationthread method)": [[8, "csle_agents.agents.dynasec.dynasec_agent.PolicyEvaluationThread.run"]], "run() (csle_agents.agents.dynasec.dynasec_agent.policyoptimizationprocess method)": [[8, "csle_agents.agents.dynasec.dynasec_agent.PolicyOptimizationProcess.run"]], "run() (csle_agents.agents.dynasec.dynasec_agent.systemidentificationprocess method)": [[8, "csle_agents.agents.dynasec.dynasec_agent.SystemIdentificationProcess.run"]], "train() (csle_agents.agents.dynasec.dynasec_agent.dynasecagent method)": [[8, "csle_agents.agents.dynasec.dynasec_agent.DynaSecAgent.train"]], "fictitiousplayagent (class in csle_agents.agents.fp.fictitious_play_agent)": [[9, "csle_agents.agents.fp.fictitious_play_agent.FictitiousPlayAgent"]], "best_response() (csle_agents.agents.fp.fictitious_play_agent.fictitiousplayagent method)": [[9, "csle_agents.agents.fp.fictitious_play_agent.FictitiousPlayAgent.best_response"]], "compute_avg_metrics() (csle_agents.agents.fp.fictitious_play_agent.fictitiousplayagent static method)": [[9, "csle_agents.agents.fp.fictitious_play_agent.FictitiousPlayAgent.compute_avg_metrics"]], "compute_empirical_strategy() (csle_agents.agents.fp.fictitious_play_agent.fictitiousplayagent method)": [[9, "csle_agents.agents.fp.fictitious_play_agent.FictitiousPlayAgent.compute_empirical_strategy"]], "csle_agents.agents.fp": [[9, "module-csle_agents.agents.fp"]], "csle_agents.agents.fp.fictitious_play_agent": [[9, "module-csle_agents.agents.fp.fictitious_play_agent"]], "fictitious_play() (csle_agents.agents.fp.fictitious_play_agent.fictitiousplayagent method)": [[9, "csle_agents.agents.fp.fictitious_play_agent.FictitiousPlayAgent.fictitious_play"]], "hparam_names() (csle_agents.agents.fp.fictitious_play_agent.fictitiousplayagent method)": [[9, "csle_agents.agents.fp.fictitious_play_agent.FictitiousPlayAgent.hparam_names"]], "round_vec() (csle_agents.agents.fp.fictitious_play_agent.fictitiousplayagent static method)": [[9, "csle_agents.agents.fp.fictitious_play_agent.FictitiousPlayAgent.round_vec"]], "train() (csle_agents.agents.fp.fictitious_play_agent.fictitiousplayagent method)": [[9, "csle_agents.agents.fp.fictitious_play_agent.FictitiousPlayAgent.train"]], "update_metrics() (csle_agents.agents.fp.fictitious_play_agent.fictitiousplayagent static method)": [[9, "csle_agents.agents.fp.fictitious_play_agent.FictitiousPlayAgent.update_metrics"]], "hsviagent (class in csle_agents.agents.hsvi.hsvi_agent)": [[10, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent"]], "approximate_projection_sawtooth() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[10, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.approximate_projection_sawtooth"]], "bayes_filter() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[10, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.bayes_filter"]], "csle_agents.agents.hsvi": [[10, "module-csle_agents.agents.hsvi"]], "csle_agents.agents.hsvi.hsvi_agent": [[10, "module-csle_agents.agents.hsvi.hsvi_agent"]], "excess() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[10, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.excess"]], "explore() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[10, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.explore"]], "generate_corner_belief() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[10, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.generate_corner_belief"]], "hparam_names() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[10, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.hparam_names"]], "hsvi() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[10, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.hsvi"]], "hsvi_algorithm() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[10, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.hsvi_algorithm"]], "initialize_lower_bound() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[10, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.initialize_lower_bound"]], "initialize_upper_bound() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[10, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.initialize_upper_bound"]], "interior_point_belief_val() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[10, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.interior_point_belief_val"]], "local_lower_bound_update() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[10, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.local_lower_bound_update"]], "local_updates() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[10, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.local_updates"]], "local_upper_bound_update() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[10, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.local_upper_bound_update"]], "lower_bound_backup() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[10, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.lower_bound_backup"]], "lower_bound_value() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[10, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.lower_bound_value"]], "lp_convex_hull_projection_lp() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[10, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.lp_convex_hull_projection_lp"]], "next_belief() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[10, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.next_belief"]], "observation_possible() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[10, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.observation_possible"]], "one_step_lookahead() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[10, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.one_step_lookahead"]], "p_o_given_b_a() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[10, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.p_o_given_b_a"]], "prune_upper_bound() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[10, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.prune_upper_bound"]], "q() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[10, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.q"]], "q_hat_interval() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[10, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.q_hat_interval"]], "simulate() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[10, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.simulate"]], "train() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[10, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.train"]], "update_corner_points() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[10, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.update_corner_points"]], "upper_bound_backup() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[10, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.upper_bound_backup"]], "upper_bound_value() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[10, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.upper_bound_value"]], "vi() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[10, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.vi"]], "width() (csle_agents.agents.hsvi.hsvi_agent.hsviagent method)": [[10, "csle_agents.agents.hsvi.hsvi_agent.HSVIAgent.width"]], "hsviosposgagent (class in csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent"]], "auxillary_game() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.auxillary_game"]], "bayes_filter() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.bayes_filter"]], "choose_a_o_for_exploration() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.choose_a_o_for_exploration"]], "combine_weights_and_pure_strategies_into_mixed_strategy() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.combine_weights_and_pure_strategies_into_mixed_strategy"]], "compute_delta() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.compute_delta"]], "compute_equilibrium_strategies_in_matrix_game() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.compute_equilibrium_strategies_in_matrix_game"]], "compute_matrix_game_value() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.compute_matrix_game_value"]], "csle_agents.agents.hsvi_os_posg": [[11, "module-csle_agents.agents.hsvi_os_posg"]], "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent": [[11, "module-csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent"]], "delta_lipschitz_envelope_of_upper_bound_value() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.delta_lipschitz_envelope_of_upper_bound_value"]], "excess() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.excess"]], "explore() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.explore"]], "generate_corner_belief() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.generate_corner_belief"]], "hparam_names() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.hparam_names"]], "hsvi() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.hsvi"]], "hsvi_os_posg() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.hsvi_os_posg"]], "initialize_lower_bound() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.initialize_lower_bound"]], "initialize_upper_bound() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.initialize_upper_bound"]], "local_lower_bound_update() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.local_lower_bound_update"]], "local_updates() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.local_updates"]], "local_upper_bound_update() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.local_upper_bound_update"]], "lower_bound_backup() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.lower_bound_backup"]], "lower_bound_value() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.lower_bound_value"]], "maxcomp_shapley_bellman_operator() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.maxcomp_shapley_bellman_operator"]], "mdp_reward_matrix_p2() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.mdp_reward_matrix_p2"]], "mdp_transition_tensor_p2() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.mdp_transition_tensor_p2"]], "next_belief() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.next_belief"]], "obtain_equilibrium_strategy_profiles_in_stage_game() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.obtain_equilibrium_strategy_profiles_in_stage_game"]], "one_step_lookahead() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.one_step_lookahead"]], "p_o_given_b_a1_a2() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.p_o_given_b_a1_a2"]], "p_o_given_b_pi_1_pi_2() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.p_o_given_b_pi_1_pi_2"]], "prune_upper_bound() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.prune_upper_bound"]], "rho() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.rho"]], "sample_d() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.sample_D"]], "si() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.si"]], "train() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.train"]], "upper_bound_backup() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.upper_bound_backup"]], "upper_bound_value() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.upper_bound_value"]], "valcomp() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.valcomp"]], "value_of_p1_strategy_static() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.value_of_p1_strategy_static"]], "vi() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.vi"]], "weighted_excess_gap() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.weighted_excess_gap"]], "width() (csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.hsviosposgagent method)": [[11, "csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent.width"]], "kieferwolfowitzagent (class in csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent)": [[12, "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.KieferWolfowitzAgent"]], "batch_gradient() (csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.kieferwolfowitzagent method)": [[12, "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.KieferWolfowitzAgent.batch_gradient"]], "compute_avg_metrics() (csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.kieferwolfowitzagent static method)": [[12, "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.KieferWolfowitzAgent.compute_avg_metrics"]], "csle_agents.agents.kiefer_wolfowitz": [[12, "module-csle_agents.agents.kiefer_wolfowitz"]], "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent": [[12, "module-csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent"]], "estimate_gk() (csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.kieferwolfowitzagent method)": [[12, "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.KieferWolfowitzAgent.estimate_gk"]], "eval_theta() (csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.kieferwolfowitzagent method)": [[12, "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.KieferWolfowitzAgent.eval_theta"]], "get_policy() (csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.kieferwolfowitzagent method)": [[12, "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.KieferWolfowitzAgent.get_policy"]], "hparam_names() (csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.kieferwolfowitzagent method)": [[12, "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.KieferWolfowitzAgent.hparam_names"]], "initial_theta() (csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.kieferwolfowitzagent static method)": [[12, "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.KieferWolfowitzAgent.initial_theta"]], "kiefer_wolfowitz() (csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.kieferwolfowitzagent method)": [[12, "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.KieferWolfowitzAgent.kiefer_wolfowitz"]], "round_vec() (csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.kieferwolfowitzagent static method)": [[12, "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.KieferWolfowitzAgent.round_vec"]], "train() (csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.kieferwolfowitzagent method)": [[12, "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.KieferWolfowitzAgent.train"]], "update_metrics() (csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.kieferwolfowitzagent static method)": [[12, "csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.KieferWolfowitzAgent.update_metrics"]], "linearprogrammingnormalformgameagent (class in csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent)": [[13, "csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.LinearProgrammingNormalFormGameAgent"]], "compute_avg_metrics() (csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.linearprogrammingnormalformgameagent static method)": [[13, "csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.LinearProgrammingNormalFormGameAgent.compute_avg_metrics"]], "compute_equilibrium_strategies_in_matrix_game() (csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.linearprogrammingnormalformgameagent method)": [[13, "csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.LinearProgrammingNormalFormGameAgent.compute_equilibrium_strategies_in_matrix_game"]], "compute_matrix_game_value() (csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.linearprogrammingnormalformgameagent method)": [[13, "csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.LinearProgrammingNormalFormGameAgent.compute_matrix_game_value"]], "csle_agents.agents.lp_nf": [[13, "module-csle_agents.agents.lp_nf"]], "csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent": [[13, "module-csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent"]], "hparam_names() (csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.linearprogrammingnormalformgameagent method)": [[13, "csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.LinearProgrammingNormalFormGameAgent.hparam_names"]], "linear_programming_normal_form() (csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.linearprogrammingnormalformgameagent method)": [[13, "csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.LinearProgrammingNormalFormGameAgent.linear_programming_normal_form"]], "round_vec() (csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.linearprogrammingnormalformgameagent static method)": [[13, "csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.LinearProgrammingNormalFormGameAgent.round_vec"]], "train() (csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.linearprogrammingnormalformgameagent method)": [[13, "csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.LinearProgrammingNormalFormGameAgent.train"]], "update_metrics() (csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.linearprogrammingnormalformgameagent static method)": [[13, "csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.LinearProgrammingNormalFormGameAgent.update_metrics"]], "piagent (class in csle_agents.agents.pi.pi_agent)": [[14, "csle_agents.agents.pi.pi_agent.PIAgent"]], "csle_agents.agents.pi": [[14, "module-csle_agents.agents.pi"]], "csle_agents.agents.pi.pi_agent": [[14, "module-csle_agents.agents.pi.pi_agent"]], "evaluate_policy() (csle_agents.agents.pi.pi_agent.piagent method)": [[14, "csle_agents.agents.pi.pi_agent.PIAgent.evaluate_policy"]], "expected_reward_under_policy() (csle_agents.agents.pi.pi_agent.piagent method)": [[14, "csle_agents.agents.pi.pi_agent.PIAgent.expected_reward_under_policy"]], "hparam_names() (csle_agents.agents.pi.pi_agent.piagent method)": [[14, "csle_agents.agents.pi.pi_agent.PIAgent.hparam_names"]], "pi() (csle_agents.agents.pi.pi_agent.piagent method)": [[14, "csle_agents.agents.pi.pi_agent.PIAgent.pi"]], "policy_evaluation() (csle_agents.agents.pi.pi_agent.piagent method)": [[14, "csle_agents.agents.pi.pi_agent.PIAgent.policy_evaluation"]], "policy_improvement() (csle_agents.agents.pi.pi_agent.piagent method)": [[14, "csle_agents.agents.pi.pi_agent.PIAgent.policy_improvement"]], "policy_iteration() (csle_agents.agents.pi.pi_agent.piagent method)": [[14, "csle_agents.agents.pi.pi_agent.PIAgent.policy_iteration"]], "train() (csle_agents.agents.pi.pi_agent.piagent method)": [[14, "csle_agents.agents.pi.pi_agent.PIAgent.train"]], "transition_probability_under_policy() (csle_agents.agents.pi.pi_agent.piagent method)": [[14, "csle_agents.agents.pi.pi_agent.PIAgent.transition_probability_under_policy"]], "ppoagent (class in csle_agents.agents.ppo.ppo_agent)": [[15, "csle_agents.agents.ppo.ppo_agent.PPOAgent"]], "ppotrainingcallback (class in csle_agents.agents.ppo.ppo_agent)": [[15, "csle_agents.agents.ppo.ppo_agent.PPOTrainingCallback"]], "csle_agents.agents.ppo": [[15, "module-csle_agents.agents.ppo"]], "csle_agents.agents.ppo.ppo_agent": [[15, "module-csle_agents.agents.ppo.ppo_agent"]], "hparam_names() (csle_agents.agents.ppo.ppo_agent.ppoagent method)": [[15, "csle_agents.agents.ppo.ppo_agent.PPOAgent.hparam_names"]], "logger (csle_agents.agents.ppo.ppo_agent.ppotrainingcallback attribute)": [[15, "csle_agents.agents.ppo.ppo_agent.PPOTrainingCallback.logger"]], "model (csle_agents.agents.ppo.ppo_agent.ppotrainingcallback attribute)": [[15, "csle_agents.agents.ppo.ppo_agent.PPOTrainingCallback.model"]], "train() (csle_agents.agents.ppo.ppo_agent.ppoagent method)": [[15, "csle_agents.agents.ppo.ppo_agent.PPOAgent.train"]], "qlearningagent (class in csle_agents.agents.q_learning.q_learning_agent)": [[16, "csle_agents.agents.q_learning.q_learning_agent.QLearningAgent"]], "create_policy_from_q_table() (csle_agents.agents.q_learning.q_learning_agent.qlearningagent method)": [[16, "csle_agents.agents.q_learning.q_learning_agent.QLearningAgent.create_policy_from_q_table"]], "csle_agents.agents.q_learning": [[16, "module-csle_agents.agents.q_learning"]], "csle_agents.agents.q_learning.q_learning_agent": [[16, "module-csle_agents.agents.q_learning.q_learning_agent"]], "eps_greedy() (csle_agents.agents.q_learning.q_learning_agent.qlearningagent method)": [[16, "csle_agents.agents.q_learning.q_learning_agent.QLearningAgent.eps_greedy"]], "evaluate_policy() (csle_agents.agents.q_learning.q_learning_agent.qlearningagent method)": [[16, "csle_agents.agents.q_learning.q_learning_agent.QLearningAgent.evaluate_policy"]], "hparam_names() (csle_agents.agents.q_learning.q_learning_agent.qlearningagent method)": [[16, "csle_agents.agents.q_learning.q_learning_agent.QLearningAgent.hparam_names"]], "initialize_count_table() (csle_agents.agents.q_learning.q_learning_agent.qlearningagent method)": [[16, "csle_agents.agents.q_learning.q_learning_agent.QLearningAgent.initialize_count_table"]], "initialize_q_table() (csle_agents.agents.q_learning.q_learning_agent.qlearningagent method)": [[16, "csle_agents.agents.q_learning.q_learning_agent.QLearningAgent.initialize_q_table"]], "q_learning() (csle_agents.agents.q_learning.q_learning_agent.qlearningagent method)": [[16, "csle_agents.agents.q_learning.q_learning_agent.QLearningAgent.q_learning"]], "q_learning_update() (csle_agents.agents.q_learning.q_learning_agent.qlearningagent method)": [[16, "csle_agents.agents.q_learning.q_learning_agent.QLearningAgent.q_learning_update"]], "step_size() (csle_agents.agents.q_learning.q_learning_agent.qlearningagent method)": [[16, "csle_agents.agents.q_learning.q_learning_agent.QLearningAgent.step_size"]], "train() (csle_agents.agents.q_learning.q_learning_agent.qlearningagent method)": [[16, "csle_agents.agents.q_learning.q_learning_agent.QLearningAgent.train"]], "train_q_learning() (csle_agents.agents.q_learning.q_learning_agent.qlearningagent method)": [[16, "csle_agents.agents.q_learning.q_learning_agent.QLearningAgent.train_q_learning"]], "randomsearchagent (class in csle_agents.agents.random_search.random_search_agent)": [[17, "csle_agents.agents.random_search.random_search_agent.RandomSearchAgent"]], "compute_avg_metrics() (csle_agents.agents.random_search.random_search_agent.randomsearchagent static method)": [[17, "csle_agents.agents.random_search.random_search_agent.RandomSearchAgent.compute_avg_metrics"]], "csle_agents.agents.random_search": [[17, "module-csle_agents.agents.random_search"]], "csle_agents.agents.random_search.random_search_agent": [[17, "module-csle_agents.agents.random_search.random_search_agent"]], "eval_theta() (csle_agents.agents.random_search.random_search_agent.randomsearchagent method)": [[17, "csle_agents.agents.random_search.random_search_agent.RandomSearchAgent.eval_theta"]], "get_policy() (csle_agents.agents.random_search.random_search_agent.randomsearchagent method)": [[17, "csle_agents.agents.random_search.random_search_agent.RandomSearchAgent.get_policy"]], "hparam_names() (csle_agents.agents.random_search.random_search_agent.randomsearchagent method)": [[17, "csle_agents.agents.random_search.random_search_agent.RandomSearchAgent.hparam_names"]], "initial_theta() (csle_agents.agents.random_search.random_search_agent.randomsearchagent static method)": [[17, "csle_agents.agents.random_search.random_search_agent.RandomSearchAgent.initial_theta"]], "random_perturbation() (csle_agents.agents.random_search.random_search_agent.randomsearchagent method)": [[17, "csle_agents.agents.random_search.random_search_agent.RandomSearchAgent.random_perturbation"]], "random_search() (csle_agents.agents.random_search.random_search_agent.randomsearchagent method)": [[17, "csle_agents.agents.random_search.random_search_agent.RandomSearchAgent.random_search"]], "round_vec() (csle_agents.agents.random_search.random_search_agent.randomsearchagent static method)": [[17, "csle_agents.agents.random_search.random_search_agent.RandomSearchAgent.round_vec"]], "train() (csle_agents.agents.random_search.random_search_agent.randomsearchagent method)": [[17, "csle_agents.agents.random_search.random_search_agent.RandomSearchAgent.train"]], "update_metrics() (csle_agents.agents.random_search.random_search_agent.randomsearchagent static method)": [[17, "csle_agents.agents.random_search.random_search_agent.RandomSearchAgent.update_metrics"]], "reinforceagent (class in csle_agents.agents.reinforce.reinforce_agent)": [[18, "csle_agents.agents.reinforce.reinforce_agent.ReinforceAgent"]], "compute_avg_metrics() (csle_agents.agents.reinforce.reinforce_agent.reinforceagent static method)": [[18, "csle_agents.agents.reinforce.reinforce_agent.ReinforceAgent.compute_avg_metrics"]], "csle_agents.agents.reinforce": [[18, "module-csle_agents.agents.reinforce"]], "csle_agents.agents.reinforce.reinforce_agent": [[18, "module-csle_agents.agents.reinforce.reinforce_agent"]], "hparam_names() (csle_agents.agents.reinforce.reinforce_agent.reinforceagent method)": [[18, "csle_agents.agents.reinforce.reinforce_agent.ReinforceAgent.hparam_names"]], "reinforce() (csle_agents.agents.reinforce.reinforce_agent.reinforceagent method)": [[18, "csle_agents.agents.reinforce.reinforce_agent.ReinforceAgent.reinforce"]], "round_vec() (csle_agents.agents.reinforce.reinforce_agent.reinforceagent static method)": [[18, "csle_agents.agents.reinforce.reinforce_agent.ReinforceAgent.round_vec"]], "train() (csle_agents.agents.reinforce.reinforce_agent.reinforceagent method)": [[18, "csle_agents.agents.reinforce.reinforce_agent.ReinforceAgent.train"]], "training_step() (csle_agents.agents.reinforce.reinforce_agent.reinforceagent method)": [[18, "csle_agents.agents.reinforce.reinforce_agent.ReinforceAgent.training_step"]], "update_metrics() (csle_agents.agents.reinforce.reinforce_agent.reinforceagent static method)": [[18, "csle_agents.agents.reinforce.reinforce_agent.ReinforceAgent.update_metrics"]], "sarsaagent (class in csle_agents.agents.sarsa.sarsa_agent)": [[19, "csle_agents.agents.sarsa.sarsa_agent.SARSAAgent"]], "create_policy_from_q_table() (csle_agents.agents.sarsa.sarsa_agent.sarsaagent method)": [[19, "csle_agents.agents.sarsa.sarsa_agent.SARSAAgent.create_policy_from_q_table"]], "csle_agents.agents.sarsa": [[19, "module-csle_agents.agents.sarsa"]], "csle_agents.agents.sarsa.sarsa_agent": [[19, "module-csle_agents.agents.sarsa.sarsa_agent"]], "eps_greedy() (csle_agents.agents.sarsa.sarsa_agent.sarsaagent method)": [[19, "csle_agents.agents.sarsa.sarsa_agent.SARSAAgent.eps_greedy"]], "evaluate_policy() (csle_agents.agents.sarsa.sarsa_agent.sarsaagent method)": [[19, "csle_agents.agents.sarsa.sarsa_agent.SARSAAgent.evaluate_policy"]], "hparam_names() (csle_agents.agents.sarsa.sarsa_agent.sarsaagent method)": [[19, "csle_agents.agents.sarsa.sarsa_agent.SARSAAgent.hparam_names"]], "initialize_count_table() (csle_agents.agents.sarsa.sarsa_agent.sarsaagent method)": [[19, "csle_agents.agents.sarsa.sarsa_agent.SARSAAgent.initialize_count_table"]], "initialize_q_table() (csle_agents.agents.sarsa.sarsa_agent.sarsaagent method)": [[19, "csle_agents.agents.sarsa.sarsa_agent.SARSAAgent.initialize_q_table"]], "q_learning() (csle_agents.agents.sarsa.sarsa_agent.sarsaagent method)": [[19, "csle_agents.agents.sarsa.sarsa_agent.SARSAAgent.q_learning"]], "sarsa_update() (csle_agents.agents.sarsa.sarsa_agent.sarsaagent method)": [[19, "csle_agents.agents.sarsa.sarsa_agent.SARSAAgent.sarsa_update"]], "step_size() (csle_agents.agents.sarsa.sarsa_agent.sarsaagent method)": [[19, "csle_agents.agents.sarsa.sarsa_agent.SARSAAgent.step_size"]], "train() (csle_agents.agents.sarsa.sarsa_agent.sarsaagent method)": [[19, "csle_agents.agents.sarsa.sarsa_agent.SARSAAgent.train"]], "train_sarsa() (csle_agents.agents.sarsa.sarsa_agent.sarsaagent method)": [[19, "csle_agents.agents.sarsa.sarsa_agent.SARSAAgent.train_sarsa"]], "shapleyiterationagent (class in csle_agents.agents.shapley_iteration.shapley_iteration_agent)": [[20, "csle_agents.agents.shapley_iteration.shapley_iteration_agent.ShapleyIterationAgent"]], "auxillary_game() (csle_agents.agents.shapley_iteration.shapley_iteration_agent.shapleyiterationagent method)": [[20, "csle_agents.agents.shapley_iteration.shapley_iteration_agent.ShapleyIterationAgent.auxillary_game"]], "compute_matrix_game_value() (csle_agents.agents.shapley_iteration.shapley_iteration_agent.shapleyiterationagent method)": [[20, "csle_agents.agents.shapley_iteration.shapley_iteration_agent.ShapleyIterationAgent.compute_matrix_game_value"]], "csle_agents.agents.shapley_iteration": [[20, "module-csle_agents.agents.shapley_iteration"]], "csle_agents.agents.shapley_iteration.shapley_iteration_agent": [[20, "module-csle_agents.agents.shapley_iteration.shapley_iteration_agent"]], "hparam_names() (csle_agents.agents.shapley_iteration.shapley_iteration_agent.shapleyiterationagent method)": [[20, "csle_agents.agents.shapley_iteration.shapley_iteration_agent.ShapleyIterationAgent.hparam_names"]], "shapley_iteration() (csle_agents.agents.shapley_iteration.shapley_iteration_agent.shapleyiterationagent method)": [[20, "csle_agents.agents.shapley_iteration.shapley_iteration_agent.ShapleyIterationAgent.shapley_iteration"]], "si() (csle_agents.agents.shapley_iteration.shapley_iteration_agent.shapleyiterationagent method)": [[20, "csle_agents.agents.shapley_iteration.shapley_iteration_agent.ShapleyIterationAgent.si"]], "train() (csle_agents.agents.shapley_iteration.shapley_iteration_agent.shapleyiterationagent method)": [[20, "csle_agents.agents.shapley_iteration.shapley_iteration_agent.ShapleyIterationAgent.train"]], "sondikviagent (class in csle_agents.agents.sondik_vi.sondik_vi_agent)": [[21, "csle_agents.agents.sondik_vi.sondik_vi_agent.SondikVIAgent"]], "check_duplicate() (csle_agents.agents.sondik_vi.sondik_vi_agent.sondikviagent method)": [[21, "csle_agents.agents.sondik_vi.sondik_vi_agent.SondikVIAgent.check_duplicate"]], "compute_all_conditional_plans_conditioned_on_a_t() (csle_agents.agents.sondik_vi.sondik_vi_agent.sondikviagent method)": [[21, "csle_agents.agents.sondik_vi.sondik_vi_agent.SondikVIAgent.compute_all_conditional_plans_conditioned_on_a_t"]], "csle_agents.agents.sondik_vi": [[21, "module-csle_agents.agents.sondik_vi"]], "csle_agents.agents.sondik_vi.sondik_vi_agent": [[21, "module-csle_agents.agents.sondik_vi.sondik_vi_agent"]], "evaluate_policy() (csle_agents.agents.sondik_vi.sondik_vi_agent.sondikviagent method)": [[21, "csle_agents.agents.sondik_vi.sondik_vi_agent.SondikVIAgent.evaluate_policy"]], "hparam_names() (csle_agents.agents.sondik_vi.sondik_vi_agent.sondikviagent method)": [[21, "csle_agents.agents.sondik_vi.sondik_vi_agent.SondikVIAgent.hparam_names"]], "prune() (csle_agents.agents.sondik_vi.sondik_vi_agent.sondikviagent method)": [[21, "csle_agents.agents.sondik_vi.sondik_vi_agent.SondikVIAgent.prune"]], "sondik_vi() (csle_agents.agents.sondik_vi.sondik_vi_agent.sondikviagent method)": [[21, "csle_agents.agents.sondik_vi.sondik_vi_agent.SondikVIAgent.sondik_vi"]], "sondik_vi_algorithm() (csle_agents.agents.sondik_vi.sondik_vi_agent.sondikviagent method)": [[21, "csle_agents.agents.sondik_vi.sondik_vi_agent.SondikVIAgent.sondik_vi_algorithm"]], "train() (csle_agents.agents.sondik_vi.sondik_vi_agent.sondikviagent method)": [[21, "csle_agents.agents.sondik_vi.sondik_vi_agent.SondikVIAgent.train"]], "tfpagent (class in csle_agents.agents.t_fp.t_fp_agent)": [[22, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent"]], "attacker_best_response() (csle_agents.agents.t_fp.t_fp_agent.tfpagent method)": [[22, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.attacker_best_response"]], "compute_avg_metrics() (csle_agents.agents.t_fp.t_fp_agent.tfpagent static method)": [[22, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.compute_avg_metrics"]], "csle_agents.agents.t_fp": [[22, "module-csle_agents.agents.t_fp"]], "csle_agents.agents.t_fp.t_fp_agent": [[22, "module-csle_agents.agents.t_fp.t_fp_agent"]], "defender_best_response() (csle_agents.agents.t_fp.t_fp_agent.tfpagent method)": [[22, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.defender_best_response"]], "evaluate_attacker_policy() (csle_agents.agents.t_fp.t_fp_agent.tfpagent method)": [[22, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.evaluate_attacker_policy"]], "evaluate_defender_policy() (csle_agents.agents.t_fp.t_fp_agent.tfpagent method)": [[22, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.evaluate_defender_policy"]], "evaluate_strategy_profile() (csle_agents.agents.t_fp.t_fp_agent.tfpagent method)": [[22, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.evaluate_strategy_profile"]], "exploitability() (csle_agents.agents.t_fp.t_fp_agent.tfpagent static method)": [[22, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.exploitability"]], "get_attacker_experiment_config() (csle_agents.agents.t_fp.t_fp_agent.tfpagent method)": [[22, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.get_attacker_experiment_config"]], "get_defender_experiment_config() (csle_agents.agents.t_fp.t_fp_agent.tfpagent method)": [[22, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.get_defender_experiment_config"]], "hparam_names() (csle_agents.agents.t_fp.t_fp_agent.tfpagent method)": [[22, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.hparam_names"]], "round_vec() (csle_agents.agents.t_fp.t_fp_agent.tfpagent static method)": [[22, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.round_vec"]], "running_average() (csle_agents.agents.t_fp.t_fp_agent.tfpagent static method)": [[22, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.running_average"]], "t_fp() (csle_agents.agents.t_fp.t_fp_agent.tfpagent method)": [[22, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.t_fp"]], "train() (csle_agents.agents.t_fp.t_fp_agent.tfpagent method)": [[22, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.train"]], "update_metrics() (csle_agents.agents.t_fp.t_fp_agent.tfpagent static method)": [[22, "csle_agents.agents.t_fp.t_fp_agent.TFPAgent.update_metrics"]], "tspsaagent (class in csle_agents.agents.t_spsa.t_spsa_agent)": [[23, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent"]], "batch_gradient() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent method)": [[23, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.batch_gradient"]], "compute_avg_metrics() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent static method)": [[23, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.compute_avg_metrics"]], "csle_agents.agents.t_spsa": [[23, "module-csle_agents.agents.t_spsa"]], "csle_agents.agents.t_spsa.t_spsa_agent": [[23, "module-csle_agents.agents.t_spsa.t_spsa_agent"]], "estimate_gk() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent method)": [[23, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.estimate_gk"]], "eval_theta() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent method)": [[23, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.eval_theta"]], "get_policy() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent method)": [[23, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.get_policy"]], "hparam_names() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent method)": [[23, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.hparam_names"]], "initial_theta() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent static method)": [[23, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.initial_theta"]], "round_vec() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent static method)": [[23, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.round_vec"]], "spsa() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent method)": [[23, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.spsa"]], "standard_ak() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent static method)": [[23, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.standard_ak"]], "standard_ck() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent static method)": [[23, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.standard_ck"]], "standard_deltak() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent static method)": [[23, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.standard_deltak"]], "train() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent method)": [[23, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.train"]], "update_metrics() (csle_agents.agents.t_spsa.t_spsa_agent.tspsaagent static method)": [[23, "csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent.update_metrics"]], "viagent (class in csle_agents.agents.vi.vi_agent)": [[24, "csle_agents.agents.vi.vi_agent.VIAgent"]], "create_policy_from_value_function() (csle_agents.agents.vi.vi_agent.viagent method)": [[24, "csle_agents.agents.vi.vi_agent.VIAgent.create_policy_from_value_function"]], "csle_agents.agents.vi": [[24, "module-csle_agents.agents.vi"]], "csle_agents.agents.vi.vi_agent": [[24, "module-csle_agents.agents.vi.vi_agent"]], "evaluate_policy() (csle_agents.agents.vi.vi_agent.viagent method)": [[24, "csle_agents.agents.vi.vi_agent.VIAgent.evaluate_policy"]], "hparam_names() (csle_agents.agents.vi.vi_agent.viagent method)": [[24, "csle_agents.agents.vi.vi_agent.VIAgent.hparam_names"]], "one_step_lookahead() (csle_agents.agents.vi.vi_agent.viagent method)": [[24, "csle_agents.agents.vi.vi_agent.VIAgent.one_step_lookahead"]], "train() (csle_agents.agents.vi.vi_agent.viagent method)": [[24, "csle_agents.agents.vi.vi_agent.VIAgent.train"]], "value_iteration() (csle_agents.agents.vi.vi_agent.viagent method)": [[24, "csle_agents.agents.vi.vi_agent.VIAgent.value_iteration"]], "vi() (csle_agents.agents.vi.vi_agent.viagent method)": [[24, "csle_agents.agents.vi.vi_agent.VIAgent.vi"]], "fnnwithgaussian (class in csle_agents.common.fnn_w_gaussian)": [[25, "csle_agents.common.fnn_w_gaussian.FNNwithGaussian"]], "fnnwithlinear (class in csle_agents.common.fnn_w_linear)": [[25, "csle_agents.common.fnn_w_linear.FNNwithLinear"]], "check_dominance_lp() (in module csle_agents.common.pruning)": [[25, "csle_agents.common.pruning.check_dominance_lp"]], "check_duplicate() (in module csle_agents.common.pruning)": [[25, "csle_agents.common.pruning.check_duplicate"]], "csle_agents.common": [[25, "module-csle_agents.common"]], "csle_agents.common.fnn_w_gaussian": [[25, "module-csle_agents.common.fnn_w_gaussian"]], "csle_agents.common.fnn_w_linear": [[25, "module-csle_agents.common.fnn_w_linear"]], "csle_agents.common.pruning": [[25, "module-csle_agents.common.pruning"]], "forward() (csle_agents.common.fnn_w_gaussian.fnnwithgaussian method)": [[25, "csle_agents.common.fnn_w_gaussian.FNNwithGaussian.forward"]], "forward() (csle_agents.common.fnn_w_linear.fnnwithlinear method)": [[25, "csle_agents.common.fnn_w_linear.FNNwithLinear.forward"]], "get_hidden_activation() (csle_agents.common.fnn_w_gaussian.fnnwithgaussian method)": [[25, "csle_agents.common.fnn_w_gaussian.FNNwithGaussian.get_hidden_activation"]], "get_hidden_activation() (csle_agents.common.fnn_w_linear.fnnwithlinear method)": [[25, "csle_agents.common.fnn_w_linear.FNNwithLinear.get_hidden_activation"]], "prune_lower_bound() (in module csle_agents.common.pruning)": [[25, "csle_agents.common.pruning.prune_lower_bound"]], "test() (in module csle_agents.common.fnn_w_gaussian)": [[25, "csle_agents.common.fnn_w_gaussian.test"]], "test() (in module csle_agents.common.fnn_w_linear)": [[25, "csle_agents.common.fnn_w_linear.test"]], "training (csle_agents.common.fnn_w_gaussian.fnnwithgaussian attribute)": [[25, "csle_agents.common.fnn_w_gaussian.FNNwithGaussian.training"]], "training (csle_agents.common.fnn_w_linear.fnnwithlinear attribute)": [[25, "csle_agents.common.fnn_w_linear.FNNwithLinear.training"]], "a (csle_agents.constants.constants.q_learning attribute)": [[26, "csle_agents.constants.constants.Q_LEARNING.A"]], "a (csle_agents.constants.constants.sarsa attribute)": [[26, "csle_agents.constants.constants.SARSA.A"]], "action_space (csle_agents.constants.constants.hsvi attribute)": [[26, "csle_agents.constants.constants.HSVI.ACTION_SPACE"]], "action_space (csle_agents.constants.constants.sondik_vi attribute)": [[26, "csle_agents.constants.constants.SONDIK_VI.ACTION_SPACE"]], "action_space_player_1 (csle_agents.constants.constants.hsvi_os_posg attribute)": [[26, "csle_agents.constants.constants.HSVI_OS_POSG.ACTION_SPACE_PLAYER_1"]], "action_space_player_1 (csle_agents.constants.constants.lp_for_nf_games attribute)": [[26, "csle_agents.constants.constants.LP_FOR_NF_GAMES.ACTION_SPACE_PLAYER_1"]], "action_space_player_1 (csle_agents.constants.constants.shapley_iteration attribute)": [[26, "csle_agents.constants.constants.SHAPLEY_ITERATION.ACTION_SPACE_PLAYER_1"]], "action_space_player_2 (csle_agents.constants.constants.hsvi_os_posg attribute)": [[26, "csle_agents.constants.constants.HSVI_OS_POSG.ACTION_SPACE_PLAYER_2"]], "action_space_player_2 (csle_agents.constants.constants.lp_for_nf_games attribute)": [[26, "csle_agents.constants.constants.LP_FOR_NF_GAMES.ACTION_SPACE_PLAYER_2"]], "action_space_player_2 (csle_agents.constants.constants.shapley_iteration attribute)": [[26, "csle_agents.constants.constants.SHAPLEY_ITERATION.ACTION_SPACE_PLAYER_2"]], "adam (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.ADAM"]], "attacker_action (csle_agents.constants.constants.env_metrics attribute)": [[26, "csle_agents.constants.constants.ENV_METRICS.ATTACKER_ACTION"]], "attacker_thresholds (csle_agents.constants.constants.t_fp attribute)": [[26, "csle_agents.constants.constants.T_FP.ATTACKER_THRESHOLDS"]], "average_attacker_return (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.AVERAGE_ATTACKER_RETURN"]], "average_best_response_attacker_return (csle_agents.constants.constants.t_fp attribute)": [[26, "csle_agents.constants.constants.T_FP.AVERAGE_BEST_RESPONSE_ATTACKER_RETURN"]], "average_best_response_defender_return (csle_agents.constants.constants.t_fp attribute)": [[26, "csle_agents.constants.constants.T_FP.AVERAGE_BEST_RESPONSE_DEFENDER_RETURN"]], "average_defender_return (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.AVERAGE_DEFENDER_RETURN"]], "average_heuristic_return (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.AVERAGE_HEURISTIC_RETURN"]], "average_heuristic_return (csle_agents.constants.constants.env_metrics attribute)": [[26, "csle_agents.constants.constants.ENV_METRICS.AVERAGE_HEURISTIC_RETURN"]], "average_random_return (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.AVERAGE_RANDOM_RETURN"]], "average_random_return (csle_agents.constants.constants.env_metrics attribute)": [[26, "csle_agents.constants.constants.ENV_METRICS.AVERAGE_RANDOM_RETURN"]], "average_return (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.AVERAGE_RETURN"]], "average_time_horizon (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.AVERAGE_TIME_HORIZON"]], "average_upper_bound_return (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.AVERAGE_UPPER_BOUND_RETURN"]], "average_upper_bound_return (csle_agents.constants.constants.env_metrics attribute)": [[26, "csle_agents.constants.constants.ENV_METRICS.AVERAGE_UPPER_BOUND_RETURN"]], "baseline_prefix (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.BASELINE_PREFIX"]], "batch_size (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.BATCH_SIZE"]], "bayesian_optimization (class in csle_agents.constants.constants)": [[26, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION"]], "best_response_evaluation_iterations (csle_agents.constants.constants.t_fp attribute)": [[26, "csle_agents.constants.constants.T_FP.BEST_RESPONSE_EVALUATION_ITERATIONS"]], "bounds (csle_agents.constants.constants.differential_evolution attribute)": [[26, "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION.BOUNDS"]], "buffer_size (csle_agents.constants.constants.dqn attribute)": [[26, "csle_agents.constants.constants.DQN.BUFFER_SIZE"]], "clients_arrival_rate (csle_agents.constants.constants.dynasec attribute)": [[26, "csle_agents.constants.constants.DYNASEC.CLIENTS_ARRIVAL_RATE"]], "clip_gradient (csle_agents.constants.constants.reinforce attribute)": [[26, "csle_agents.constants.constants.REINFORCE.CLIP_GRADIENT"]], "clip_range (csle_agents.constants.constants.ppo attribute)": [[26, "csle_agents.constants.constants.PPO.CLIP_RANGE"]], "clip_range_vf (csle_agents.constants.constants.ppo attribute)": [[26, "csle_agents.constants.constants.PPO.CLIP_RANGE_VF"]], "common (class in csle_agents.constants.constants)": [[26, "csle_agents.constants.constants.COMMON"]], "confidence_interval (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.CONFIDENCE_INTERVAL"]], "cross_entropy (class in csle_agents.constants.constants)": [[26, "csle_agents.constants.constants.CROSS_ENTROPY"]], "defender_action (csle_agents.constants.constants.env_metrics attribute)": [[26, "csle_agents.constants.constants.ENV_METRICS.DEFENDER_ACTION"]], "defender_thresholds (csle_agents.constants.constants.t_fp attribute)": [[26, "csle_agents.constants.constants.T_FP.DEFENDER_THRESHOLDS"]], "delta (csle_agents.constants.constants.kiefer_wolfowitz attribute)": [[26, "csle_agents.constants.constants.KIEFER_WOLFOWITZ.DELTA"]], "delta (csle_agents.constants.constants.random_search attribute)": [[26, "csle_agents.constants.constants.RANDOM_SEARCH.DELTA"]], "delta (csle_agents.constants.constants.shapley_iteration attribute)": [[26, "csle_agents.constants.constants.SHAPLEY_ITERATION.DELTA"]], "delta (csle_agents.constants.constants.vi attribute)": [[26, "csle_agents.constants.constants.VI.DELTA"]], "differential_evolution (class in csle_agents.constants.constants)": [[26, "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION"]], "dqn (class in csle_agents.constants.constants)": [[26, "csle_agents.constants.constants.DQN"]], "dqn_batch_size (csle_agents.constants.constants.dqn attribute)": [[26, "csle_agents.constants.constants.DQN.DQN_BATCH_SIZE"]], "dynasec (class in csle_agents.constants.constants)": [[26, "csle_agents.constants.constants.DYNASEC"]], "emulation_monitor_sleep_time (csle_agents.constants.constants.dynasec attribute)": [[26, "csle_agents.constants.constants.DYNASEC.EMULATION_MONITOR_SLEEP_TIME"]], "emulation_traces_to_save_w_data_collection_job (csle_agents.constants.constants.dynasec attribute)": [[26, "csle_agents.constants.constants.DYNASEC.EMULATION_TRACES_TO_SAVE_W_DATA_COLLECTION_JOB"]], "ent_coef (csle_agents.constants.constants.ppo attribute)": [[26, "csle_agents.constants.constants.PPO.ENT_COEF"]], "env_metrics (class in csle_agents.constants.constants)": [[26, "csle_agents.constants.constants.ENV_METRICS"]], "epsilon (csle_agents.constants.constants.hsvi attribute)": [[26, "csle_agents.constants.constants.HSVI.EPSILON"]], "epsilon (csle_agents.constants.constants.hsvi_os_posg attribute)": [[26, "csle_agents.constants.constants.HSVI_OS_POSG.EPSILON"]], "epsilon (csle_agents.constants.constants.q_learning attribute)": [[26, "csle_agents.constants.constants.Q_LEARNING.EPSILON"]], "epsilon (csle_agents.constants.constants.sarsa attribute)": [[26, "csle_agents.constants.constants.SARSA.EPSILON"]], "equilibrium_strategies_evaluation_iterations (csle_agents.constants.constants.t_fp attribute)": [[26, "csle_agents.constants.constants.T_FP.EQUILIBRIUM_STRATEGIES_EVALUATION_ITERATIONS"]], "eval_batch_size (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.EVAL_BATCH_SIZE"]], "eval_every (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.EVAL_EVERY"]], "eval_prefix (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.EVAL_PREFIX"]], "excesses (csle_agents.constants.constants.hsvi_os_posg attribute)": [[26, "csle_agents.constants.constants.HSVI_OS_POSG.EXCESSES"]], "exploitability (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.EXPLOITABILITY"]], "exploration_final_eps (csle_agents.constants.constants.dqn attribute)": [[26, "csle_agents.constants.constants.DQN.EXPLORATION_FINAL_EPS"]], "exploration_fraction (csle_agents.constants.constants.dqn attribute)": [[26, "csle_agents.constants.constants.DQN.EXPLORATION_FRACTION"]], "exploration_initial_eps (csle_agents.constants.constants.dqn attribute)": [[26, "csle_agents.constants.constants.DQN.EXPLORATION_INITIAL_EPS"]], "fictitious_play (class in csle_agents.constants.constants)": [[26, "csle_agents.constants.constants.FICTITIOUS_PLAY"]], "gae_lambda (csle_agents.constants.constants.ppo attribute)": [[26, "csle_agents.constants.constants.PPO.GAE_LAMBDA"]], "gamma (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.GAMMA"]], "gradient_batch_size (csle_agents.constants.constants.kiefer_wolfowitz attribute)": [[26, "csle_agents.constants.constants.KIEFER_WOLFOWITZ.GRADIENT_BATCH_SIZE"]], "gradient_batch_size (csle_agents.constants.constants.reinforce attribute)": [[26, "csle_agents.constants.constants.REINFORCE.GRADIENT_BATCH_SIZE"]], "gradient_steps (csle_agents.constants.constants.dqn attribute)": [[26, "csle_agents.constants.constants.DQN.GRADIENT_STEPS"]], "hsvi (class in csle_agents.constants.constants)": [[26, "csle_agents.constants.constants.HSVI"]], "hsvi_os_posg (class in csle_agents.constants.constants)": [[26, "csle_agents.constants.constants.HSVI_OS_POSG"]], "initial_alpha (csle_agents.constants.constants.kiefer_wolfowitz attribute)": [[26, "csle_agents.constants.constants.KIEFER_WOLFOWITZ.INITIAL_ALPHA"]], "initial_belief (csle_agents.constants.constants.hsvi attribute)": [[26, "csle_agents.constants.constants.HSVI.INITIAL_BELIEF"]], "initial_belief (csle_agents.constants.constants.hsvi_os_posg attribute)": [[26, "csle_agents.constants.constants.HSVI_OS_POSG.INITIAL_BELIEF"]], "initial_belief (csle_agents.constants.constants.sondik_vi attribute)": [[26, "csle_agents.constants.constants.SONDIK_VI.INITIAL_BELIEF"]], "initial_belief_values (csle_agents.constants.constants.hsvi attribute)": [[26, "csle_agents.constants.constants.HSVI.INITIAL_BELIEF_VALUES"]], "initial_belief_values (csle_agents.constants.constants.sondik_vi attribute)": [[26, "csle_agents.constants.constants.SONDIK_VI.INITIAL_BELIEF_VALUES"]], "initial_policy (csle_agents.constants.constants.pi attribute)": [[26, "csle_agents.constants.constants.PI.INITIAL_POLICY"]], "initial_state_values (csle_agents.constants.constants.q_learning attribute)": [[26, "csle_agents.constants.constants.Q_LEARNING.INITIAL_STATE_VALUES"]], "initial_state_values (csle_agents.constants.constants.sarsa attribute)": [[26, "csle_agents.constants.constants.SARSA.INITIAL_STATE_VALUES"]], "intrusion_alerts_mean (csle_agents.constants.constants.dynasec attribute)": [[26, "csle_agents.constants.constants.DYNASEC.INTRUSION_ALERTS_MEAN"]], "intrusion_alerts_mean_baseline (csle_agents.constants.constants.dynasec attribute)": [[26, "csle_agents.constants.constants.DYNASEC.INTRUSION_ALERTS_MEAN_BASELINE"]], "intrusion_start_p (csle_agents.constants.constants.dynasec attribute)": [[26, "csle_agents.constants.constants.DYNASEC.INTRUSION_START_P"]], "k (csle_agents.constants.constants.cross_entropy attribute)": [[26, "csle_agents.constants.constants.CROSS_ENTROPY.K"]], "kiefer_wolfowitz (class in csle_agents.constants.constants)": [[26, "csle_agents.constants.constants.KIEFER_WOLFOWITZ"]], "l (csle_agents.constants.constants.bayesian_optimization attribute)": [[26, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.L"]], "l (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.L"]], "l (csle_agents.constants.constants.cross_entropy attribute)": [[26, "csle_agents.constants.constants.CROSS_ENTROPY.L"]], "l (csle_agents.constants.constants.differential_evolution attribute)": [[26, "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION.L"]], "l (csle_agents.constants.constants.kiefer_wolfowitz attribute)": [[26, "csle_agents.constants.constants.KIEFER_WOLFOWITZ.L"]], "l (csle_agents.constants.constants.random_search attribute)": [[26, "csle_agents.constants.constants.RANDOM_SEARCH.L"]], "lamb (csle_agents.constants.constants.cross_entropy attribute)": [[26, "csle_agents.constants.constants.CROSS_ENTROPY.LAMB"]], "lb_size (csle_agents.constants.constants.hsvi attribute)": [[26, "csle_agents.constants.constants.HSVI.LB_SIZE"]], "lb_sizes (csle_agents.constants.constants.hsvi attribute)": [[26, "csle_agents.constants.constants.HSVI.LB_SIZES"]], "learning_rate (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.LEARNING_RATE"]], "learning_rate_decay_rate (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.LEARNING_RATE_DECAY_RATE"]], "learning_rate_exp_decay (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.LEARNING_RATE_EXP_DECAY"]], "learning_starts (csle_agents.constants.constants.dqn attribute)": [[26, "csle_agents.constants.constants.DQN.LEARNING_STARTS"]], "lp_for_nf_games (class in csle_agents.constants.constants)": [[26, "csle_agents.constants.constants.LP_FOR_NF_GAMES"]], "max_env_steps (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.MAX_ENV_STEPS"]], "max_grad_norm (csle_agents.constants.constants.dqn attribute)": [[26, "csle_agents.constants.constants.DQN.MAX_GRAD_NORM"]], "max_grad_norm (csle_agents.constants.constants.ppo attribute)": [[26, "csle_agents.constants.constants.PPO.MAX_GRAD_NORM"]], "mlp_policy (csle_agents.constants.constants.dqn attribute)": [[26, "csle_agents.constants.constants.DQN.MLP_POLICY"]], "mlp_policy (csle_agents.constants.constants.ppo attribute)": [[26, "csle_agents.constants.constants.PPO.MLP_POLICY"]], "mutate (csle_agents.constants.constants.differential_evolution attribute)": [[26, "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION.MUTATE"]], "n (csle_agents.constants.constants.bayesian_optimization attribute)": [[26, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.N"]], "n (csle_agents.constants.constants.cross_entropy attribute)": [[26, "csle_agents.constants.constants.CROSS_ENTROPY.N"]], "n (csle_agents.constants.constants.differential_evolution attribute)": [[26, "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION.N"]], "n (csle_agents.constants.constants.fictitious_play attribute)": [[26, "csle_agents.constants.constants.FICTITIOUS_PLAY.N"]], "n (csle_agents.constants.constants.hsvi_os_posg attribute)": [[26, "csle_agents.constants.constants.HSVI_OS_POSG.N"]], "n (csle_agents.constants.constants.kiefer_wolfowitz attribute)": [[26, "csle_agents.constants.constants.KIEFER_WOLFOWITZ.N"]], "n (csle_agents.constants.constants.lp_for_nf_games attribute)": [[26, "csle_agents.constants.constants.LP_FOR_NF_GAMES.N"]], "n (csle_agents.constants.constants.pi attribute)": [[26, "csle_agents.constants.constants.PI.N"]], "n (csle_agents.constants.constants.q_learning attribute)": [[26, "csle_agents.constants.constants.Q_LEARNING.N"]], "n (csle_agents.constants.constants.random_search attribute)": [[26, "csle_agents.constants.constants.RANDOM_SEARCH.N"]], "n (csle_agents.constants.constants.reinforce attribute)": [[26, "csle_agents.constants.constants.REINFORCE.N"]], "n (csle_agents.constants.constants.sarsa attribute)": [[26, "csle_agents.constants.constants.SARSA.N"]], "n (csle_agents.constants.constants.shapley_iteration attribute)": [[26, "csle_agents.constants.constants.SHAPLEY_ITERATION.N"]], "no_intrusion_alerts_mean (csle_agents.constants.constants.dynasec attribute)": [[26, "csle_agents.constants.constants.DYNASEC.NO_INTRUSION_ALERTS_MEAN"]], "no_intrusion_alerts_mean_baseline (csle_agents.constants.constants.dynasec attribute)": [[26, "csle_agents.constants.constants.DYNASEC.NO_INTRUSION_ALERTS_MEAN_BASELINE"]], "number_of_simulations (csle_agents.constants.constants.hsvi attribute)": [[26, "csle_agents.constants.constants.HSVI.NUMBER_OF_SIMULATIONS"]], "num_actions (csle_agents.constants.constants.pi attribute)": [[26, "csle_agents.constants.constants.PI.NUM_ACTIONS"]], "num_actions (csle_agents.constants.constants.vi attribute)": [[26, "csle_agents.constants.constants.VI.NUM_ACTIONS"]], "num_alpha_vectors (csle_agents.constants.constants.sondik_vi attribute)": [[26, "csle_agents.constants.constants.SONDIK_VI.NUM_ALPHA_VECTORS"]], "num_cached_simulation_traces (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.NUM_CACHED_SIMULATION_TRACES"]], "num_clients (csle_agents.constants.constants.dynasec attribute)": [[26, "csle_agents.constants.constants.DYNASEC.NUM_CLIENTS"]], "num_nodes (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.NUM_NODES"]], "num_parallel_envs (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.NUM_PARALLEL_ENVS"]], "num_states (csle_agents.constants.constants.pi attribute)": [[26, "csle_agents.constants.constants.PI.NUM_STATES"]], "num_states (csle_agents.constants.constants.vi attribute)": [[26, "csle_agents.constants.constants.VI.NUM_STATES"]], "num_training_timesteps (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.NUM_TRAINING_TIMESTEPS"]], "n_2 (csle_agents.constants.constants.t_fp attribute)": [[26, "csle_agents.constants.constants.T_FP.N_2"]], "n_episodes_rollout (csle_agents.constants.constants.dqn attribute)": [[26, "csle_agents.constants.constants.DQN.N_EPISODES_ROLLOUT"]], "observation (csle_agents.constants.constants.env_metrics attribute)": [[26, "csle_agents.constants.constants.ENV_METRICS.OBSERVATION"]], "observation_function (csle_agents.constants.constants.hsvi_os_posg attribute)": [[26, "csle_agents.constants.constants.HSVI_OS_POSG.OBSERVATION_FUNCTION"]], "observation_space (csle_agents.constants.constants.hsvi attribute)": [[26, "csle_agents.constants.constants.HSVI.OBSERVATION_SPACE"]], "observation_space (csle_agents.constants.constants.hsvi_os_posg attribute)": [[26, "csle_agents.constants.constants.HSVI_OS_POSG.OBSERVATION_SPACE"]], "observation_space (csle_agents.constants.constants.sondik_vi attribute)": [[26, "csle_agents.constants.constants.SONDIK_VI.OBSERVATION_SPACE"]], "observation_tensor (csle_agents.constants.constants.hsvi attribute)": [[26, "csle_agents.constants.constants.HSVI.OBSERVATION_TENSOR"]], "observation_tensor (csle_agents.constants.constants.sondik_vi attribute)": [[26, "csle_agents.constants.constants.SONDIK_VI.OBSERVATION_TENSOR"]], "optimizer (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.OPTIMIZER"]], "parameter_bounds (csle_agents.constants.constants.bayesian_optimization attribute)": [[26, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.PARAMETER_BOUNDS"]], "params (csle_agents.constants.constants.bayesian_optimization attribute)": [[26, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.PARAMS"]], "payoff_matrix (csle_agents.constants.constants.fictitious_play attribute)": [[26, "csle_agents.constants.constants.FICTITIOUS_PLAY.PAYOFF_MATRIX"]], "payoff_matrix (csle_agents.constants.constants.lp_for_nf_games attribute)": [[26, "csle_agents.constants.constants.LP_FOR_NF_GAMES.PAYOFF_MATRIX"]], "pi (class in csle_agents.constants.constants)": [[26, "csle_agents.constants.constants.PI"]], "planning_horizon (csle_agents.constants.constants.sondik_vi attribute)": [[26, "csle_agents.constants.constants.SONDIK_VI.PLANNING_HORIZON"]], "player_1_prior (csle_agents.constants.constants.fictitious_play attribute)": [[26, "csle_agents.constants.constants.FICTITIOUS_PLAY.PLAYER_1_PRIOR"]], "player_2_prior (csle_agents.constants.constants.fictitious_play attribute)": [[26, "csle_agents.constants.constants.FICTITIOUS_PLAY.PLAYER_2_PRIOR"]], "policy_losses (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.POLICY_LOSSES"]], "policy_type (csle_agents.constants.constants.bayesian_optimization attribute)": [[26, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.POLICY_TYPE"]], "policy_type (csle_agents.constants.constants.cross_entropy attribute)": [[26, "csle_agents.constants.constants.CROSS_ENTROPY.POLICY_TYPE"]], "policy_type (csle_agents.constants.constants.differential_evolution attribute)": [[26, "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION.POLICY_TYPE"]], "policy_type (csle_agents.constants.constants.kiefer_wolfowitz attribute)": [[26, "csle_agents.constants.constants.KIEFER_WOLFOWITZ.POLICY_TYPE"]], "policy_type (csle_agents.constants.constants.random_search attribute)": [[26, "csle_agents.constants.constants.RANDOM_SEARCH.POLICY_TYPE"]], "population_size (csle_agents.constants.constants.differential_evolution attribute)": [[26, "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION.POPULATION_SIZE"]], "ppo (class in csle_agents.constants.constants)": [[26, "csle_agents.constants.constants.PPO"]], "prune_frequency (csle_agents.constants.constants.hsvi attribute)": [[26, "csle_agents.constants.constants.HSVI.PRUNE_FREQUENCY"]], "prune_frequency (csle_agents.constants.constants.hsvi_os_posg attribute)": [[26, "csle_agents.constants.constants.HSVI_OS_POSG.PRUNE_FREQUENCY"]], "q_learning (class in csle_agents.constants.constants)": [[26, "csle_agents.constants.constants.Q_LEARNING"]], "random_search (class in csle_agents.constants.constants)": [[26, "csle_agents.constants.constants.RANDOM_SEARCH"]], "recombination (csle_agents.constants.constants.differential_evolution attribute)": [[26, "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION.RECOMBINATION"]], "reinforce (class in csle_agents.constants.constants)": [[26, "csle_agents.constants.constants.REINFORCE"]], "replay_window_size (csle_agents.constants.constants.dynasec attribute)": [[26, "csle_agents.constants.constants.DYNASEC.REPLAY_WINDOW_SIZE"]], "return (csle_agents.constants.constants.env_metrics attribute)": [[26, "csle_agents.constants.constants.ENV_METRICS.RETURN"]], "reward_tensor (csle_agents.constants.constants.hsvi attribute)": [[26, "csle_agents.constants.constants.HSVI.REWARD_TENSOR"]], "reward_tensor (csle_agents.constants.constants.hsvi_os_posg attribute)": [[26, "csle_agents.constants.constants.HSVI_OS_POSG.REWARD_TENSOR"]], "reward_tensor (csle_agents.constants.constants.pi attribute)": [[26, "csle_agents.constants.constants.PI.REWARD_TENSOR"]], "reward_tensor (csle_agents.constants.constants.shapley_iteration attribute)": [[26, "csle_agents.constants.constants.SHAPLEY_ITERATION.REWARD_TENSOR"]], "reward_tensor (csle_agents.constants.constants.sondik_vi attribute)": [[26, "csle_agents.constants.constants.SONDIK_VI.REWARD_TENSOR"]], "reward_tensor (csle_agents.constants.constants.vi attribute)": [[26, "csle_agents.constants.constants.VI.REWARD_TENSOR"]], "running_average (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.RUNNING_AVERAGE"]], "running_average_attacker_return (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.RUNNING_AVERAGE_ATTACKER_RETURN"]], "running_average_best_response_attacker_return (csle_agents.constants.constants.t_fp attribute)": [[26, "csle_agents.constants.constants.T_FP.RUNNING_AVERAGE_BEST_RESPONSE_ATTACKER_RETURN"]], "running_average_best_response_defender_return (csle_agents.constants.constants.t_fp attribute)": [[26, "csle_agents.constants.constants.T_FP.RUNNING_AVERAGE_BEST_RESPONSE_DEFENDER_RETURN"]], "running_average_defender_return (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.RUNNING_AVERAGE_DEFENDER_RETURN"]], "running_average_exploitability (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.RUNNING_AVERAGE_EXPLOITABILITY"]], "running_average_intrusion_length (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.RUNNING_AVERAGE_INTRUSION_LENGTH"]], "running_average_intrusion_start (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.RUNNING_AVERAGE_INTRUSION_START"]], "running_average_return (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.RUNNING_AVERAGE_RETURN"]], "running_average_start_point_correct (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.RUNNING_AVERAGE_START_POINT_CORRECT"]], "running_average_time_horizon (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.RUNNING_AVERAGE_TIME_HORIZON"]], "running_average_weighted_intrusion_prediction_distance (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.RUNNING_AVERAGE_WEIGHTED_INTRUSION_PREDICTION_DISTANCE"]], "runtime (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.RUNTIME"]], "s (csle_agents.constants.constants.q_learning attribute)": [[26, "csle_agents.constants.constants.Q_LEARNING.S"]], "s (csle_agents.constants.constants.sarsa attribute)": [[26, "csle_agents.constants.constants.SARSA.S"]], "sarsa (class in csle_agents.constants.constants)": [[26, "csle_agents.constants.constants.SARSA"]], "save_every (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.SAVE_EVERY"]], "sgd (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.SGD"]], "shapley_iteration (class in csle_agents.constants.constants)": [[26, "csle_agents.constants.constants.SHAPLEY_ITERATION"]], "simulate_horizon (csle_agents.constants.constants.hsvi attribute)": [[26, "csle_agents.constants.constants.HSVI.SIMULATE_HORIZON"]], "simulation_frequency (csle_agents.constants.constants.hsvi attribute)": [[26, "csle_agents.constants.constants.HSVI.SIMULATION_FREQUENCY"]], "sleep_time (csle_agents.constants.constants.dynasec attribute)": [[26, "csle_agents.constants.constants.DYNASEC.SLEEP_TIME"]], "sondik_vi (class in csle_agents.constants.constants)": [[26, "csle_agents.constants.constants.SONDIK_VI"]], "start_point_correct (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.START_POINT_CORRECT"]], "state (csle_agents.constants.constants.env_metrics attribute)": [[26, "csle_agents.constants.constants.ENV_METRICS.STATE"]], "state_space (csle_agents.constants.constants.hsvi attribute)": [[26, "csle_agents.constants.constants.HSVI.STATE_SPACE"]], "state_space (csle_agents.constants.constants.hsvi_os_posg attribute)": [[26, "csle_agents.constants.constants.HSVI_OS_POSG.STATE_SPACE"]], "state_space (csle_agents.constants.constants.shapley_iteration attribute)": [[26, "csle_agents.constants.constants.SHAPLEY_ITERATION.STATE_SPACE"]], "state_space (csle_agents.constants.constants.sondik_vi attribute)": [[26, "csle_agents.constants.constants.SONDIK_VI.STATE_SPACE"]], "static_attacker_type (csle_agents.constants.constants.dynasec attribute)": [[26, "csle_agents.constants.constants.DYNASEC.STATIC_ATTACKER_TYPE"]], "steps_between_updates (csle_agents.constants.constants.ppo attribute)": [[26, "csle_agents.constants.constants.PPO.STEPS_BETWEEN_UPDATES"]], "stopping_envs (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.STOPPING_ENVS"]], "stop_distribution_attacker (csle_agents.constants.constants.bayesian_optimization attribute)": [[26, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.STOP_DISTRIBUTION_ATTACKER"]], "stop_distribution_attacker (csle_agents.constants.constants.cross_entropy attribute)": [[26, "csle_agents.constants.constants.CROSS_ENTROPY.STOP_DISTRIBUTION_ATTACKER"]], "stop_distribution_attacker (csle_agents.constants.constants.differential_evolution attribute)": [[26, "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION.STOP_DISTRIBUTION_ATTACKER"]], "stop_distribution_attacker (csle_agents.constants.constants.kiefer_wolfowitz attribute)": [[26, "csle_agents.constants.constants.KIEFER_WOLFOWITZ.STOP_DISTRIBUTION_ATTACKER"]], "stop_distribution_attacker (csle_agents.constants.constants.random_search attribute)": [[26, "csle_agents.constants.constants.RANDOM_SEARCH.STOP_DISTRIBUTION_ATTACKER"]], "stop_distribution_defender (csle_agents.constants.constants.bayesian_optimization attribute)": [[26, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.STOP_DISTRIBUTION_DEFENDER"]], "stop_distribution_defender (csle_agents.constants.constants.cross_entropy attribute)": [[26, "csle_agents.constants.constants.CROSS_ENTROPY.STOP_DISTRIBUTION_DEFENDER"]], "stop_distribution_defender (csle_agents.constants.constants.differential_evolution attribute)": [[26, "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION.STOP_DISTRIBUTION_DEFENDER"]], "stop_distribution_defender (csle_agents.constants.constants.kiefer_wolfowitz attribute)": [[26, "csle_agents.constants.constants.KIEFER_WOLFOWITZ.STOP_DISTRIBUTION_DEFENDER"]], "stop_distribution_defender (csle_agents.constants.constants.random_search attribute)": [[26, "csle_agents.constants.constants.RANDOM_SEARCH.STOP_DISTRIBUTION_DEFENDER"]], "target (csle_agents.constants.constants.bayesian_optimization attribute)": [[26, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.TARGET"]], "target_kl (csle_agents.constants.constants.ppo attribute)": [[26, "csle_agents.constants.constants.PPO.TARGET_KL"]], "target_update_interval (csle_agents.constants.constants.dqn attribute)": [[26, "csle_agents.constants.constants.DQN.TARGET_UPDATE_INTERVAL"]], "theta (csle_agents.constants.constants.vi attribute)": [[26, "csle_agents.constants.constants.VI.THETA"]], "theta1 (csle_agents.constants.constants.bayesian_optimization attribute)": [[26, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.THETA1"]], "theta1 (csle_agents.constants.constants.cross_entropy attribute)": [[26, "csle_agents.constants.constants.CROSS_ENTROPY.THETA1"]], "theta1 (csle_agents.constants.constants.differential_evolution attribute)": [[26, "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION.THETA1"]], "theta1 (csle_agents.constants.constants.kiefer_wolfowitz attribute)": [[26, "csle_agents.constants.constants.KIEFER_WOLFOWITZ.THETA1"]], "theta1 (csle_agents.constants.constants.random_search attribute)": [[26, "csle_agents.constants.constants.RANDOM_SEARCH.THETA1"]], "theta1_attacker (csle_agents.constants.constants.t_fp attribute)": [[26, "csle_agents.constants.constants.T_FP.THETA1_ATTACKER"]], "theta1_defender (csle_agents.constants.constants.t_fp attribute)": [[26, "csle_agents.constants.constants.T_FP.THETA1_DEFENDER"]], "thetas (csle_agents.constants.constants.bayesian_optimization attribute)": [[26, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.THETAS"]], "thetas (csle_agents.constants.constants.cross_entropy attribute)": [[26, "csle_agents.constants.constants.CROSS_ENTROPY.THETAS"]], "thetas (csle_agents.constants.constants.differential_evolution attribute)": [[26, "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION.THETAS"]], "thetas (csle_agents.constants.constants.kiefer_wolfowitz attribute)": [[26, "csle_agents.constants.constants.KIEFER_WOLFOWITZ.THETAS"]], "thetas (csle_agents.constants.constants.random_search attribute)": [[26, "csle_agents.constants.constants.RANDOM_SEARCH.THETAS"]], "thresholds (csle_agents.constants.constants.bayesian_optimization attribute)": [[26, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.THRESHOLDS"]], "thresholds (csle_agents.constants.constants.cross_entropy attribute)": [[26, "csle_agents.constants.constants.CROSS_ENTROPY.THRESHOLDS"]], "thresholds (csle_agents.constants.constants.differential_evolution attribute)": [[26, "csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION.THRESHOLDS"]], "thresholds (csle_agents.constants.constants.kiefer_wolfowitz attribute)": [[26, "csle_agents.constants.constants.KIEFER_WOLFOWITZ.THRESHOLDS"]], "thresholds (csle_agents.constants.constants.random_search attribute)": [[26, "csle_agents.constants.constants.RANDOM_SEARCH.THRESHOLDS"]], "time_horizon (csle_agents.constants.constants.env_metrics attribute)": [[26, "csle_agents.constants.constants.ENV_METRICS.TIME_HORIZON"]], "time_step (csle_agents.constants.constants.env_metrics attribute)": [[26, "csle_agents.constants.constants.ENV_METRICS.TIME_STEP"]], "training_epochs (csle_agents.constants.constants.dynasec attribute)": [[26, "csle_agents.constants.constants.DYNASEC.TRAINING_EPOCHS"]], "train_freq (csle_agents.constants.constants.dqn attribute)": [[26, "csle_agents.constants.constants.DQN.TRAIN_FREQ"]], "transition_tensor (csle_agents.constants.constants.hsvi attribute)": [[26, "csle_agents.constants.constants.HSVI.TRANSITION_TENSOR"]], "transition_tensor (csle_agents.constants.constants.hsvi_os_posg attribute)": [[26, "csle_agents.constants.constants.HSVI_OS_POSG.TRANSITION_TENSOR"]], "transition_tensor (csle_agents.constants.constants.pi attribute)": [[26, "csle_agents.constants.constants.PI.TRANSITION_TENSOR"]], "transition_tensor (csle_agents.constants.constants.shapley_iteration attribute)": [[26, "csle_agents.constants.constants.SHAPLEY_ITERATION.TRANSITION_TENSOR"]], "transition_tensor (csle_agents.constants.constants.sondik_vi attribute)": [[26, "csle_agents.constants.constants.SONDIK_VI.TRANSITION_TENSOR"]], "transition_tensor (csle_agents.constants.constants.vi attribute)": [[26, "csle_agents.constants.constants.VI.TRANSITION_TENSOR"]], "t_fp (class in csle_agents.constants.constants)": [[26, "csle_agents.constants.constants.T_FP"]], "ub_size (csle_agents.constants.constants.hsvi attribute)": [[26, "csle_agents.constants.constants.HSVI.UB_SIZE"]], "ub_sizes (csle_agents.constants.constants.hsvi attribute)": [[26, "csle_agents.constants.constants.HSVI.UB_SIZES"]], "ucb (csle_agents.constants.constants.bayesian_optimization attribute)": [[26, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.UCB"]], "ucb_kappa (csle_agents.constants.constants.bayesian_optimization attribute)": [[26, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.UCB_KAPPA"]], "ucb_xi (csle_agents.constants.constants.bayesian_optimization attribute)": [[26, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.UCB_XI"]], "use_lp (csle_agents.constants.constants.hsvi attribute)": [[26, "csle_agents.constants.constants.HSVI.USE_LP"]], "use_pruning (csle_agents.constants.constants.sondik_vi attribute)": [[26, "csle_agents.constants.constants.SONDIK_VI.USE_PRUNING"]], "utility_function (csle_agents.constants.constants.bayesian_optimization attribute)": [[26, "csle_agents.constants.constants.BAYESIAN_OPTIMIZATION.UTILITY_FUNCTION"]], "vf_coef (csle_agents.constants.constants.ppo attribute)": [[26, "csle_agents.constants.constants.PPO.VF_COEF"]], "vi (class in csle_agents.constants.constants)": [[26, "csle_agents.constants.constants.VI"]], "warmup_episodes (csle_agents.constants.constants.dynasec attribute)": [[26, "csle_agents.constants.constants.DYNASEC.WARMUP_EPISODES"]], "weighted_intrusion_prediction_distance (csle_agents.constants.constants.common attribute)": [[26, "csle_agents.constants.constants.COMMON.WEIGHTED_INTRUSION_PREDICTION_DISTANCE"]], "width (csle_agents.constants.constants.hsvi attribute)": [[26, "csle_agents.constants.constants.HSVI.WIDTH"]], "widths (csle_agents.constants.constants.hsvi attribute)": [[26, "csle_agents.constants.constants.HSVI.WIDTHS"]], "widths (csle_agents.constants.constants.hsvi_os_posg attribute)": [[26, "csle_agents.constants.constants.HSVI_OS_POSG.WIDTHS"]], "csle_agents.constants": [[26, "module-csle_agents.constants"]], "csle_agents.constants.constants": [[26, "module-csle_agents.constants.constants"]], "trainingjobmanager (class in csle_agents.job_controllers.training_job_manager)": [[27, "csle_agents.job_controllers.training_job_manager.TrainingJobManager"]], "csle_agents.job_controllers": [[27, "module-csle_agents.job_controllers"]], "csle_agents.job_controllers.training_job_manager": [[27, "module-csle_agents.job_controllers.training_job_manager"]], "run_training_job() (csle_agents.job_controllers.training_job_manager.trainingjobmanager static method)": [[27, "csle_agents.job_controllers.training_job_manager.TrainingJobManager.run_training_job"]], "start_training_job_in_background() (csle_agents.job_controllers.training_job_manager.trainingjobmanager static method)": [[27, "csle_agents.job_controllers.training_job_manager.TrainingJobManager.start_training_job_in_background"]]}})