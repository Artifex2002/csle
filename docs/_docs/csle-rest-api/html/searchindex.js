Search.setIndex({docnames:["csle_agents","csle_agents.agents","csle_agents.agents.base","csle_agents.agents.bayes_opt","csle_agents.agents.cross_entropy","csle_agents.agents.differential_evolution","csle_agents.agents.dqn","csle_agents.agents.dynasec","csle_agents.agents.fp","csle_agents.agents.hsvi","csle_agents.agents.hsvi_os_posg","csle_agents.agents.kiefer_wolfowitz","csle_agents.agents.lp_nf","csle_agents.agents.pi","csle_agents.agents.ppo","csle_agents.agents.q_learning","csle_agents.agents.random_search","csle_agents.agents.reinforce","csle_agents.agents.sarsa","csle_agents.agents.shapley_iteration","csle_agents.agents.sondik_vi","csle_agents.agents.t_fp","csle_agents.agents.t_spsa","csle_agents.agents.vi","csle_agents.common","csle_agents.constants","csle_agents.job_controllers","index","modules"],envversion:{"sphinx.domains.c":2,"sphinx.domains.changeset":1,"sphinx.domains.citation":1,"sphinx.domains.cpp":4,"sphinx.domains.index":1,"sphinx.domains.javascript":2,"sphinx.domains.math":2,"sphinx.domains.python":3,"sphinx.domains.rst":2,"sphinx.domains.std":2,"sphinx.ext.viewcode":1,sphinx:56},filenames:["csle_agents.rst","csle_agents.agents.rst","csle_agents.agents.base.rst","csle_agents.agents.bayes_opt.rst","csle_agents.agents.cross_entropy.rst","csle_agents.agents.differential_evolution.rst","csle_agents.agents.dqn.rst","csle_agents.agents.dynasec.rst","csle_agents.agents.fp.rst","csle_agents.agents.hsvi.rst","csle_agents.agents.hsvi_os_posg.rst","csle_agents.agents.kiefer_wolfowitz.rst","csle_agents.agents.lp_nf.rst","csle_agents.agents.pi.rst","csle_agents.agents.ppo.rst","csle_agents.agents.q_learning.rst","csle_agents.agents.random_search.rst","csle_agents.agents.reinforce.rst","csle_agents.agents.sarsa.rst","csle_agents.agents.shapley_iteration.rst","csle_agents.agents.sondik_vi.rst","csle_agents.agents.t_fp.rst","csle_agents.agents.t_spsa.rst","csle_agents.agents.vi.rst","csle_agents.common.rst","csle_agents.constants.rst","csle_agents.job_controllers.rst","index.rst","modules.rst"],objects:{"":[[27,0,0,"-","csle_agents"]],"csle_agents.agents":[[2,0,0,"-","base"],[3,0,0,"-","bayes_opt"],[4,0,0,"-","cross_entropy"],[5,0,0,"-","differential_evolution"],[6,0,0,"-","dqn"],[7,0,0,"-","dynasec"],[8,0,0,"-","fp"],[9,0,0,"-","hsvi"],[10,0,0,"-","hsvi_os_posg"],[11,0,0,"-","kiefer_wolfowitz"],[12,0,0,"-","lp_nf"],[13,0,0,"-","pi"],[14,0,0,"-","ppo"],[15,0,0,"-","q_learning"],[16,0,0,"-","random_search"],[17,0,0,"-","reinforce"],[18,0,0,"-","sarsa"],[19,0,0,"-","shapley_iteration"],[20,0,0,"-","sondik_vi"],[21,0,0,"-","t_fp"],[22,0,0,"-","t_spsa"],[23,0,0,"-","vi"]],"csle_agents.agents.base":[[2,0,0,"-","base_agent"]],"csle_agents.agents.base.base_agent":[[2,1,1,"","BaseAgent"]],"csle_agents.agents.base.base_agent.BaseAgent":[[2,2,1,"","hparam_names"],[2,2,1,"","train"]],"csle_agents.agents.cross_entropy":[[4,0,0,"-","cross_entropy_agent"]],"csle_agents.agents.cross_entropy.cross_entropy_agent":[[4,1,1,"","CrossEntropyAgent"]],"csle_agents.agents.cross_entropy.cross_entropy_agent.CrossEntropyAgent":[[4,2,1,"","compute_avg_metrics"],[4,2,1,"","cross_entropy"],[4,2,1,"","eval_theta"],[4,2,1,"","hparam_names"],[4,2,1,"","initial_theta"],[4,2,1,"","round_vec"],[4,2,1,"","train"],[4,2,1,"","update_metrics"]],"csle_agents.agents.differential_evolution":[[5,0,0,"-","differential_evolution_agent"]],"csle_agents.agents.differential_evolution.differential_evolution_agent":[[5,1,1,"","DifferentialEvolutionAgent"]],"csle_agents.agents.differential_evolution.differential_evolution_agent.DifferentialEvolutionAgent":[[5,2,1,"","compute_avg_metrics"],[5,2,1,"","differential_evolution"],[5,2,1,"","ensure_bounds"],[5,2,1,"","eval_theta"],[5,2,1,"","hparam_names"],[5,2,1,"","initial_theta"],[5,2,1,"","round_vec"],[5,2,1,"","train"],[5,2,1,"","update_metrics"]],"csle_agents.agents.dqn":[[6,0,0,"-","dqn_agent"]],"csle_agents.agents.dqn.dqn_agent":[[6,1,1,"","DQNAgent"],[6,1,1,"","DQNTrainingCallback"]],"csle_agents.agents.dqn.dqn_agent.DQNAgent":[[6,2,1,"","hparam_names"],[6,2,1,"","train"]],"csle_agents.agents.dynasec":[[7,0,0,"-","dynasec_agent"]],"csle_agents.agents.dynasec.dynasec_agent":[[7,1,1,"","DataCollectorProcess"],[7,1,1,"","DynaSecAgent"],[7,1,1,"","EmulationMonitorThread"],[7,1,1,"","EmulationStatisticsThread"],[7,1,1,"","PolicyEvaluationThread"],[7,1,1,"","PolicyOptimizationProcess"],[7,1,1,"","SystemIdentificationProcess"]],"csle_agents.agents.dynasec.dynasec_agent.DataCollectorProcess":[[7,2,1,"","run"]],"csle_agents.agents.dynasec.dynasec_agent.DynaSecAgent":[[7,2,1,"","get_Z_from_system_model"],[7,2,1,"","get_spsa_experiment_config"],[7,2,1,"","hparam_names"],[7,2,1,"","mean"],[7,2,1,"","record_metrics"],[7,2,1,"","train"]],"csle_agents.agents.dynasec.dynasec_agent.EmulationMonitorThread":[[7,2,1,"","run"]],"csle_agents.agents.dynasec.dynasec_agent.EmulationStatisticsThread":[[7,2,1,"","run"]],"csle_agents.agents.dynasec.dynasec_agent.PolicyEvaluationThread":[[7,2,1,"","eval_traces"],[7,2,1,"","record_metrics"],[7,2,1,"","run"]],"csle_agents.agents.dynasec.dynasec_agent.PolicyOptimizationProcess":[[7,2,1,"","run"]],"csle_agents.agents.dynasec.dynasec_agent.SystemIdentificationProcess":[[7,2,1,"","run"]],"csle_agents.agents.fp":[[8,0,0,"-","fictitious_play_agent"]],"csle_agents.agents.fp.fictitious_play_agent":[[8,1,1,"","FictitiousPlayAgent"]],"csle_agents.agents.fp.fictitious_play_agent.FictitiousPlayAgent":[[8,2,1,"","best_response"],[8,2,1,"","compute_avg_metrics"],[8,2,1,"","compute_empirical_strategy"],[8,2,1,"","fictitious_play"],[8,2,1,"","hparam_names"],[8,2,1,"","round_vec"],[8,2,1,"","train"],[8,2,1,"","update_metrics"]],"csle_agents.agents.hsvi":[[9,0,0,"-","hsvi_agent"]],"csle_agents.agents.hsvi.hsvi_agent":[[9,1,1,"","HSVIAgent"]],"csle_agents.agents.hsvi.hsvi_agent.HSVIAgent":[[9,2,1,"","approximate_projection_sawtooth"],[9,2,1,"","bayes_filter"],[9,2,1,"","excess"],[9,2,1,"","explore"],[9,2,1,"","generate_corner_belief"],[9,2,1,"","hparam_names"],[9,2,1,"","hsvi"],[9,2,1,"","hsvi_algorithm"],[9,2,1,"","initialize_lower_bound"],[9,2,1,"","initialize_upper_bound"],[9,2,1,"","interior_point_belief_val"],[9,2,1,"","local_lower_bound_update"],[9,2,1,"","local_updates"],[9,2,1,"","local_upper_bound_update"],[9,2,1,"","lower_bound_backup"],[9,2,1,"","lower_bound_value"],[9,2,1,"","lp_convex_hull_projection_lp"],[9,2,1,"","next_belief"],[9,2,1,"","observation_possible"],[9,2,1,"","one_step_lookahead"],[9,2,1,"","p_o_given_b_a"],[9,2,1,"","prune_upper_bound"],[9,2,1,"","q"],[9,2,1,"","q_hat_interval"],[9,2,1,"","simulate"],[9,2,1,"","train"],[9,2,1,"","update_corner_points"],[9,2,1,"","upper_bound_backup"],[9,2,1,"","upper_bound_value"],[9,2,1,"","vi"],[9,2,1,"","width"]],"csle_agents.agents.hsvi_os_posg":[[10,0,0,"-","hsvi_os_posg_agent"]],"csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent":[[10,1,1,"","HSVIOSPOSGAgent"]],"csle_agents.agents.hsvi_os_posg.hsvi_os_posg_agent.HSVIOSPOSGAgent":[[10,2,1,"","auxillary_game"],[10,2,1,"","bayes_filter"],[10,2,1,"","choose_a_o_for_exploration"],[10,2,1,"","combine_weights_and_pure_strategies_into_mixed_strategy"],[10,2,1,"","compute_delta"],[10,2,1,"","compute_equilibrium_strategies_in_matrix_game"],[10,2,1,"","compute_matrix_game_value"],[10,2,1,"","delta_lipschitz_envelope_of_upper_bound_value"],[10,2,1,"","excess"],[10,2,1,"","explore"],[10,2,1,"","generate_corner_belief"],[10,2,1,"","hparam_names"],[10,2,1,"","hsvi"],[10,2,1,"","hsvi_os_posg"],[10,2,1,"","initialize_lower_bound"],[10,2,1,"","initialize_upper_bound"],[10,2,1,"","local_lower_bound_update"],[10,2,1,"","local_updates"],[10,2,1,"","local_upper_bound_update"],[10,2,1,"","lower_bound_backup"],[10,2,1,"","lower_bound_value"],[10,2,1,"","maxcomp_shapley_bellman_operator"],[10,2,1,"","mdp_reward_matrix_p2"],[10,2,1,"","mdp_transition_tensor_p2"],[10,2,1,"","next_belief"],[10,2,1,"","obtain_equilibrium_strategy_profiles_in_stage_game"],[10,2,1,"","one_step_lookahead"],[10,2,1,"","p_o_given_b_a1_a2"],[10,2,1,"","p_o_given_b_pi_1_pi_2"],[10,2,1,"","prune_upper_bound"],[10,2,1,"","rho"],[10,2,1,"","sample_D"],[10,2,1,"","si"],[10,2,1,"","train"],[10,2,1,"","upper_bound_backup"],[10,2,1,"","upper_bound_value"],[10,2,1,"","valcomp"],[10,2,1,"","value_of_p1_strategy_static"],[10,2,1,"","vi"],[10,2,1,"","weighted_excess_gap"],[10,2,1,"","width"]],"csle_agents.agents.kiefer_wolfowitz":[[11,0,0,"-","kiefer_wolfowitz_agent"]],"csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent":[[11,1,1,"","KieferWolfowitzAgent"]],"csle_agents.agents.kiefer_wolfowitz.kiefer_wolfowitz_agent.KieferWolfowitzAgent":[[11,2,1,"","batch_gradient"],[11,2,1,"","compute_avg_metrics"],[11,2,1,"","estimate_gk"],[11,2,1,"","eval_theta"],[11,2,1,"","hparam_names"],[11,2,1,"","initial_theta"],[11,2,1,"","kiefer_wolfowitz"],[11,2,1,"","round_vec"],[11,2,1,"","train"],[11,2,1,"","update_metrics"]],"csle_agents.agents.lp_nf":[[12,0,0,"-","linear_programming_normal_form_game_agent"]],"csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent":[[12,1,1,"","LinearProgrammingNormalFormGameAgent"]],"csle_agents.agents.lp_nf.linear_programming_normal_form_game_agent.LinearProgrammingNormalFormGameAgent":[[12,2,1,"","compute_avg_metrics"],[12,2,1,"","compute_equilibrium_strategies_in_matrix_game"],[12,2,1,"","compute_matrix_game_value"],[12,2,1,"","hparam_names"],[12,2,1,"","linear_programming_normal_form"],[12,2,1,"","round_vec"],[12,2,1,"","train"],[12,2,1,"","update_metrics"]],"csle_agents.agents.pi":[[13,0,0,"-","pi_agent"]],"csle_agents.agents.pi.pi_agent":[[13,1,1,"","PIAgent"]],"csle_agents.agents.pi.pi_agent.PIAgent":[[13,2,1,"","evaluate_policy"],[13,2,1,"","expected_reward_under_policy"],[13,2,1,"","hparam_names"],[13,2,1,"","pi"],[13,2,1,"","policy_evaluation"],[13,2,1,"","policy_improvement"],[13,2,1,"","policy_iteration"],[13,2,1,"","train"],[13,2,1,"","transition_probability_under_policy"]],"csle_agents.agents.ppo":[[14,0,0,"-","ppo_agent"]],"csle_agents.agents.ppo.ppo_agent":[[14,1,1,"","PPOAgent"],[14,1,1,"","PPOTrainingCallback"]],"csle_agents.agents.ppo.ppo_agent.PPOAgent":[[14,2,1,"","hparam_names"],[14,2,1,"","train"]],"csle_agents.agents.q_learning":[[15,0,0,"-","q_learning_agent"]],"csle_agents.agents.q_learning.q_learning_agent":[[15,1,1,"","QLearningAgent"]],"csle_agents.agents.q_learning.q_learning_agent.QLearningAgent":[[15,2,1,"","create_policy_from_q_table"],[15,2,1,"","eps_greedy"],[15,2,1,"","evaluate_policy"],[15,2,1,"","hparam_names"],[15,2,1,"","initialize_count_table"],[15,2,1,"","initialize_q_table"],[15,2,1,"","q_learning"],[15,2,1,"","q_learning_update"],[15,2,1,"","step_size"],[15,2,1,"","train"],[15,2,1,"","train_q_learning"]],"csle_agents.agents.random_search":[[16,0,0,"-","random_search_agent"]],"csle_agents.agents.random_search.random_search_agent":[[16,1,1,"","RandomSearchAgent"]],"csle_agents.agents.random_search.random_search_agent.RandomSearchAgent":[[16,2,1,"","compute_avg_metrics"],[16,2,1,"","eval_theta"],[16,2,1,"","hparam_names"],[16,2,1,"","initial_theta"],[16,2,1,"","random_perturbation"],[16,2,1,"","random_search"],[16,2,1,"","round_vec"],[16,2,1,"","train"],[16,2,1,"","update_metrics"]],"csle_agents.agents.reinforce":[[17,0,0,"-","reinforce_agent"]],"csle_agents.agents.reinforce.reinforce_agent":[[17,1,1,"","ReinforceAgent"]],"csle_agents.agents.reinforce.reinforce_agent.ReinforceAgent":[[17,2,1,"","compute_avg_metrics"],[17,2,1,"","hparam_names"],[17,2,1,"","reinforce"],[17,2,1,"","round_vec"],[17,2,1,"","train"],[17,2,1,"","training_step"],[17,2,1,"","update_metrics"]],"csle_agents.agents.sarsa":[[18,0,0,"-","sarsa_agent"]],"csle_agents.agents.sarsa.sarsa_agent":[[18,1,1,"","SARSAAgent"]],"csle_agents.agents.sarsa.sarsa_agent.SARSAAgent":[[18,2,1,"","create_policy_from_q_table"],[18,2,1,"","eps_greedy"],[18,2,1,"","evaluate_policy"],[18,2,1,"","hparam_names"],[18,2,1,"","initialize_count_table"],[18,2,1,"","initialize_q_table"],[18,2,1,"","q_learning"],[18,2,1,"","sarsa_update"],[18,2,1,"","step_size"],[18,2,1,"","train"],[18,2,1,"","train_sarsa"]],"csle_agents.agents.shapley_iteration":[[19,0,0,"-","shapley_iteration_agent"]],"csle_agents.agents.shapley_iteration.shapley_iteration_agent":[[19,1,1,"","ShapleyIterationAgent"]],"csle_agents.agents.shapley_iteration.shapley_iteration_agent.ShapleyIterationAgent":[[19,2,1,"","auxillary_game"],[19,2,1,"","compute_matrix_game_value"],[19,2,1,"","hparam_names"],[19,2,1,"","shapley_iteration"],[19,2,1,"","si"],[19,2,1,"","train"]],"csle_agents.agents.sondik_vi":[[20,0,0,"-","sondik_vi_agent"]],"csle_agents.agents.sondik_vi.sondik_vi_agent":[[20,1,1,"","SondikVIAgent"]],"csle_agents.agents.sondik_vi.sondik_vi_agent.SondikVIAgent":[[20,2,1,"","check_duplicate"],[20,2,1,"","compute_all_conditional_plans_conditioned_on_a_t"],[20,2,1,"","evaluate_policy"],[20,2,1,"","hparam_names"],[20,2,1,"","prune"],[20,2,1,"","sondik_vi"],[20,2,1,"","sondik_vi_algorithm"],[20,2,1,"","train"]],"csle_agents.agents.t_fp":[[21,0,0,"-","t_fp_agent"]],"csle_agents.agents.t_fp.t_fp_agent":[[21,1,1,"","TFPAgent"]],"csle_agents.agents.t_fp.t_fp_agent.TFPAgent":[[21,2,1,"","attacker_best_response"],[21,2,1,"","compute_avg_metrics"],[21,2,1,"","defender_best_response"],[21,2,1,"","evaluate_attacker_policy"],[21,2,1,"","evaluate_defender_policy"],[21,2,1,"","evaluate_strategy_profile"],[21,2,1,"","exploitability"],[21,2,1,"","get_attacker_experiment_config"],[21,2,1,"","get_defender_experiment_config"],[21,2,1,"","hparam_names"],[21,2,1,"","round_vec"],[21,2,1,"","running_average"],[21,2,1,"","t_fp"],[21,2,1,"","train"],[21,2,1,"","update_metrics"]],"csle_agents.agents.t_spsa":[[22,0,0,"-","t_spsa_agent"]],"csle_agents.agents.t_spsa.t_spsa_agent":[[22,1,1,"","TSPSAAgent"]],"csle_agents.agents.t_spsa.t_spsa_agent.TSPSAAgent":[[22,2,1,"","batch_gradient"],[22,2,1,"","compute_avg_metrics"],[22,2,1,"","estimate_gk"],[22,2,1,"","eval_theta"],[22,2,1,"","hparam_names"],[22,2,1,"","initial_theta"],[22,2,1,"","round_vec"],[22,2,1,"","spsa"],[22,2,1,"","standard_ak"],[22,2,1,"","standard_ck"],[22,2,1,"","standard_deltak"],[22,2,1,"","train"],[22,2,1,"","update_metrics"]],"csle_agents.agents.vi":[[23,0,0,"-","vi_agent"]],"csle_agents.agents.vi.vi_agent":[[23,1,1,"","VIAgent"]],"csle_agents.agents.vi.vi_agent.VIAgent":[[23,2,1,"","create_policy_from_value_function"],[23,2,1,"","evaluate_policy"],[23,2,1,"","hparam_names"],[23,2,1,"","one_step_lookahead"],[23,2,1,"","train"],[23,2,1,"","value_iteration"],[23,2,1,"","vi"]],"csle_agents.common":[[24,0,0,"-","fnn_w_gaussian"],[24,0,0,"-","fnn_w_linear"],[24,0,0,"-","fnn_w_softmax"],[24,0,0,"-","pruning"]],"csle_agents.common.fnn_w_gaussian":[[24,1,1,"","FNNwithGaussian"],[24,4,1,"","test"]],"csle_agents.common.fnn_w_gaussian.FNNwithGaussian":[[24,2,1,"","forward"],[24,2,1,"","get_hidden_activation"],[24,3,1,"","training"]],"csle_agents.common.fnn_w_linear":[[24,1,1,"","FNNwithLinear"],[24,4,1,"","test"]],"csle_agents.common.fnn_w_linear.FNNwithLinear":[[24,2,1,"","forward"],[24,2,1,"","get_hidden_activation"],[24,3,1,"","training"]],"csle_agents.common.fnn_w_softmax":[[24,1,1,"","FNNwithSoftmax"],[24,4,1,"","test"]],"csle_agents.common.fnn_w_softmax.FNNwithSoftmax":[[24,2,1,"","forward"],[24,2,1,"","get_hidden_activation"],[24,3,1,"","training"]],"csle_agents.common.pruning":[[24,4,1,"","check_dominance_lp"],[24,4,1,"","check_duplicate"],[24,4,1,"","prune_lower_bound"]],"csle_agents.constants":[[25,0,0,"-","constants"]],"csle_agents.constants.constants":[[25,1,1,"","BAYESIAN_OPTIMIZATION"],[25,1,1,"","COMMON"],[25,1,1,"","CROSS_ENTROPY"],[25,1,1,"","DIFFERENTIAL_EVOLUTION"],[25,1,1,"","DQN"],[25,1,1,"","DYNASEC"],[25,1,1,"","FICTITIOUS_PLAY"],[25,1,1,"","HSVI"],[25,1,1,"","HSVI_OS_POSG"],[25,1,1,"","KIEFER_WOLFOWITZ"],[25,1,1,"","LP_FOR_NF_GAMES"],[25,1,1,"","PI"],[25,1,1,"","PPO"],[25,1,1,"","Q_LEARNING"],[25,1,1,"","RANDOM_SEARCH"],[25,1,1,"","REINFORCE"],[25,1,1,"","SARSA"],[25,1,1,"","SHAPLEY_ITERATION"],[25,1,1,"","SONDIK_VI"],[25,1,1,"","T_FP"],[25,1,1,"","T_SPSA"],[25,1,1,"","VI"]],"csle_agents.constants.constants.BAYESIAN_OPTIMIZATION":[[25,3,1,"","L"],[25,3,1,"","N"],[25,3,1,"","PARAMETER_BOUNDS"],[25,3,1,"","PARAMS"],[25,3,1,"","STOP_DISTRIBUTION_ATTACKER"],[25,3,1,"","STOP_DISTRIBUTION_DEFENDER"],[25,3,1,"","TARGET"],[25,3,1,"","THETA1"],[25,3,1,"","THETAS"],[25,3,1,"","THRESHOLDS"],[25,3,1,"","UCB"],[25,3,1,"","UCB_KAPPA"],[25,3,1,"","UCB_XI"],[25,3,1,"","UTILITY_FUNCTION"]],"csle_agents.constants.constants.COMMON":[[25,3,1,"","ACTIVATION_FUNCTION"],[25,3,1,"","ADAM"],[25,3,1,"","AVERAGE_ATTACKER_RETURN"],[25,3,1,"","AVERAGE_DEFENDER_RETURN"],[25,3,1,"","AVERAGE_RETURN"],[25,3,1,"","BASELINE_PREFIX"],[25,3,1,"","BATCH_SIZE"],[25,3,1,"","CONFIDENCE_INTERVAL"],[25,3,1,"","DEVICE"],[25,3,1,"","EVAL_BATCH_SIZE"],[25,3,1,"","EVAL_EVERY"],[25,3,1,"","EVAL_PREFIX"],[25,3,1,"","EXPLOITABILITY"],[25,3,1,"","GAMMA"],[25,3,1,"","L"],[25,3,1,"","LEARNING_RATE"],[25,3,1,"","LEARNING_RATE_DECAY_RATE"],[25,3,1,"","LEARNING_RATE_EXP_DECAY"],[25,3,1,"","MAX_ENV_STEPS"],[25,3,1,"","NUM_CACHED_SIMULATION_TRACES"],[25,3,1,"","NUM_HIDDEN_LAYERS"],[25,3,1,"","NUM_NEURONS_PER_HIDDEN_LAYER"],[25,3,1,"","NUM_PARALLEL_ENVS"],[25,3,1,"","NUM_TRAINING_TIMESTEPS"],[25,3,1,"","OPTIMIZER"],[25,3,1,"","POLICY_LOSSES"],[25,3,1,"","RUNNING_AVERAGE"],[25,3,1,"","RUNNING_AVERAGE_ATTACKER_RETURN"],[25,3,1,"","RUNNING_AVERAGE_DEFENDER_RETURN"],[25,3,1,"","RUNNING_AVERAGE_EXPLOITABILITY"],[25,3,1,"","RUNNING_AVERAGE_INTRUSION_LENGTH"],[25,3,1,"","RUNNING_AVERAGE_INTRUSION_START"],[25,3,1,"","RUNNING_AVERAGE_RETURN"],[25,3,1,"","RUNNING_AVERAGE_START_POINT_CORRECT"],[25,3,1,"","RUNNING_AVERAGE_TIME_HORIZON"],[25,3,1,"","RUNNING_AVERAGE_WEIGHTED_INTRUSION_PREDICTION_DISTANCE"],[25,3,1,"","SAVE_EVERY"],[25,3,1,"","SGD"],[25,3,1,"","START_POINT_CORRECT"],[25,3,1,"","STOPPING_ENVS"],[25,3,1,"","WEIGHTED_INTRUSION_PREDICTION_DISTANCE"]],"csle_agents.constants.constants.CROSS_ENTROPY":[[25,3,1,"","K"],[25,3,1,"","L"],[25,3,1,"","LAMB"],[25,3,1,"","N"],[25,3,1,"","STOP_DISTRIBUTION_ATTACKER"],[25,3,1,"","STOP_DISTRIBUTION_DEFENDER"],[25,3,1,"","THETA1"],[25,3,1,"","THETAS"],[25,3,1,"","THRESHOLDS"]],"csle_agents.constants.constants.DIFFERENTIAL_EVOLUTION":[[25,3,1,"","BOUNDS"],[25,3,1,"","L"],[25,3,1,"","MUTATE"],[25,3,1,"","N"],[25,3,1,"","POPULATION_SIZE"],[25,3,1,"","RECOMBINATION"],[25,3,1,"","STOP_DISTRIBUTION_ATTACKER"],[25,3,1,"","STOP_DISTRIBUTION_DEFENDER"],[25,3,1,"","THETA1"],[25,3,1,"","THETAS"],[25,3,1,"","THRESHOLDS"]],"csle_agents.constants.constants.DQN":[[25,3,1,"","BUFFER_SIZE"],[25,3,1,"","DQN_BATCH_SIZE"],[25,3,1,"","EXPLORATION_FINAL_EPS"],[25,3,1,"","EXPLORATION_FRACTION"],[25,3,1,"","EXPLORATION_INITIAL_EPS"],[25,3,1,"","GRADIENT_STEPS"],[25,3,1,"","LEARNING_STARTS"],[25,3,1,"","MAX_GRAD_NORM"],[25,3,1,"","MLP_POLICY"],[25,3,1,"","N_EPISODES_ROLLOUT"],[25,3,1,"","TARGET_UPDATE_INTERVAL"],[25,3,1,"","TRAIN_FREQ"]],"csle_agents.constants.constants.DYNASEC":[[25,3,1,"","CLIENTS_ARRIVAL_RATE"],[25,3,1,"","EMULATION_MONITOR_SLEEP_TIME"],[25,3,1,"","EMULATION_TRACES_TO_SAVE_W_DATA_COLLECTION_JOB"],[25,3,1,"","INTRUSION_ALERTS_MEAN"],[25,3,1,"","INTRUSION_ALERTS_MEAN_BASELINE"],[25,3,1,"","INTRUSION_START_P"],[25,3,1,"","NO_INTRUSION_ALERTS_MEAN"],[25,3,1,"","NO_INTRUSION_ALERTS_MEAN_BASELINE"],[25,3,1,"","NUM_CLIENTS"],[25,3,1,"","REPLAY_WINDOW_SIZE"],[25,3,1,"","SLEEP_TIME"],[25,3,1,"","STATIC_ATTACKER_TYPE"],[25,3,1,"","TRAINING_EPOCHS"],[25,3,1,"","WARMUP_EPISODES"]],"csle_agents.constants.constants.FICTITIOUS_PLAY":[[25,3,1,"","N"],[25,3,1,"","PAYOFF_MATRIX"],[25,3,1,"","PLAYER_1_PRIOR"],[25,3,1,"","PLAYER_2_PRIOR"]],"csle_agents.constants.constants.HSVI":[[25,3,1,"","ACTION_SPACE"],[25,3,1,"","EPSILON"],[25,3,1,"","INITIAL_BELIEF"],[25,3,1,"","INITIAL_BELIEF_VALUES"],[25,3,1,"","LB_SIZE"],[25,3,1,"","LB_SIZES"],[25,3,1,"","NUMBER_OF_SIMULATIONS"],[25,3,1,"","OBSERVATION_SPACE"],[25,3,1,"","OBSERVATION_TENSOR"],[25,3,1,"","PRUNE_FREQUENCY"],[25,3,1,"","REWARD_TENSOR"],[25,3,1,"","SIMULATE_HORIZON"],[25,3,1,"","SIMULATION_FREQUENCY"],[25,3,1,"","STATE_SPACE"],[25,3,1,"","TRANSITION_TENSOR"],[25,3,1,"","UB_SIZE"],[25,3,1,"","UB_SIZES"],[25,3,1,"","USE_LP"],[25,3,1,"","WIDTH"],[25,3,1,"","WIDTHS"]],"csle_agents.constants.constants.HSVI_OS_POSG":[[25,3,1,"","ACTION_SPACE_PLAYER_1"],[25,3,1,"","ACTION_SPACE_PLAYER_2"],[25,3,1,"","EPSILON"],[25,3,1,"","EXCESSES"],[25,3,1,"","INITIAL_BELIEF"],[25,3,1,"","N"],[25,3,1,"","OBSERVATION_FUNCTION"],[25,3,1,"","OBSERVATION_SPACE"],[25,3,1,"","PRUNE_FREQUENCY"],[25,3,1,"","REWARD_TENSOR"],[25,3,1,"","STATE_SPACE"],[25,3,1,"","TRANSITION_TENSOR"],[25,3,1,"","WIDTHS"]],"csle_agents.constants.constants.KIEFER_WOLFOWITZ":[[25,3,1,"","DELTA"],[25,3,1,"","GRADIENT_BATCH_SIZE"],[25,3,1,"","INITIAL_ALPHA"],[25,3,1,"","L"],[25,3,1,"","N"],[25,3,1,"","STOP_DISTRIBUTION_ATTACKER"],[25,3,1,"","STOP_DISTRIBUTION_DEFENDER"],[25,3,1,"","THETA1"],[25,3,1,"","THETAS"],[25,3,1,"","THRESHOLDS"]],"csle_agents.constants.constants.LP_FOR_NF_GAMES":[[25,3,1,"","ACTION_SPACE_PLAYER_1"],[25,3,1,"","ACTION_SPACE_PLAYER_2"],[25,3,1,"","N"],[25,3,1,"","PAYOFF_MATRIX"]],"csle_agents.constants.constants.PI":[[25,3,1,"","INITIAL_POLICY"],[25,3,1,"","N"],[25,3,1,"","NUM_ACTIONS"],[25,3,1,"","NUM_STATES"],[25,3,1,"","REWARD_TENSOR"],[25,3,1,"","TRANSITION_TENSOR"]],"csle_agents.constants.constants.PPO":[[25,3,1,"","CLIP_RANGE"],[25,3,1,"","CLIP_RANGE_VF"],[25,3,1,"","ENT_COEF"],[25,3,1,"","GAE_LAMBDA"],[25,3,1,"","MAX_GRAD_NORM"],[25,3,1,"","MLP_POLICY"],[25,3,1,"","STEPS_BETWEEN_UPDATES"],[25,3,1,"","TARGET_KL"],[25,3,1,"","VF_COEF"]],"csle_agents.constants.constants.Q_LEARNING":[[25,3,1,"","A"],[25,3,1,"","EPSILON"],[25,3,1,"","INITIAL_STATE_VALUES"],[25,3,1,"","N"],[25,3,1,"","S"]],"csle_agents.constants.constants.RANDOM_SEARCH":[[25,3,1,"","DELTA"],[25,3,1,"","L"],[25,3,1,"","N"],[25,3,1,"","STOP_DISTRIBUTION_ATTACKER"],[25,3,1,"","STOP_DISTRIBUTION_DEFENDER"],[25,3,1,"","THETA1"],[25,3,1,"","THETAS"],[25,3,1,"","THRESHOLDS"]],"csle_agents.constants.constants.REINFORCE":[[25,3,1,"","CLIP_GRADIENT"],[25,3,1,"","GRADIENT_BATCH_SIZE"],[25,3,1,"","N"]],"csle_agents.constants.constants.SARSA":[[25,3,1,"","A"],[25,3,1,"","EPSILON"],[25,3,1,"","INITIAL_STATE_VALUES"],[25,3,1,"","N"],[25,3,1,"","S"]],"csle_agents.constants.constants.SHAPLEY_ITERATION":[[25,3,1,"","ACTION_SPACE_PLAYER_1"],[25,3,1,"","ACTION_SPACE_PLAYER_2"],[25,3,1,"","DELTA"],[25,3,1,"","N"],[25,3,1,"","REWARD_TENSOR"],[25,3,1,"","STATE_SPACE"],[25,3,1,"","TRANSITION_TENSOR"]],"csle_agents.constants.constants.SONDIK_VI":[[25,3,1,"","ACTION_SPACE"],[25,3,1,"","INITIAL_BELIEF"],[25,3,1,"","INITIAL_BELIEF_VALUES"],[25,3,1,"","NUM_ALPHA_VECTORS"],[25,3,1,"","OBSERVATION_SPACE"],[25,3,1,"","OBSERVATION_TENSOR"],[25,3,1,"","PLANNING_HORIZON"],[25,3,1,"","REWARD_TENSOR"],[25,3,1,"","STATE_SPACE"],[25,3,1,"","TRANSITION_TENSOR"],[25,3,1,"","USE_PRUNING"]],"csle_agents.constants.constants.T_FP":[[25,3,1,"","ATTACKER_THRESHOLDS"],[25,3,1,"","AVERAGE_BEST_RESPONSE_ATTACKER_RETURN"],[25,3,1,"","AVERAGE_BEST_RESPONSE_DEFENDER_RETURN"],[25,3,1,"","BEST_RESPONSE_EVALUATION_ITERATIONS"],[25,3,1,"","DEFENDER_THRESHOLDS"],[25,3,1,"","EQUILIBRIUM_STRATEGIES_EVALUATION_ITERATIONS"],[25,3,1,"","N_2"],[25,3,1,"","RUNNING_AVERAGE_BEST_RESPONSE_ATTACKER_RETURN"],[25,3,1,"","RUNNING_AVERAGE_BEST_RESPONSE_DEFENDER_RETURN"],[25,3,1,"","THETA1_ATTACKER"],[25,3,1,"","THETA1_DEFENDER"]],"csle_agents.constants.constants.T_SPSA":[[25,3,1,"","A"],[25,3,1,"","EPSILON"],[25,3,1,"","GRADIENT_BATCH_SIZE"],[25,3,1,"","L"],[25,3,1,"","LAMBDA"],[25,3,1,"","N"],[25,3,1,"","STOP_DISTRIBUTION_ATTACKER"],[25,3,1,"","STOP_DISTRIBUTION_DEFENDER"],[25,3,1,"","THETA1"],[25,3,1,"","THETAS"],[25,3,1,"","THRESHOLDS"],[25,3,1,"","a"],[25,3,1,"","c"]],"csle_agents.constants.constants.VI":[[25,3,1,"","DELTA"],[25,3,1,"","NUM_ACTIONS"],[25,3,1,"","NUM_STATES"],[25,3,1,"","REWARD_TENSOR"],[25,3,1,"","THETA"],[25,3,1,"","TRANSITION_TENSOR"]],"csle_agents.job_controllers":[[26,0,0,"-","training_job_manager"]],"csle_agents.job_controllers.training_job_manager":[[26,1,1,"","TrainingJobManager"]],"csle_agents.job_controllers.training_job_manager.TrainingJobManager":[[26,2,1,"","run_training_job"],[26,2,1,"","start_training_job_in_background"]],csle_agents:[[1,0,0,"-","agents"],[24,0,0,"-","common"],[25,0,0,"-","constants"],[26,0,0,"-","job_controllers"]]},objnames:{"0":["py","module","Python module"],"1":["py","class","Python class"],"2":["py","method","Python method"],"3":["py","attribute","Python attribute"],"4":["py","function","Python function"]},objtypes:{"0":"py:module","1":"py:class","2":"py:method","3":"py:attribute","4":"py:function"},terms:{"0":[6,7,9,10,14,15,18,19,20,23],"0001":[9,10,23],"1":[7,9,10,11,12,13,19,20,22,23],"10":[6,9,10,14],"100":[6,14],"10000":[15,18],"1951":8,"1953":[10,19],"1971":20,"1997":24,"2":[10,12,15,18,19,20,24],"200":[4,5,11,16,22],"2000":9,"2004":[9,10],"2017":10,"2019":10,"2020":10,"2021":22,"256":[15,18],"2delta":10,"3":[4,5,6,8,11,12,14,16,17,21,22,25],"30":7,"5":[15,18],"50":11,"500":[10,19],"8":[15,18],"abstract":2,"boolean":[9,10,12,19],"case":24,"class":[2,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26],"float":[4,5,7,8,9,10,11,12,13,15,16,17,18,19,20,21,22,23],"function":[5,7,9,10,13,19,23,24],"hor\u00e1k":10,"import":7,"int":[4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],"kova\u0159\u00edk":10,"new":[4,5,7,8,9,10,11,12,13,16,17,21,22],"return":[4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,26],"static":[4,5,7,8,10,11,12,16,17,21,22,26],"true":[4,5,7,8,9,10,11,12,13,15,16,17,18,19,20,22,23,24],A:[6,8,9,10,12,14,15,18,19,22,24,25],By:10,For:10,It:[10,20],That:10,The:[9,10,13,20],To:10,_i:20,_j:20,_k:20,a1:[10,12,18,19],a2:[10,12,19],a_1:10,a_k:22,abc:2,abl:[10,24],accord:[10,15,18],accuraci:[9,10],achiev:10,aciton:[9,10,19],action:[6,8,9,10,12,13,14,15,17,18,19,20,23],action_spac:25,action_space_player_1:25,action_space_player_2:25,activ:24,activation_funct:25,actor_critic_net:[0,27,28],adam:25,add:[9,10],after:[9,10,13],against:[8,10,21,24],agent:[0,25,27,28],aggreg:[4,5,8,11,12,16,17,21,22],aleph:20,algebra:13,algorithm:[4,5,8,9,10,11,12,13,15,16,17,18,19,20,21,22,23,24,25],all:[10,13,19,20,25],alpha:[9,10,20,24],alpha_bar:10,alpha_corn:9,alpha_set:24,alpha_vec:24,alpha_vectors_polici:20,alphavectorspolici:20,alreadi:[20,24],also:[10,12],among:25,an:[2,7,9,10,13,15,18,19,20,23],ani:[10,12],api:24,appli:9,approxim:9,approximate_projection_sawtooth:9,ar:10,argmax_:10,arrai:[9,10,23],ascent:22,assum:[10,13],attack:[7,21,25],attacker_best_respons:21,attacker_sequ:7,attacker_simulation_env_config:21,attacker_strategi:21,attacker_threshold:[21,25],attacker_v:21,auxillari:[10,19],auxillary_gam:[10,19],av:[20,24],averag:[4,5,8,11,12,15,16,17,18,21,22],average_attacker_return:25,average_best_response_attacker_return:25,average_best_response_defender_return:25,average_defender_return:25,average_return:[23,25],b0:[9,10,20],b:[9,10],b_1:10,b_prime:[9,10],background:26,backup:10,base:[0,1,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27],base_ag:[0,1,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,27],baseag:[2,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23],basecallback:[6,14],baselin:[6,7,14],baseline_:25,baseline_polici:7,baseline_prefix:25,baseline_system_model:7,basic:24,batch:[11,13,15,18,20,22,23],batch_gradi:[11,22],batch_siz:25,bayes_filt:[9,10],bayes_opt:[0,1,27],bayes_opt_ag:[0,1,27],bayesian:[9,10,25],bayesian_optim:25,behavior:10,being:[9,10],belief:[9,10,20],bellman:[9,10],best:[8,10,21],best_respons:8,best_response_evaluation_iter:25,between:10,bool:[4,5,7,8,9,10,11,12,13,15,16,17,18,19,20,22,23,24],bosanski:10,bound:[5,9,10,24,25],brown:8,buffer_s:25,c:[10,22,25],calcul:[15,18,21],callback:[6,14],can:[9,10,24],carlo:[4,5,11,16,21,22],cassandra:24,check:[9,20,24],check_dominance_lp:24,check_dupl:[20,24],child:10,choose_a_o_for_explor:10,ck:[11,22],clients_arrival_r:25,clip_gradi:25,clip_rang:25,clip_range_vf:25,collect:7,collector:7,combin:[10,20],combine_weights_and_pure_strategies_into_mixed_strategi:10,common:[0,6,14,17,25,27,28],composit:10,compur:9,comput:[4,5,8,9,10,11,12,13,15,16,17,18,19,20,21,22,23],compute_all_conditional_plans_conditioned_on_a_t:20,compute_avg_metr:[4,5,8,11,12,16,17,21,22],compute_delta:10,compute_empirical_strategi:8,compute_equilibrium_strategies_in_matrix_gam:[10,12],compute_matrix_game_valu:[10,12,19],condit:20,conditional_plan:20,confidence_interv:25,config:[4,5,8,11,12,16,17,22],configur:[7,21,26],consist:10,constant:[0,27,28],construct:10,contain:20,content:28,continu:10,converg:[9,10,13,23],convex:[9,10],core:[4,5,6,7,8,11,12,14,16,17,21,22],corner:[9,10],corner_point:9,correspond:[9,10],count:[8,15,18],count_tabl:[15,18],creat:[10,15,18,19,23,24],create_policy_from_q_t:[15,18],create_policy_from_value_funct:23,cross:[4,25],cross_entropi:[0,1,25,27],cross_entropy_ag:[0,1,27],crossentropyag:4,csle:[25,26],csle_common:[2,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,26],cumul:9,current:[9,10,11,13,16,21,22,23,24],custom:24,d:10,dao:[2,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,26],data:[7,24],data_collector_process:7,datacollectorprocess:7,dear:10,decid:[9,10],decim:[4,5,8,11,12,16,17,21,22],defend:[7,11,21,22,25],defender_best_respons:21,defender_polici:7,defender_sequ:7,defender_simulation_env_config:21,defender_strategi:21,defender_threshold:[21,25],defender_v:21,defin:24,delta:[10,11,16,23,25],delta_k:22,delta_lipschitz_envelope_of_upper_bound_valu:10,delta_threshold:[10,19],deltak:22,depth:[9,10],determin:[15,18],determinist:13,devic:25,dict:[4,5,7,8,11,12,16,17,21,22],differenti:[5,25],differential_evolut:[0,1,25,27],differential_evolution_ag:[0,1,27],differentialevolutionag:5,dimens:[4,5,11,13,16,22,24],direct:22,discount:[9,10,13,15,17,18,19,20,23],discount_factor:[9,10,23],distribut:10,domin:[20,24],dqn:[0,1,25,27],dqn_agent:[0,1,27],dqn_batch_siz:25,dqnagent:6,dqntrainingcallback:6,dure:[9,10],dynam:13,dynasec:[0,1,25,27],dynasec_ag:[0,1,27],dynasecag:7,e:10,each:[10,13,20],eaction:18,element:[20,21],empir:8,emul:7,emulation_act:7,emulation_attacker_act:7,emulation_config:[2,4,5,6,7,8,11,12,14,16,17,21,22],emulation_defender_act:7,emulation_env_config:[2,4,5,6,7,8,11,12,14,16,17,21,22],emulation_execut:7,emulation_monitor_sleep_tim:25,emulation_statist:7,emulation_statistics_thread:7,emulation_statistics_window:7,emulation_trac:7,emulation_traces_to_save_w_data_collection_job:25,emulation_traces_to_save_with_data_collection_job:[7,25],emulationattackeract:7,emulationdefenderact:7,emulationenvconfig:[2,4,5,6,7,8,11,12,14,16,17,21,22],emulationexecut:7,emulationmonitorthread:7,emulationstatist:7,emulationstatisticsthread:7,emulationstatisticswindow:7,emulationtrac:7,encount:17,ensur:[5,10],ensure_bound:5,ent_coef:25,entropi:[4,25],env:[4,5,6,7,8,11,12,14,16,17,21,22],envelop:10,environ:[4,5,8,11,12,16,17,21,22],episod:17,eps_greedi:[15,18],epsilon:[9,10,15,18,22,25],equat:[9,10],equilibrium:[10,12],equilibrium_strategies_evaluation_iter:25,estim:[7,9,11,21,22],estimate_gk:[11,22],eval:7,eval_:25,eval_batch_s:[6,13,14,15,18,20,23,25],eval_everi:[6,14,25],eval_prefix:25,eval_theta:[4,5,11,16,22],eval_trac:7,evalu:[4,5,7,10,11,13,15,16,18,20,21,22,23],evaluate_attacker_polici:21,evaluate_defender_polici:21,evaluate_polici:[13,15,18,20,23],evaluate_strategy_profil:21,evalut:[13,15,18,20,23],evolut:[5,25],exact:10,exampl:10,excess:[9,10,25],execut:7,exp_execut:[6,14],exp_result:[4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23],expect:[10,13],expected_reward_under_polici:13,experi:[4,5,7,8,9,10,11,12,13,15,16,17,18,19,20,21,22,23],experiment_config:[2,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23],experiment_execut:[2,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23],experiment_result:[4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23],experimentconfig:[2,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23],experimentexecut:[2,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23],experimentresult:[4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23],exploit:[21,25],explor:[9,10,15,18],exploration_final_ep:25,exploration_fracion:25,exploration_fract:25,exploration_initial_ep:25,factor:[9,10,13,15,17,18,19,20,23],fals:[7,9,10,24],fasl:9,fictiti:[8,25],fictitious_plai:[8,25],fictitious_play_ag:[0,1,27],fictitiousplayag:8,filter:[9,10,20,24],fit:24,fix:10,flag:[9,10,12,19],fnn:24,fnn_w_gaussian:[0,27,28],fnn_w_linear:[0,27,28],fnn_w_softmax:[0,17,27,28],fnnwithgaussian:24,fnnwithlinear:24,fnnwithsoftmax:[17,24],follow:[10,20,21],form:[8,12,20,25],forward:24,found:10,fp:[0,1,21,25,27],frequent:9,from:[4,5,6,7,8,10,11,12,14,15,16,17,18,21,22,23],fulli:10,further:10,gae_lambda:25,game:[8,10,12,19,21,25],gamma:[9,10,13,15,17,18,19,20,25],gap:10,gaussian:24,gaussian_mixture_system_model:7,gaussianmixturesystemmodel:7,gener:[7,9,10,24],generate_corner_belief:[9,10],get:22,get_attacker_experiment_config:21,get_defender_experiment_config:21,get_hidden_activ:24,get_spsa_experiment_config:7,get_z_from_system_model:7,given:[4,5,7,8,9,10,11,12,13,16,17,21,22,24,26],gradient:[11,22],gradient_batch_s:[11,22,25],gradient_step:25,greedi:[9,10,15,18,23],guarante:13,gym:[4,5,6,7,8,11,12,14,16,17,21,22],gym_env_nam:[6,14],hack:[9,10,23],hammar:22,hauskreht:9,heurist:[9,10],hidden:24,hidden_activ:24,hidden_dim:24,high:24,horak:10,horizon:[9,20],how:[9,10],hp:[9,10,23],hparam_nam:[2,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23],hsvi:[0,1,10,25,27],hsvi_ag:[0,1,27],hsvi_algorithm:9,hsvi_os_posg:[0,1,25,27],hsvi_os_posg_ag:[0,1,27],hsviagent:9,hsviosposgag:10,hull:[9,10],hv:10,hyperparamet:[4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23],i:10,id:[9,10,23],immedi:[13,20],implement:[6,9,10,11,13,14,21,22,23,24],improv:13,includ:[11,22],increas:10,independ:10,index:22,indic:19,induc:[9,10,20],info:[4,5,8,11,12,16,17,21,22],inform:[4,5,8,11,12,16,17,21,22],initi:[4,5,9,10,11,15,16,18,20,22],initial_alpha:25,initial_belief:25,initial_belief_valu:25,initial_polici:25,initial_state_valu:25,initial_theta:[4,5,11,16,22],initialize_count_t:[15,18],initialize_lower_bound:[9,10],initialize_q_t:[15,18],initialize_upper_bound:[9,10],input:24,input_dim:24,interact:7,interior:9,interior_point:9,interior_point_belief_v:9,interleav:13,interpret:[13,24],interv:[9,10],intrus:22,intrusion_alerts_mean:25,intrusion_alerts_mean_baselin:25,intrusion_start_p:[7,25],iter:[9,10,11,13,15,18,19,20,22,23,25],its:[8,21],job:[4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,26],job_config:26,job_control:[0,27,28],k:[11,22,25],karel:10,keep:10,kernel:[9,10,23],kiefer:[11,25],kiefer_wolfowitz:[0,1,25,27],kiefer_wolfowitz_ag:[0,1,27],kieferwolfowitzag:11,kiekintveld:10,l:[4,5,6,10,11,14,16,19,22,25],lamb:[22,25],lambda:[22,25],lark:[20,24],last:21,latest:[9,10,17],layer:24,lb_size:25,learn:[7,15,18,21,25],learning_r:25,learning_rate_decay_r:25,learning_rate_exp_decai:25,learning_start:25,legal:10,length:9,level:24,linear:[10,12,13,25],linear_programming_normal_form:12,linear_programming_normal_form_game_ag:[0,1,27],linearprogrammingnormalformgameag:12,lipschitz:10,lipshitz:10,list:[2,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],littman:24,local:[9,10],local_lower_bound_upd:[9,10],local_upd:[9,10],local_upper_bound_upd:[9,10],log:[10,17],lookahead:[9,10,23],lookup:[9,10,23],loss:17,lower:[9,10,24],lower_bound:[9,10,24],lower_bound_backup:[9,10],lower_bound_s:25,lower_bound_valu:[9,10],lp:[9,10,12,24],lp_convex_hull_projection_lp:9,lp_for_nf_gam:25,lp_nf:[0,1,10,27],manag:26,mani:10,matrix:[8,10,12,13,19,20],max_env_step:25,max_grad_norm:25,max_iter:[10,19],max_step:[4,5,6,7,11,14,16,22],maxcomp:10,maxcomp_shapley_bellman_oper:10,maxim:[8,10,12,19],maximin:[10,12,19],maximum:[10,19],mayb:9,mdp:[10,13,15,18,25],mdp_reward_matrix_p2:10,mdp_transition_tensor_p2:10,mean:[7,20],method:4,metric:[4,5,7,8,11,12,16,17,21,22],metrics_dict:7,minim:[8,10,12],minimax:[10,12,19],mix:10,mixed_multi_threshold_stopping_polici:21,mixedmultithresholdstoppingpolici:21,mixtur:10,mlp_polici:25,mlppolici:25,model:[7,24],modul:28,monitor:[6,14],monoton:10,mont:[4,5,11,16,21,22],most:10,multi_threshold_stopping_polici:[4,5,11,16,22],multithresholdstoppingpolici:[4,5,11,16,22],mutat:25,n:[13,15,18,21,25],n_2:25,n_action:[15,18,20],n_alpha_vector:20,n_alpha_vectors_t_plus_on:20,n_episodes_rollout:25,n_ob:20,n_state:[15,18,20],name:[4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23],ndarrai:[4,5,7,8,9,10,11,12,13,15,16,18,19,22,23,24],need:10,neighboorhood:10,neighborhood:10,network:[17,24],new_point:9,next:[9,10,15,18,23],next_belief:[9,10],next_state_lookahead:[9,10,23],nn:24,no_intrusion_alerts_mean:25,no_intrusion_alerts_mean_baselin:25,none:[2,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,26],normal:[8,12,25],num_act:[9,10,13,15,18,23,25],num_alpha_vector:25,num_cached_simulation_trac:25,num_client:25,num_hidden_lay:[24,25],num_neurons_per_hidden_lay:25,num_parallel_env:25,num_stat:[9,10,13,15,18,23,25],num_training_timestep:25,number:[9,10,11,13,15,18,19,20,21,22,23,24],number_of_simul:[9,25],numpi:[4,5,7,8,9,10,11,12,13,15,16,18,19,22,23,24],o:[9,10,20],o_i:20,o_j:20,o_k:20,object:[4,5,8,9,10,11,12,13,15,16,17,18,19,20,22,23,25,26],observ:[9,10,20],observation_funct:25,observation_poss:9,observation_spac:25,observation_tensor:25,obtain_equilibrium_strategy_profiles_in_stage_gam:10,often:[9,10],old:13,one:[9,10,23],one_step_lookahead:[9,10,23],onto:9,openai:[6,14],oper:[9,10,23],oppon:[8,10],optim:[7,10,13,17,22,25],option:[4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23],os:[10,25],otherwis:[9,24],output:24,output_dim:24,over:10,p1:10,p1_strategi:10,p2:10,p:[8,9,10,13,17,20],p_o_given_b_a1_a2:10,p_o_given_b_a:9,p_o_given_b_pi_1_pi_2:10,p_pi:13,packag:28,param:[9,10,13,20,23,25],paramet:[4,5,7,8,9,10,11,12,13,15,16,17,18,19,20,21,22,23,24,26],parameter_bound:25,parameteriz:24,payoff:8,payoff_matrix:25,pechoucek:10,perform:[4,5,7,8,9,10,11,12,16,17,21,22,23],period:7,pertrub:22,perturb:[11,16,22],phd:10,pi:[0,1,10,25,27],pi_1:10,pi_1_upper_bound:10,pi_2:10,pi_2_lower_bound:10,pi_ag:[0,1,27],pi_prim:13,piagent:13,plai:[8,10,25],plan:20,planning_horizon:25,player:[8,10,12,19],player_1_prior:25,player_2_prior:25,player_typ:[6,14],playertyp:[6,14],point:[9,10],pointwis:10,polici:[4,5,7,8,9,10,11,12,13,15,16,17,18,20,21,22,23],policy_evalu:13,policy_improv:13,policy_iter:13,policy_loss:25,policy_network:17,policyevaluationthread:7,policyoptimizationprocess:7,pomdp:[9,10,20,25],population_s:25,posg:[10,25],possibl:[9,10,20],ppo:[0,1,25,27],ppo_ag:[0,1,27],ppoagent:14,ppotrainingcallback:14,predict:24,preserv:10,prevent:22,prob_vector:7,probabl:[9,10,13,17,20,23],process:7,produc:20,profil:[10,12,21],program:[10,12,13,25],project:9,propag:24,properti:10,prove:10,prune:[0,9,10,20,27,28],prune_frequ:[9,10,25],prune_lower_bound:24,prune_upper_bound:[9,10],purpos:10,pytorch:24,q:[9,15,18,24,25],q_hat_interv:9,q_learn:[0,1,18,25,27],q_learning_ag:[0,1,27],q_learning_upd:15,q_tabl:[15,18],qlearningag:15,r:[9,10,13,15,18,19,20,23],random:[4,5,7,8,9,10,11,12,13,15,16,17,18,19,20,21,22,23,25],random_perturb:16,random_se:[4,5,6,8,11,12,14,16,17,21,22],random_search:[0,1,25,27],random_search_ag:[0,1,27],randomli:[4,5,11,16,22,24],randomsearchag:16,rang:10,recombin:25,record:7,record_metr:7,refer:9,reid:[9,10],reinforc:[0,1,7,25,27],reinforce_ag:[0,1,27],reinforceag:17,relat:25,relu:24,remov:20,replay_window_s:25,repres:[2,9,10],requir:10,respect:[9,10],respons:[8,10,21],result:[4,5,7,8,9,10,11,12,13,15,16,17,18,19,20,22,23],reward:[9,10,13,15,17,18,19,20,21,23],reward_tensor:25,rho:10,rl:[2,11,21,22],round:[4,5,8,11,12,16,17,21,22],round_vec:[4,5,8,11,12,16,17,21,22],run:[4,5,7,8,9,10,11,12,13,15,16,17,18,19,20,21,22,23,26],run_training_job:26,running_averag:[21,25],running_average_attacker_return:25,running_average_best_response_attacker_return:25,running_average_best_response_defender_return:25,running_average_defender_return:25,running_average_exploit:25,running_average_intrusion_length:25,running_average_intrusion_start:25,running_average_return:25,running_average_start_point_correct:25,running_average_time_horizon:25,running_average_weighted_intrusion_prediction_dist:25,s:[9,10,15,17,18,19,20,24,25],s_prime:[9,10,15,18],sa:[11,15,18],sampl:[10,15,18],sample_d:10,sample_spac:7,sarsa:[0,1,25,27],sarsa_ag:[0,1,27],sarsa_upd:18,sarsaag:18,save_dir:[6,14],save_everi:[6,14,25],save_to_metastor:[4,5,7,8,9,10,11,12,13,15,16,17,18,19,20,22,23],saved_log_prob:17,saved_reward:17,sawtooth:9,scalar:[13,22],search:[9,10,16,17,25],seed:[4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23],select:[10,13,15,18],sequenc:10,set:[9,10,12,19,20,24],sg:[10,19],sgd:25,shaplei:[10,19,25],shapley_iter:[0,1,25,27],shapley_iteration_ag:[0,1,27],shapleyiterationag:19,should:[19,20],si:[10,19],sigma_1:10,simmon:[9,10],simplex:[9,10],simul:[4,5,9,11,16,20,22],simulate_horizon:[9,25],simulation_config:[2,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23],simulation_env_config:[2,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23],simulation_frequ:[9,25],simulation_nam:[6,14],simulationenvconfig:[2,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23],sinc:10,singleton:10,size:[11,13,15,16,18,20,22,23],sleep_tim:[7,25],sleep_time_minut:7,smith:[9,10],softmax:24,solut:10,solv:[9,10,13],some:[9,10,24],sondik:[20,25],sondik_vi:[0,1,25,27],sondik_vi_ag:[0,1,27],sondik_vi_algorithm:20,sondikviag:20,sourc:[2,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26],space:[9,10,15,18],specif:10,spsa:[7,22,25],stable_baselines3:[6,14],stadler:22,stage:[10,19],standard_ak:22,standard_ck:22,standard_deltak:22,start:26,start_point_correct:25,start_training_job_in_background:26,state:[6,9,10,13,14,15,18,19,20,23,24],state_spac:25,state_to_id:[9,10,23],static_attacker_typ:25,statist:7,step:[9,10,11,13,15,16,17,18,22,23],step_siz:[15,18],steps_between_upd:25,stop:[10,11,19,22,25],stop_distribution_attack:25,stop_distribution_defend:25,stopping_env:25,store:[4,5,8,11,12,16,17,22],str:[2,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],strategi:[8,10,12,15,18,19,21],string:25,sub:24,subgam:10,submodul:[0,1,27,28],subpackag:28,subsequ:10,substituted_alpha:10,sum:10,system:[7,13],system_identif:7,system_identification_config:7,system_model:7,systemidentificationconfig:7,systemidentificationprocess:7,t:[7,9,10,19,20,21,22,23,25],t_fp:[0,1,25,27],t_fp_agent:[0,1,27],t_spsa:[0,1,25,27],t_spsa_ag:[0,1,27],tabl:[9,10,15,18,23],tabular:[13,15,18,20,23],take:[9,10],target:25,target_kl:25,target_update_interv:25,teh:10,tensor:[9,10,13,17,19,24],test:24,tfpagent:21,them:7,themselv:[10,19],thesi:10,theta1:25,theta1_attack:25,theta1_defend:25,theta:[4,5,9,10,11,16,22,23,25],thi:10,thread:7,threshold:[4,5,9,10,11,16,19,21,22,23,25],through:[7,10,22],time:10,tocheck:9,todo:21,torch:[17,24],total:[11,22],trace:7,track:7,train:[2,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,26],train_freq:25,train_q_learn:15,train_sarsa:18,training_epoch:25,training_job:[4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,26],training_job_config:[4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,26],training_job_manag:[0,27,28],training_step:17,trainingjobconfig:[4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,26],trainingjobmanag:26,trajectori:17,transit:[9,10,13,19,20,23],transition_probability_under_polici:13,transition_tensor:25,treat:10,tree:[9,10],trei:[9,10],tri:10,tspsaagent:22,tupl:[7,8,9,10,12,13,15,18,19,20,21,23],u:10,ub_siz:25,ucb:25,ucb_kappa:25,ucb_xi:25,unbound:10,uncertainti:9,under:13,uniform:10,union:[2,4,5,6,8,11,12,14,16,17,21,22],updat:[4,5,7,8,9,10,11,12,13,15,16,17,18,19,20,21,22,23],update_corner_point:9,update_metr:[4,5,8,11,12,16,17,21,22],upepr:9,upper:[9,10],upper_bound:[9,10],upper_bound_backup:[9,10],upper_bound_s:25,upper_bound_valu:[9,10],us:[4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,20,21,22,24],use_lp:25,use_prun:[20,25],util:[5,7,10,13],utility_funct:25,v1:25,v:[9,10,13,19,20,23],v_lb:10,v_ub:10,val:[10,12,19],valcomp:10,valu:[8,9,10,12,13,15,18,19,20,21,23],value_iter:23,value_of_p1_strategy_stat:10,vec:[4,5,8,11,12,16,17,21,22],vector:[4,5,8,9,10,11,12,13,16,17,20,21,22,24],verbos:[6,10,14],verifi:24,version:10,vf_coef:25,vi:[0,1,9,10,25,27],vi_ag:[0,1,27],viagent:23,warmup_episod:25,watkin:15,we:10,weight:[10,17],weighted_excess:10,weighted_excess_gap:10,weighted_intrusion_prediction_dist:25,well:10,when:[9,10,21],where:[10,13,20],whether:[8,9,10,12,19,20,24],which:[9,10],whole:10,width:[9,10,25],wolfowitz:[11,25],worker_id:7,x:[10,13,21,24],z:[9,10,20],zero:10,zhang:24},titles:["csle_agents package","csle_agents.agents package","csle_agents.agents.base package","csle_agents.agents.bayes_opt package","csle_agents.agents.cross_entropy package","csle_agents.agents.differential_evolution package","csle_agents.agents.dqn package","csle_agents.agents.dynasec package","csle_agents.agents.fp package","csle_agents.agents.hsvi package","csle_agents.agents.hsvi_os_posg package","csle_agents.agents.kiefer_wolfowitz package","csle_agents.agents.lp_nf package","csle_agents.agents.pi package","csle_agents.agents.ppo package","csle_agents.agents.q_learning package","csle_agents.agents.random_search package","csle_agents.agents.reinforce package","csle_agents.agents.sarsa package","csle_agents.agents.shapley_iteration package","csle_agents.agents.sondik_vi package","csle_agents.agents.t_fp package","csle_agents.agents.t_spsa package","csle_agents.agents.vi package","csle_agents.common package","csle_agents.constants package","csle_agents.job_controllers package","csle_agents package","csle_agents"],titleterms:{actor_critic_net:24,agent:[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23],base:2,base_ag:2,bayes_opt:3,bayes_opt_ag:3,common:24,constant:25,content:[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27],cross_entropi:4,cross_entropy_ag:4,csle_ag:[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28],differential_evolut:5,differential_evolution_ag:5,dqn:6,dqn_agent:6,dynasec:7,dynasec_ag:7,fictitious_play_ag:8,fnn_w_gaussian:24,fnn_w_linear:24,fnn_w_softmax:24,fp:8,hsvi:9,hsvi_ag:9,hsvi_os_posg:10,hsvi_os_posg_ag:10,job_control:26,kiefer_wolfowitz:11,kiefer_wolfowitz_ag:11,linear_programming_normal_form_game_ag:12,lp_nf:12,modul:[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27],packag:[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27],pi:13,pi_ag:13,ppo:14,ppo_ag:14,prune:24,q_learn:15,q_learning_ag:15,random_search:16,random_search_ag:16,reinforc:17,reinforce_ag:17,sarsa:18,sarsa_ag:18,shapley_iter:19,shapley_iteration_ag:19,sondik_vi:20,sondik_vi_ag:20,submodul:[2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26],subpackag:[0,1,27],t_fp:21,t_fp_agent:21,t_spsa:22,t_spsa_ag:22,training_job_manag:26,vi:23,vi_ag:23}})