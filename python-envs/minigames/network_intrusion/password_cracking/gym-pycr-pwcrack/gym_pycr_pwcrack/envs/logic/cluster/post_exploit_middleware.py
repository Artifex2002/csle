from typing import Tuple
from gym_pycr_pwcrack.dao.network.env_state import EnvState
from gym_pycr_pwcrack.dao.network.env_config import EnvConfig
from gym_pycr_pwcrack.dao.action.action import Action
from gym_pycr_pwcrack.envs.logic.cluster.cluster_util import ClusterUtil
from gym_pycr_pwcrack.envs.logic.common.env_dynamics_util import EnvDynamicsUtil
import gym_pycr_pwcrack.constants.constants as constants
from gym_pycr_pwcrack.dao.observation.machine_observation_state import MachineObservationState
from gym_pycr_pwcrack.dao.action_results.nmap_scan_result import NmapScanResult

class PostExploitMiddleware:
    """
    Class that implements functionality for executing post-exploits actions on the cluster
    """

    @staticmethod
    def execute_service_login(s: EnvState, a: Action, env_config: EnvConfig) -> Tuple[EnvState, int, bool]:
        """
        Executes a service login on the cluster using previously found credentials

        :param s: the current state
        :param a: the action to take
        :param env_config: the environment configuration
        :return: s_prime, reward, done
        """
        s_1, t_n_p_1, t_n_os_1, t_n_v_1, t_n_m_1, \
        t_n_s_a_1, t_n_f_p_1, t_n_r_1, t_n_o_v_1, t_n_l_i_1, t_n_t_i_1, ssh_cost, new_conn_ssh = ClusterUtil.login_service_helper(
            s=s, a=a, alive_check=EnvDynamicsUtil.check_if_ssh_connection_is_alive,
            service_name=constants.SSH.SERVICE_NAME, env_config=env_config)
        s_2, t_n_p_2, t_n_os_2, t_n_v_2, t_n_m_2, \
        t_n_s_a_2, t_n_f_p_2, t_n_r_2, t_n_o_v_2, t_n_l_i_2, t_n_t_i_2, ftp_cost, new_conn_ftp = ClusterUtil.login_service_helper(
            s=s_1, a=a, alive_check=EnvDynamicsUtil.check_if_ftp_connection_is_alive,
            service_name=constants.FTP.SERVICE_NAME, env_config=env_config)
        s_3, t_n_p_3, t_n_os_3, t_n_v_3, t_n_m_3, \
        t_n_s_a_3, t_n_f_p_3, t_n_r_3, t_n_o_v_3, t_n_l_i_3, t_n_t_i_3, telnet_cost, new_conn_telnet = ClusterUtil.login_service_helper(
            s=s_2, a=a, alive_check=EnvDynamicsUtil.check_if_telnet_connection_is_alive,
            service_name=constants.TELNET.SERVICE_NAME, env_config=env_config)
        total_cost = ssh_cost + ftp_cost + telnet_cost
        total_new_ports = t_n_p_1 + t_n_p_2 + t_n_p_3
        total_new_os = t_n_os_1 + t_n_os_2 + t_n_os_3
        total_new_cve_vuln = t_n_v_1 + t_n_v_2 + t_n_v_3
        total_new_machines = t_n_m_1 + t_n_m_2 + t_n_m_3
        total_new_shell_access = t_n_s_a_1 + t_n_s_a_2 + t_n_s_a_3
        total_new_flag_pts = t_n_f_p_1 + t_n_f_p_2 + t_n_f_p_3
        total_new_root = t_n_r_1 + t_n_r_2 + t_n_r_3
        total_new_osvdb_vuln = t_n_o_v_1 + t_n_o_v_2 + t_n_o_v_3
        total_new_logins = t_n_l_i_1 + t_n_l_i_2 + t_n_l_i_3
        total_new_tools_installed = t_n_t_i_1 + t_n_t_i_2 + t_n_t_i_3

        s_prime = s_3

        for m in s_prime.obs_state.machines:
            if m.ip == a.ip:
                m.untried_credentials = False

        # Update cost cache
        total_cost = round(total_cost, 1)
        if new_conn_ssh or new_conn_ftp or new_conn_telnet:
            ClusterUtil.write_estimated_cost(total_time=total_cost, action=a,
                                             env_config=env_config, ip=a.ip)
            env_config.action_costs.service_add_cost(action_id=a.id, ip=a.ip, cost=float(total_cost))

        # Use measured cost
        if env_config.action_costs.service_exists(action_id=a.id, ip=a.ip):
            a.cost = env_config.action_costs.service_get_cost(action_id=a.id, ip=a.ip)
        reward = EnvDynamicsUtil.reward_function(num_new_ports_found=total_new_ports, num_new_os_found=total_new_os,
                                                 num_new_cve_vuln_found=total_new_cve_vuln,
                                                 num_new_machines=total_new_machines,
                                                 num_new_shell_access=total_new_shell_access,
                                                 num_new_root=total_new_root,
                                                 num_new_flag_pts=total_new_flag_pts,
                                                 num_new_osvdb_vuln_found = total_new_osvdb_vuln,
                                                 num_new_logged_in=total_new_logins,
                                                 num_new_tools_installed=total_new_tools_installed,
                                                 cost=a.cost,
                                                 env_config=env_config)
        return s_prime, reward, False

    @staticmethod
    def execute_bash_find_flag(s: EnvState, a: Action, env_config: EnvConfig) -> Tuple[EnvState, int, bool]:
        """
        Searches the file system for all servers where the agent is currently logged in to find flags

        :param s: the current state
        :param a: the action to take
        :param env_config: the environment configuration
        :return: s_prime, reward, done
        """
        new_machines_obs = []
        total_cost = 0
        for machine in s.obs_state.machines:
            if machine.logged_in:
                new_m_obs = MachineObservationState(ip=machine.ip)
                key = (machine.ip, machine.root)
                if env_config.use_file_system_cache and key in env_config.filesystem_scan_cache.cache:
                    new_m_obs, cost = env_config.filesystem_scan_cache.get(key)
                    new_machines_obs.append(new_m_obs)
                    total_cost = cost
                    continue

                root_scan = False

                # Start with ssh connections
                new_m_obs, ssh_cost, ssh_root = ClusterUtil._find_flag_using_ssh(machine=machine, env_config=env_config, a=a,
                                                                       new_m_obs=new_m_obs)
                total_cost += ssh_cost
                if ssh_root:
                    root_scan = True

                if root_scan:
                    # Update cache
                    if env_config.use_file_system_cache:
                        env_config.filesystem_scan_cache.add(key, (new_m_obs, total_cost))
                    new_machines_obs.append(new_m_obs)
                    continue

                # If root scan not tried, try telnet connections
                new_m_obs, telnet_cost, telnet_root = ClusterUtil._find_flag_using_telnet(machine=machine, env_config=env_config,
                                                                             a=a, new_m_obs=new_m_obs)
                total_cost += telnet_cost
                if telnet_root:
                    root_scan = True

                if root_scan:
                    # Update cache
                    if env_config.use_file_system_cache:
                        env_config.filesystem_scan_cache.add(key, (new_m_obs, total_cost))
                    new_machines_obs.append(new_m_obs)
                    continue

                # If root scan not tried, try ftp connections
                new_m_obs, ftp_cost, ftp_root = ClusterUtil._find_flag_using_ftp(machine=machine, env_config=env_config,
                                                                       a=a, new_m_obs=new_m_obs)
                total_cost += ftp_cost
                if ftp_root:
                    root_scan = True

                # Update cache
                if env_config.use_file_system_cache:
                    env_config.filesystem_scan_cache.add(key, (new_m_obs, total_cost))

                new_machines_obs.append(new_m_obs)

        new_machines_obs, total_new_ports, total_new_os, total_new_vuln, total_new_machines, \
        total_new_shell_access, total_new_flag_pts, total_new_root, total_new_osvdb_vuln_found, total_new_logged_in, \
        total_new_tools_installed = \
            EnvDynamicsUtil.merge_new_obs_with_old(s.obs_state.machines, new_machines_obs, env_config=env_config)
        s_prime = s
        s_prime.obs_state.machines = new_machines_obs

        reward = EnvDynamicsUtil.reward_function(num_new_ports_found=total_new_ports, num_new_os_found=total_new_os,
                                                 num_new_cve_vuln_found=total_new_vuln,
                                                 num_new_machines=total_new_machines,
                                                 num_new_shell_access=total_new_shell_access,
                                                 num_new_root=total_new_root,
                                                 num_new_flag_pts=total_new_flag_pts,
                                                 num_new_osvdb_vuln_found=total_new_osvdb_vuln_found,
                                                 num_new_logged_in=total_new_logged_in,
                                                 num_new_tools_installed=total_new_tools_installed,
                                                 cost=total_cost,
                                                 env_config=env_config)
        s_prime.obs_state.catched_flags += total_new_flag_pts
        done = EnvDynamicsUtil.is_all_flags_collected(s_prime, env_config)
        if done:
            reward = reward + env_config.all_flags_reward
        s_prime.obs_state.all_flags = done
        return s_prime, reward, done

    @staticmethod
    def execute_install_tools(s: EnvState, a: Action, env_config: EnvConfig) -> Tuple[EnvState, int, bool]:
        """
        Uses compromised machines with root access to install tools

        :param s: the current state
        :param a: the action to take
        :param env_config: the environment configuration
        :return: s_prime, reward, done
        """
        return ClusterUtil.install_tools_helper(s=s, a=a, env_config=env_config)

    @staticmethod
    def execute_pivot_tcp_syn_stealth_scan(s: EnvState, a: Action, env_config: EnvConfig) -> Tuple[EnvState, int, bool]:
        """
        Uses compromised machines with root access to run nmap tcp syn stealth scan

        :param s: the current state
        :param a: the action to take
        :param env_config: the environment configuration
        :return: s_prime, reward, done
        """
        base_cache_id = str(a.id.value) + "_" + str(a.index) + "_" + a.ip + ".xml"
        if a.subnet:
            base_cache_id = str(a.id.value) + "_" + str(a.index) + ".xml"

        # Check in-memory cache
        if env_config.use_nmap_cache:
            scan_result = env_config.nmap_scan_cache.get(base_cache_id)
            if scan_result is not None:
                s_prime, reward = ClusterUtil.merge_nmap_scan_result_with_state(scan_result=scan_result, s=s, a=a,
                                                                            env_config=env_config)
                print("pivot in memory base cache hit")
                return s_prime, reward, False

        new_machines_obs = []
        total_cost = 0
        merged_scan_result = None

        for machine in s.obs_state.machines:
            new_m_obs = MachineObservationState(ip=machine.ip)
            cache_id = str(a.id.value) + "_" + str(a.index) + "_" + machine.ip + "_" + a.ip + ".xml"
            if a.subnet:
                cache_id = str(a.id.value) + "_" + str(a.index) + "_" + machine.ip + ".xml"

            if machine.logged_in and machine.tools_installed:

                # Start with ssh connections
                ssh_connections_sorted_by_root = sorted(machine.ssh_connections, key=lambda x: x.root, reverse=True)
                for c in ssh_connections_sorted_by_root:

                    # Check in-memory cache
                    if env_config.use_nmap_cache:
                        scan_result = env_config.nmap_scan_cache.get(cache_id)
                        if scan_result is not None:
                            print("pivot in memory non-base cache hit")
                            break

                    # Check On-disk cache
                    cwd, _, total_time = ClusterUtil.execute_ssh_cmd(cmd="pwd", conn=c.conn)
                    cwd = cwd.decode().replace("\n", "") + "/"
                    total_cost += total_time
                    if env_config.use_nmap_cache:
                        cache_result = ClusterUtil.check_nmap_action_cache(a=a, env_config=env_config, conn=c.conn,
                                                                           dir=cwd)
                        if cache_result is not None:
                            print("pivot disk non-base cache hit")

                    # If cache miss, then execute cmd
                    if cache_result is None:
                        cmd = a.nmap_cmd(machine_ip = machine.ip)
                        outdata, errdata, total_time = ClusterUtil.execute_ssh_cmd(cmd=cmd, conn=c.conn)
                        total_cost += total_time
                        ClusterUtil.write_estimated_cost(total_time=total_time, action=a, env_config=env_config,
                                                         conn=c.conn, dir=cwd, machine_ip=machine.ip)
                        env_config.action_costs.pivot_scan_add_cost(action_id=a.id, ip=machine.ip, user=c.username,
                                                                    target_ip=machine.ip, cost=round(total_time, 1))
                        cache_result = cache_id

                    # Read result
                    for i in range(env_config.num_retries):
                        try:
                            xml_data = ClusterUtil.parse_nmap_scan(file_name=cache_result, env_config=env_config,
                                                                   conn=c.conn, dir=cwd)
                            scan_result = ClusterUtil.parse_nmap_scan_xml(xml_data)
                            break
                        except Exception as e:
                            scan_result = NmapScanResult(hosts=[])
                            break

                    if env_config.use_nmap_cache:
                        env_config.nmap_scan_cache.add(cache_id, scan_result)
                    break

                # Update state with scan result
                if merged_scan_result is not None:
                    merged_scan_result = ClusterUtil.merge_nmap_scan_results(scan_result_1=merged_scan_result,
                                                                             scan_result_2=scan_result)
                else:
                    merged_scan_result = scan_result

        if env_config.use_nmap_cache:
            env_config.nmap_scan_cache.add(base_cache_id, merged_scan_result)
        s_prime, reward = ClusterUtil.merge_nmap_scan_result_with_state(scan_result=merged_scan_result, s=s, a=a,
                                                                        env_config=env_config)
        return s_prime, reward, False